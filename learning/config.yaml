# defaults:
#     - override hydra/launcher: submitit_local

# environment
benchmark: dm_control
task: CheetahRun
obs: state
exp_name : test
# evaluation
checkpoint: ???
eval_episodes: 1
eval_pi: true
eval_value: true # evaluate value function approximation
eval_freq: 50000
impl : warp
eval_with_training_env : false #added
#policy
policy : td3
asymmetric_critic: true

#dynamics shift
randomization: true
# shift_dynamics_type: stochastic 
eval_randomization: true
# logging
wandb_project: test-algorithms
wandb_entity: tjrcjf410-seoul-national-university
wandb_silent: false
use_wandb: true
save_csv: true
comment: ''

# misc
save_video: true
save_agent: true
seed: 1

# convenience
work_dir: ???
task_title: ???
multitask: ???
tasks: ???
obs_shape: ???
action_dim: ???
episode_length: ???
obs_shapes: ???
action_dims: ???
episode_lengths: ???
seed_steps: ???
bin_size: ???

#default parameters
# learning_rate: 3e-4
# discounting: 0.99
# action_repeat: 1
# normalize_observations: true
# reward_scale: 1.0
#rambo
real_ratio : ???
rollout_length : ???
adv_weight : ???
batch_size : ???
rollout_batch_size : ???

#wdsac
n_nominals : ???
delta : ???
lambda_update_steps : ???
single_lambda : false
lmbda_lr : ???
init_lmbda : ???
distance_type : wass
custom_wrapper: true
adv_wrapper : true
#flow
flow_lr : ???
dr_flow : false
dr_train_ratio : 1.0

#simba
simba : false

#tdmpc
horizon: 3

#m2td3
omega_distance_threshold: 0.1