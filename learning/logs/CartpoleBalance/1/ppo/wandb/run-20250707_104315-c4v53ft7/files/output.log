training with ppo
INFO:2025-07-07 10:43:17,001:jax._src.xla_bridge:752: Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
[2025-07-07 10:43:17,001][jax._src.xla_bridge][INFO] - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
[2025-07-07 10:43:17,155][root][INFO] - Using JAX default device: cuda:0.
[2025-07-07 10:43:17,156][root][INFO] - MJX Warp is disabled via MJX_WARP_ENABLED=false.
[2025-07-07 10:43:17,370][absl][INFO] - Device count: 1, process count: 1 (id 0), local device count: 1, devices to be used count: 1
[2025-07-07 10:43:18,481][root][INFO] - Using JAX default device: cuda:0.
[2025-07-07 10:43:18,482][root][INFO] - MJX Warp is disabled via MJX_WARP_ENABLED=false.
[2025-07-07 10:43:28,816][root][INFO] - Using JAX default device: cuda:0.
[2025-07-07 10:43:28,817][root][INFO] - MJX Warp is disabled via MJX_WARP_ENABLED=false.
[2025-07-07 10:43:42,595][absl][INFO] - {'eval/walltime': 13.63163709640503, 'eval/episode_reward': Array(280.97, dtype=float32), 'eval/episode_reward/angle_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/centered': Array(722.488, dtype=float32), 'eval/episode_reward/small_control': Array(923.89, dtype=float32), 'eval/episode_reward/small_velocity': Array(632.353, dtype=float32), 'eval/episode_reward/upright': Array(570.899, dtype=float32), 'eval/episode_reward_std': Array(59.525, dtype=float32), 'eval/episode_reward/angle_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/centered_std': Array(65.659, dtype=float32), 'eval/episode_reward/small_control_std': Array(11.044, dtype=float32), 'eval/episode_reward/small_velocity_std': Array(68.195, dtype=float32), 'eval/episode_reward/upright_std': Array(88.874, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 13.63163709640503, 'eval/sps': 9389.921334815794}
 eval/walltime :  13.63163709640503
 eval/episode_reward :  280.969970703125
 eval/episode_reward/angle_in_bounds :  0.0
 eval/episode_reward/cart_in_bounds :  0.0
 eval/episode_reward/centered :  722.4876708984375
 eval/episode_reward/small_control :  923.8895263671875
 eval/episode_reward/small_velocity :  632.3533935546875
 eval/episode_reward/upright :  570.8992919921875
 eval/episode_reward_std :  59.52457046508789
 eval/episode_reward/angle_in_bounds_std :  0.0
 eval/episode_reward/cart_in_bounds_std :  0.0
 eval/episode_reward/centered_std :  65.6590576171875
 eval/episode_reward/small_control_std :  11.043773651123047
 eval/episode_reward/small_velocity_std :  68.19498443603516
 eval/episode_reward/upright_std :  88.8744125366211
 eval/avg_episode_length :  1000.0
 eval/std_episode_length :  0.0
 eval/epoch_eval_time :  13.63163709640503
 eval/sps :  9389.921334815794
[2025-07-07 10:43:42,608][absl][INFO] - starting iteration 0 25.238395929336548
[2025-07-07 10:44:13,556][absl][INFO] - {'eval/walltime': 13.81781816482544, 'training/sps': np.float64(227591.82533244742), 'training/walltime': 30.235180854797363, 'training/entropy_loss': Array(-0.005, dtype=float32), 'training/policy_loss': Array(-0.007, dtype=float32), 'training/total_loss': Array(518.706, dtype=float32), 'training/v_loss': Array(518.718, dtype=float32), 'eval/episode_reward': Array(634.307, dtype=float32), 'eval/episode_reward/angle_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/centered': Array(888.879, dtype=float32), 'eval/episode_reward/small_control': Array(947.936, dtype=float32), 'eval/episode_reward/small_velocity': Array(831.937, dtype=float32), 'eval/episode_reward/upright': Array(806.585, dtype=float32), 'eval/episode_reward_std': Array(100.204, dtype=float32), 'eval/episode_reward/angle_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/centered_std': Array(39.684, dtype=float32), 'eval/episode_reward/small_control_std': Array(5.802, dtype=float32), 'eval/episode_reward/small_velocity_std': Array(58.9, dtype=float32), 'eval/episode_reward/upright_std': Array(73.503, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 0.18618106842041016, 'eval/sps': 687502.7686003329}
 eval/walltime :  13.81781816482544
 training/sps :  227591.82533244742
 training/walltime :  30.235180854797363
 training/entropy_loss :  -0.005326516460627317
 training/policy_loss :  -0.007181978784501553
 training/total_loss :  518.7055053710938
 training/v_loss :  518.7180786132812
 eval/episode_reward :  634.3070068359375
 eval/episode_reward/angle_in_bounds :  0.0
 eval/episode_reward/cart_in_bounds :  0.0
 eval/episode_reward/centered :  888.879150390625
 eval/episode_reward/small_control :  947.9364013671875
 eval/episode_reward/small_velocity :  831.9368286132812
 eval/episode_reward/upright :  806.5845947265625
 eval/episode_reward_std :  100.20384979248047
 eval/episode_reward/angle_in_bounds_std :  0.0
 eval/episode_reward/cart_in_bounds_std :  0.0
 eval/episode_reward/centered_std :  39.68440628051758
 eval/episode_reward/small_control_std :  5.802381992340088
 eval/episode_reward/small_velocity_std :  58.90032196044922
 eval/episode_reward/upright_std :  73.50302124023438
 eval/avg_episode_length :  1000.0
 eval/std_episode_length :  0.0
 eval/epoch_eval_time :  0.18618106842041016
 eval/sps :  687502.7686003329
[2025-07-07 10:44:13,568][absl][INFO] - starting iteration 1 56.19894504547119
[2025-07-07 10:44:27,380][absl][INFO] - {'eval/walltime': 13.989440679550171, 'training/sps': np.float64(505265.12185536703), 'training/walltime': 43.854327917099, 'training/entropy_loss': Array(-0., dtype=float32), 'training/policy_loss': Array(-0.027, dtype=float32), 'training/total_loss': Array(114.046, dtype=float32), 'training/v_loss': Array(114.073, dtype=float32), 'eval/episode_reward': Array(995.977, dtype=float32), 'eval/episode_reward/angle_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/centered': Array(999.805, dtype=float32), 'eval/episode_reward/small_control': Array(996.227, dtype=float32), 'eval/episode_reward/small_velocity': Array(999.95, dtype=float32), 'eval/episode_reward/upright': Array(999.998, dtype=float32), 'eval/episode_reward_std': Array(0.283, dtype=float32), 'eval/episode_reward/angle_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/centered_std': Array(0.19, dtype=float32), 'eval/episode_reward/small_control_std': Array(0.173, dtype=float32), 'eval/episode_reward/small_velocity_std': Array(0.011, dtype=float32), 'eval/episode_reward/upright_std': Array(0.001, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 0.17162251472473145, 'eval/sps': 745822.8904599235}
 eval/walltime :  13.989440679550171
 training/sps :  505265.12185536703
 training/walltime :  43.854327917099
 training/entropy_loss :  -5.11273674419499e-06
 training/policy_loss :  -0.026699621230363846
 training/total_loss :  114.04612731933594
 training/v_loss :  114.07283020019531
 eval/episode_reward :  995.9766845703125
 eval/episode_reward/angle_in_bounds :  0.0
 eval/episode_reward/cart_in_bounds :  0.0
 eval/episode_reward/centered :  999.8050537109375
 eval/episode_reward/small_control :  996.2271728515625
 eval/episode_reward/small_velocity :  999.9502563476562
 eval/episode_reward/upright :  999.9984130859375
 eval/episode_reward_std :  0.28262752294540405
 eval/episode_reward/angle_in_bounds_std :  0.0
 eval/episode_reward/cart_in_bounds_std :  0.0
 eval/episode_reward/centered_std :  0.1895788311958313
 eval/episode_reward/small_control_std :  0.173029363155365
 eval/episode_reward/small_velocity_std :  0.010989809408783913
 eval/episode_reward/upright_std :  0.00121135707013309
 eval/avg_episode_length :  1000.0
 eval/std_episode_length :  0.0
 eval/epoch_eval_time :  0.17162251472473145
 eval/sps :  745822.8904599235
[2025-07-07 10:44:27,395][absl][INFO] - starting iteration 2 70.02564144134521
[2025-07-07 10:44:40,913][absl][INFO] - {'eval/walltime': 14.170387983322144, 'training/sps': np.float64(516705.00925782725), 'training/walltime': 57.17194604873657, 'training/entropy_loss': Array(0.013, dtype=float32), 'training/policy_loss': Array(-0.011, dtype=float32), 'training/total_loss': Array(0.031, dtype=float32), 'training/v_loss': Array(0.029, dtype=float32), 'eval/episode_reward': Array(998.938, dtype=float32), 'eval/episode_reward/angle_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/centered': Array(999.513, dtype=float32), 'eval/episode_reward/small_control': Array(999.438, dtype=float32), 'eval/episode_reward/small_velocity': Array(999.991, dtype=float32), 'eval/episode_reward/upright': Array(999.999, dtype=float32), 'eval/episode_reward_std': Array(0.195, dtype=float32), 'eval/episode_reward/angle_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/centered_std': Array(0.179, dtype=float32), 'eval/episode_reward/small_control_std': Array(0.042, dtype=float32), 'eval/episode_reward/small_velocity_std': Array(0.007, dtype=float32), 'eval/episode_reward/upright_std': Array(0.001, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 0.18094730377197266, 'eval/sps': 707388.2690250188}
 eval/walltime :  14.170387983322144
 training/sps :  516705.00925782725
 training/walltime :  57.17194604873657
 training/entropy_loss :  0.012904996052384377
 training/policy_loss :  -0.010744980536401272
 training/total_loss :  0.03122570738196373
 training/v_loss :  0.0290656927973032
 eval/episode_reward :  998.938232421875
 eval/episode_reward/angle_in_bounds :  0.0
 eval/episode_reward/cart_in_bounds :  0.0
 eval/episode_reward/centered :  999.5133056640625
 eval/episode_reward/small_control :  999.438232421875
 eval/episode_reward/small_velocity :  999.9908447265625
 eval/episode_reward/upright :  999.9989013671875
 eval/episode_reward_std :  0.19497309625148773
 eval/episode_reward/angle_in_bounds_std :  0.0
 eval/episode_reward/cart_in_bounds_std :  0.0
 eval/episode_reward/centered_std :  0.1787022054195404
 eval/episode_reward/small_control_std :  0.04228278249502182
 eval/episode_reward/small_velocity_std :  0.007484126836061478
 eval/episode_reward/upright_std :  0.000978795113041997
 eval/avg_episode_length :  1000.0
 eval/std_episode_length :  0.0
 eval/epoch_eval_time :  0.18094730377197266
 eval/sps :  707388.2690250188
[2025-07-07 10:44:40,919][absl][INFO] - starting iteration 3 83.54955577850342
[2025-07-07 10:44:54,520][absl][INFO] - {'eval/walltime': 14.351708889007568, 'training/sps': np.float64(513146.57837040053), 'training/walltime': 70.58191561698914, 'training/entropy_loss': Array(0.019, dtype=float32), 'training/policy_loss': Array(-0., dtype=float32), 'training/total_loss': Array(0.046, dtype=float32), 'training/v_loss': Array(0.027, dtype=float32), 'eval/episode_reward': Array(999.318, dtype=float32), 'eval/episode_reward/angle_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/centered': Array(999.601, dtype=float32), 'eval/episode_reward/small_control': Array(999.728, dtype=float32), 'eval/episode_reward/small_velocity': Array(999.994, dtype=float32), 'eval/episode_reward/upright': Array(999.999, dtype=float32), 'eval/episode_reward_std': Array(0.45, dtype=float32), 'eval/episode_reward/angle_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/centered_std': Array(0.421, dtype=float32), 'eval/episode_reward/small_control_std': Array(0.033, dtype=float32), 'eval/episode_reward/small_velocity_std': Array(0.005, dtype=float32), 'eval/episode_reward/upright_std': Array(0.001, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 0.1813209056854248, 'eval/sps': 705930.7337790839}
 eval/walltime :  14.351708889007568
 training/sps :  513146.57837040053
 training/walltime :  70.58191561698914
 training/entropy_loss :  0.018687674775719643
 training/policy_loss :  -0.00021435417875181884
 training/total_loss :  0.04587803781032562
 training/v_loss :  0.027404718101024628
 eval/episode_reward :  999.3175048828125
 eval/episode_reward/angle_in_bounds :  0.0
 eval/episode_reward/cart_in_bounds :  0.0
 eval/episode_reward/centered :  999.6007080078125
 eval/episode_reward/small_control :  999.7282104492188
 eval/episode_reward/small_velocity :  999.9937744140625
 eval/episode_reward/upright :  999.998779296875
 eval/episode_reward_std :  0.45000892877578735
 eval/episode_reward/angle_in_bounds_std :  0.0
 eval/episode_reward/cart_in_bounds_std :  0.0
 eval/episode_reward/centered_std :  0.42062148451805115
 eval/episode_reward/small_control_std :  0.033137619495391846
 eval/episode_reward/small_velocity_std :  0.005415303632616997
 eval/episode_reward/upright_std :  0.0011532505741342902
 eval/avg_episode_length :  1000.0
 eval/std_episode_length :  0.0
 eval/epoch_eval_time :  0.1813209056854248
 eval/sps :  705930.7337790839
[2025-07-07 10:44:54,527][absl][INFO] - starting iteration 4 97.1575858592987
[2025-07-07 10:45:08,113][absl][INFO] - {'eval/walltime': 14.529025554656982, 'training/sps': np.float64(513648.0852245447), 'training/walltime': 83.97879219055176, 'training/entropy_loss': Array(0.022, dtype=float32), 'training/policy_loss': Array(0., dtype=float32), 'training/total_loss': Array(0.044, dtype=float32), 'training/v_loss': Array(0.022, dtype=float32), 'eval/episode_reward': Array(999.542, dtype=float32), 'eval/episode_reward/angle_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/centered': Array(999.711, dtype=float32), 'eval/episode_reward/small_control': Array(999.843, dtype=float32), 'eval/episode_reward/small_velocity': Array(999.993, dtype=float32), 'eval/episode_reward/upright': Array(999.998, dtype=float32), 'eval/episode_reward_std': Array(0.346, dtype=float32), 'eval/episode_reward/angle_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/centered_std': Array(0.324, dtype=float32), 'eval/episode_reward/small_control_std': Array(0.023, dtype=float32), 'eval/episode_reward/small_velocity_std': Array(0.006, dtype=float32), 'eval/episode_reward/upright_std': Array(0.002, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 0.17731666564941406, 'eval/sps': 721872.3605658043}
 eval/walltime :  14.529025554656982
 training/sps :  513648.0852245447
 training/walltime :  83.97879219055176
 training/entropy_loss :  0.021755032241344452
 training/policy_loss :  0.000166841215104796
 training/total_loss :  0.04376129060983658
 training/v_loss :  0.02183941751718521
 eval/episode_reward :  999.542236328125
 eval/episode_reward/angle_in_bounds :  0.0
 eval/episode_reward/cart_in_bounds :  0.0
 eval/episode_reward/centered :  999.7110595703125
 eval/episode_reward/small_control :  999.8433837890625
 eval/episode_reward/small_velocity :  999.9932861328125
 eval/episode_reward/upright :  999.998291015625
 eval/episode_reward_std :  0.34609395265579224
 eval/episode_reward/angle_in_bounds_std :  0.0
 eval/episode_reward/cart_in_bounds_std :  0.0
 eval/episode_reward/centered_std :  0.32433751225471497
 eval/episode_reward/small_control_std :  0.023369234055280685
 eval/episode_reward/small_velocity_std :  0.0055229333229362965
 eval/episode_reward/upright_std :  0.0015359451062977314
 eval/avg_episode_length :  1000.0
 eval/std_episode_length :  0.0
 eval/epoch_eval_time :  0.17731666564941406
 eval/sps :  721872.3605658043
[2025-07-07 10:45:08,123][absl][INFO] - starting iteration 5 110.75302910804749
[2025-07-07 10:45:21,893][absl][INFO] - {'eval/walltime': 14.712270021438599, 'training/sps': np.float64(506942.1987826297), 'training/walltime': 97.55288410186768, 'training/entropy_loss': Array(0.024, dtype=float32), 'training/policy_loss': Array(0.001, dtype=float32), 'training/total_loss': Array(0.04, dtype=float32), 'training/v_loss': Array(0.015, dtype=float32), 'eval/episode_reward': Array(999.621, dtype=float32), 'eval/episode_reward/angle_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/centered': Array(999.743, dtype=float32), 'eval/episode_reward/small_control': Array(999.888, dtype=float32), 'eval/episode_reward/small_velocity': Array(999.994, dtype=float32), 'eval/episode_reward/upright': Array(999.998, dtype=float32), 'eval/episode_reward_std': Array(0.306, dtype=float32), 'eval/episode_reward/angle_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/centered_std': Array(0.285, dtype=float32), 'eval/episode_reward/small_control_std': Array(0.021, dtype=float32), 'eval/episode_reward/small_velocity_std': Array(0.006, dtype=float32), 'eval/episode_reward/upright_std': Array(0.002, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 0.1832444667816162, 'eval/sps': 698520.4096369552}
 eval/walltime :  14.712270021438599
 training/sps :  506942.1987826297
 training/walltime :  97.55288410186768
 training/entropy_loss :  0.02415207214653492
 training/policy_loss :  0.0010512180160731077
 training/total_loss :  0.03991866111755371
 training/v_loss :  0.014715374447405338
 eval/episode_reward :  999.6207275390625
 eval/episode_reward/angle_in_bounds :  0.0
 eval/episode_reward/cart_in_bounds :  0.0
 eval/episode_reward/centered :  999.743408203125
 eval/episode_reward/small_control :  999.8883056640625
 eval/episode_reward/small_velocity :  999.994140625
 eval/episode_reward/upright :  999.998046875
 eval/episode_reward_std :  0.3056962192058563
 eval/episode_reward/angle_in_bounds_std :  0.0
 eval/episode_reward/cart_in_bounds_std :  0.0
 eval/episode_reward/centered_std :  0.28512853384017944
 eval/episode_reward/small_control_std :  0.020665517076849937
 eval/episode_reward/small_velocity_std :  0.005685009993612766
 eval/episode_reward/upright_std :  0.001988061238080263
 eval/avg_episode_length :  1000.0
 eval/std_episode_length :  0.0
 eval/epoch_eval_time :  0.1832444667816162
 eval/sps :  698520.4096369552
[2025-07-07 10:45:21,907][absl][INFO] - starting iteration 6 124.53765177726746
[2025-07-07 10:45:36,076][absl][INFO] - {'eval/walltime': 14.898519277572632, 'training/sps': np.float64(492764.375675259), 'training/walltime': 111.51752996444702, 'training/entropy_loss': Array(0.026, dtype=float32), 'training/policy_loss': Array(0., dtype=float32), 'training/total_loss': Array(0.038, dtype=float32), 'training/v_loss': Array(0.012, dtype=float32), 'eval/episode_reward': Array(999.645, dtype=float32), 'eval/episode_reward/angle_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/centered': Array(999.743, dtype=float32), 'eval/episode_reward/small_control': Array(999.916, dtype=float32), 'eval/episode_reward/small_velocity': Array(999.994, dtype=float32), 'eval/episode_reward/upright': Array(999.997, dtype=float32), 'eval/episode_reward_std': Array(0.298, dtype=float32), 'eval/episode_reward/angle_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/centered_std': Array(0.284, dtype=float32), 'eval/episode_reward/small_control_std': Array(0.014, dtype=float32), 'eval/episode_reward/small_velocity_std': Array(0.005, dtype=float32), 'eval/episode_reward/upright_std': Array(0.002, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 0.1862492561340332, 'eval/sps': 687251.066967406}
 eval/walltime :  14.898519277572632
 training/sps :  492764.375675259
 training/walltime :  111.51752996444702
 training/entropy_loss :  0.025531794875860214
 training/policy_loss :  0.00023571724887005985
 training/total_loss :  0.03821156919002533
 training/v_loss :  0.012444059364497662
 eval/episode_reward :  999.645263671875
 eval/episode_reward/angle_in_bounds :  0.0
 eval/episode_reward/cart_in_bounds :  0.0
 eval/episode_reward/centered :  999.7430419921875
 eval/episode_reward/small_control :  999.916015625
 eval/episode_reward/small_velocity :  999.9943237304688
 eval/episode_reward/upright :  999.997314453125
 eval/episode_reward_std :  0.29767000675201416
 eval/episode_reward/angle_in_bounds_std :  0.0
 eval/episode_reward/cart_in_bounds_std :  0.0
 eval/episode_reward/centered_std :  0.28368109464645386
 eval/episode_reward/small_control_std :  0.013636215589940548
 eval/episode_reward/small_velocity_std :  0.005212322808802128
 eval/episode_reward/upright_std :  0.0024472344666719437
 eval/avg_episode_length :  1000.0
 eval/std_episode_length :  0.0
 eval/epoch_eval_time :  0.1862492561340332
 eval/sps :  687251.066967406
[2025-07-07 10:45:36,084][absl][INFO] - starting iteration 7 138.71440601348877
[2025-07-07 10:45:50,251][absl][INFO] - {'eval/walltime': 15.074322700500488, 'training/sps': np.float64(492248.0074862435), 'training/walltime': 125.49682474136353, 'training/entropy_loss': Array(0.023, dtype=float32), 'training/policy_loss': Array(0.009, dtype=float32), 'training/total_loss': Array(328.636, dtype=float32), 'training/v_loss': Array(328.603, dtype=float32), 'eval/episode_reward': Array(440.327, dtype=float32), 'eval/episode_reward/angle_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/centered': Array(835.267, dtype=float32), 'eval/episode_reward/small_control': Array(888.225, dtype=float32), 'eval/episode_reward/small_velocity': Array(721.741, dtype=float32), 'eval/episode_reward/upright': Array(682.198, dtype=float32), 'eval/episode_reward_std': Array(143.453, dtype=float32), 'eval/episode_reward/angle_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/centered_std': Array(57.266, dtype=float32), 'eval/episode_reward/small_control_std': Array(24.614, dtype=float32), 'eval/episode_reward/small_velocity_std': Array(89.923, dtype=float32), 'eval/episode_reward/upright_std': Array(115.141, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 0.17580342292785645, 'eval/sps': 728085.9375105951}
 eval/walltime :  15.074322700500488
 training/sps :  492248.0074862435
 training/walltime :  125.49682474136353
 training/entropy_loss :  0.02344217151403427
 training/policy_loss :  0.009001952596008778
 training/total_loss :  328.6358947753906
 training/v_loss :  328.60345458984375
 eval/episode_reward :  440.3267517089844
 eval/episode_reward/angle_in_bounds :  0.0
 eval/episode_reward/cart_in_bounds :  0.0
 eval/episode_reward/centered :  835.2673950195312
 eval/episode_reward/small_control :  888.2252197265625
 eval/episode_reward/small_velocity :  721.7408447265625
 eval/episode_reward/upright :  682.198486328125
 eval/episode_reward_std :  143.45266723632812
 eval/episode_reward/angle_in_bounds_std :  0.0
 eval/episode_reward/cart_in_bounds_std :  0.0
 eval/episode_reward/centered_std :  57.26604461669922
 eval/episode_reward/small_control_std :  24.614477157592773
 eval/episode_reward/small_velocity_std :  89.92292785644531
 eval/episode_reward/upright_std :  115.1412353515625
 eval/avg_episode_length :  1000.0
 eval/std_episode_length :  0.0
 eval/epoch_eval_time :  0.17580342292785645
 eval/sps :  728085.9375105951
[2025-07-07 10:45:50,264][absl][INFO] - starting iteration 8 152.89408612251282
[2025-07-07 10:46:04,689][absl][INFO] - {'eval/walltime': 15.265300989151001, 'training/sps': np.float64(484093.63047526655), 'training/walltime': 139.71159553527832, 'training/entropy_loss': Array(0.007, dtype=float32), 'training/policy_loss': Array(-0.024, dtype=float32), 'training/total_loss': Array(224.752, dtype=float32), 'training/v_loss': Array(224.769, dtype=float32), 'eval/episode_reward': Array(992.737, dtype=float32), 'eval/episode_reward/angle_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/centered': Array(996.216, dtype=float32), 'eval/episode_reward/small_control': Array(996.571, dtype=float32), 'eval/episode_reward/small_velocity': Array(999.944, dtype=float32), 'eval/episode_reward/upright': Array(999.996, dtype=float32), 'eval/episode_reward_std': Array(0.396, dtype=float32), 'eval/episode_reward/angle_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/centered_std': Array(0.212, dtype=float32), 'eval/episode_reward/small_control_std': Array(0.428, dtype=float32), 'eval/episode_reward/small_velocity_std': Array(0.029, dtype=float32), 'eval/episode_reward/upright_std': Array(0.003, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 0.1909782886505127, 'eval/sps': 670233.2548085506}
 eval/walltime :  15.265300989151001
 training/sps :  484093.63047526655
 training/walltime :  139.71159553527832
 training/entropy_loss :  0.006561198737472296
 training/policy_loss :  -0.02392708882689476
 training/total_loss :  224.7515106201172
 training/v_loss :  224.7688751220703
 eval/episode_reward :  992.7369995117188
 eval/episode_reward/angle_in_bounds :  0.0
 eval/episode_reward/cart_in_bounds :  0.0
 eval/episode_reward/centered :  996.21630859375
 eval/episode_reward/small_control :  996.5711669921875
 eval/episode_reward/small_velocity :  999.9444580078125
 eval/episode_reward/upright :  999.9956665039062
 eval/episode_reward_std :  0.3964662551879883
 eval/episode_reward/angle_in_bounds_std :  0.0
 eval/episode_reward/cart_in_bounds_std :  0.0
 eval/episode_reward/centered_std :  0.2116885781288147
 eval/episode_reward/small_control_std :  0.42819878458976746
 eval/episode_reward/small_velocity_std :  0.028805270791053772
 eval/episode_reward/upright_std :  0.0034420620650053024
 eval/avg_episode_length :  1000.0
 eval/std_episode_length :  0.0
 eval/epoch_eval_time :  0.1909782886505127
 eval/sps :  670233.2548085506
[2025-07-07 10:46:05,652][absl][INFO] - total steps: 61931520
time to jit: 0:00:25.232085
time to train: 0:02:22.099622
