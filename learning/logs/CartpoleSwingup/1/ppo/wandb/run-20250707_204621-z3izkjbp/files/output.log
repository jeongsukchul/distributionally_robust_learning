training with ppo
INFO:2025-07-07 20:46:22,887:jax._src.xla_bridge:752: Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
[2025-07-07 20:46:22,887][jax._src.xla_bridge][INFO] - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
[2025-07-07 20:46:23,043][root][INFO] - Using JAX default device: cuda:0.
[2025-07-07 20:46:23,044][root][INFO] - MJX Warp is disabled via MJX_WARP_ENABLED=false.
[2025-07-07 20:46:23,186][root][INFO] - Using JAX default device: cuda:0.
[2025-07-07 20:46:23,187][root][INFO] - MJX Warp is disabled via MJX_WARP_ENABLED=false.
[2025-07-07 20:46:24,348][root][INFO] - Using JAX default device: cuda:0.
[2025-07-07 20:46:24,348][root][INFO] - MJX Warp is disabled via MJX_WARP_ENABLED=false.
[2025-07-07 20:46:35,973][root][INFO] - Using JAX default device: cuda:0.
[2025-07-07 20:46:35,973][root][INFO] - MJX Warp is disabled via MJX_WARP_ENABLED=false.
-------------------------------------------------------------------
num_steps: 0
 eval/walltime :  16.245713233947754
 eval/episode_reward :  34.50839614868164
 eval/episode_reward/angle_in_bounds :  0.0
 eval/episode_reward/cart_in_bounds :  0.0
 eval/episode_reward/centered :  826.7589111328125
 eval/episode_reward/small_control :  941.2802124023438
 eval/episode_reward/small_velocity :  911.4990234375
 eval/episode_reward/upright :  55.7447395324707
 eval/episode_reward_std :  25.49077033996582
 eval/episode_reward/angle_in_bounds_std :  0.0
 eval/episode_reward/cart_in_bounds_std :  0.0
 eval/episode_reward/centered_std :  65.50981903076172
 eval/episode_reward/small_control_std :  2.721644163131714
 eval/episode_reward/small_velocity_std :  47.325809478759766
 eval/episode_reward/upright_std :  49.66188049316406
 eval/avg_episode_length :  1000.0
 eval/std_episode_length :  0.0
 eval/epoch_eval_time :  16.245713233947754
 eval/sps :  7879.001565319127
-------------------------------------------------------------------
-------------------------------------------------------------------
num_steps: 6881280
 eval/walltime :  16.420040130615234
 training/sps :  215014.84722646844
 training/walltime :  32.003743410110474
 training/entropy_loss :  -0.00561507698148489
 training/policy_loss :  -0.006302607245743275
 training/total_loss :  262.6095886230469
 training/v_loss :  262.6214904785156
 eval/episode_reward :  239.04196166992188
 eval/episode_reward/angle_in_bounds :  0.0
 eval/episode_reward/cart_in_bounds :  0.0
 eval/episode_reward/centered :  748.8480224609375
 eval/episode_reward/small_control :  932.8672485351562
 eval/episode_reward/small_velocity :  632.2808837890625
 eval/episode_reward/upright :  514.3472900390625
 eval/episode_reward_std :  33.39768981933594
 eval/episode_reward/angle_in_bounds_std :  0.0
 eval/episode_reward/cart_in_bounds_std :  0.0
 eval/episode_reward/centered_std :  35.623600006103516
 eval/episode_reward/small_control_std :  3.441981315612793
 eval/episode_reward/small_velocity_std :  45.619667053222656
 eval/episode_reward/upright_std :  44.51274108886719
 eval/avg_episode_length :  1000.0
 eval/std_episode_length :  0.0
 eval/epoch_eval_time :  0.17432689666748047
 eval/sps :  734252.7312016193
-------------------------------------------------------------------
-------------------------------------------------------------------
num_steps: 13762560
 eval/walltime :  16.595327854156494
 training/sps :  515409.3565146688
 training/walltime :  45.35483980178833
 training/entropy_loss :  -0.004105254542082548
 training/policy_loss :  -0.006320449989289045
 training/total_loss :  445.4486083984375
 training/v_loss :  445.4590759277344
 eval/episode_reward :  774.8837890625
 eval/episode_reward/angle_in_bounds :  0.0
 eval/episode_reward/cart_in_bounds :  0.0
 eval/episode_reward/centered :  920.774658203125
 eval/episode_reward/small_control :  958.860107421875
 eval/episode_reward/small_velocity :  947.3768310546875
 eval/episode_reward/upright :  862.8353271484375
 eval/episode_reward_std :  80.35096740722656
 eval/episode_reward/angle_in_bounds_std :  0.0
 eval/episode_reward/cart_in_bounds_std :  0.0
 eval/episode_reward/centered_std :  38.279109954833984
 eval/episode_reward/small_control_std :  4.405462265014648
 eval/episode_reward/small_velocity_std :  29.714431762695312
 eval/episode_reward/upright_std :  54.3941764831543
 eval/avg_episode_length :  1000.0
 eval/std_episode_length :  0.0
 eval/epoch_eval_time :  0.17528772354125977
 eval/sps :  730227.978400729
-------------------------------------------------------------------
-------------------------------------------------------------------
num_steps: 20643840
 eval/walltime :  16.783069610595703
 training/sps :  503660.0234946807
 training/walltime :  59.01738929748535
 training/entropy_loss :  -0.0005869196611456573
 training/policy_loss :  -0.010786847211420536
 training/total_loss :  140.42349243164062
 training/v_loss :  140.4348602294922
 eval/episode_reward :  841.6847534179688
 eval/episode_reward/angle_in_bounds :  0.0
 eval/episode_reward/cart_in_bounds :  0.0
 eval/episode_reward/centered :  951.362060546875
 eval/episode_reward/small_control :  978.7456665039062
 eval/episode_reward/small_velocity :  954.86279296875
 eval/episode_reward/upright :  882.4212036132812
 eval/episode_reward_std :  9.229683876037598
 eval/episode_reward/angle_in_bounds_std :  0.0
 eval/episode_reward/cart_in_bounds_std :  0.0
 eval/episode_reward/centered_std :  7.986045837402344
 eval/episode_reward/small_control_std :  1.0994778871536255
 eval/episode_reward/small_velocity_std :  0.8210219144821167
 eval/episode_reward/upright_std :  1.3227673768997192
 eval/avg_episode_length :  1000.0
 eval/std_episode_length :  0.0
 eval/epoch_eval_time :  0.18774175643920898
 eval/sps :  681787.5917840715
-------------------------------------------------------------------
-------------------------------------------------------------------
num_steps: 27525120
 eval/walltime :  16.962031602859497
 training/sps :  490332.84356055665
 training/walltime :  73.05128502845764
 training/entropy_loss :  0.004347920883446932
 training/policy_loss :  -0.009144444949924946
 training/total_loss :  68.16447448730469
 training/v_loss :  68.16926574707031
 eval/episode_reward :  831.0137939453125
 eval/episode_reward/angle_in_bounds :  0.0
 eval/episode_reward/cart_in_bounds :  0.0
 eval/episode_reward/centered :  938.5767822265625
 eval/episode_reward/small_control :  980.492431640625
 eval/episode_reward/small_velocity :  953.4178466796875
 eval/episode_reward/upright :  881.223388671875
 eval/episode_reward_std :  8.983697891235352
 eval/episode_reward/angle_in_bounds_std :  0.0
 eval/episode_reward/cart_in_bounds_std :  0.0
 eval/episode_reward/centered_std :  8.412882804870605
 eval/episode_reward/small_control_std :  0.7733733654022217
 eval/episode_reward/small_velocity_std :  0.44549962878227234
 eval/episode_reward/upright_std :  0.8359547257423401
 eval/avg_episode_length :  1000.0
 eval/std_episode_length :  0.0
 eval/epoch_eval_time :  0.17896199226379395
 eval/sps :  715235.6675339486
-------------------------------------------------------------------
-------------------------------------------------------------------
num_steps: 34406400
 eval/walltime :  17.146528720855713
 training/sps :  504801.2880576291
 training/walltime :  86.68294596672058
 training/entropy_loss :  0.0054873633198440075
 training/policy_loss :  -0.007031402550637722
 training/total_loss :  91.98422241210938
 training/v_loss :  91.98577117919922
 eval/episode_reward :  817.2801513671875
 eval/episode_reward/angle_in_bounds :  0.0
 eval/episode_reward/cart_in_bounds :  0.0
 eval/episode_reward/centered :  925.6922607421875
 eval/episode_reward/small_control :  980.8632202148438
 eval/episode_reward/small_velocity :  951.1602783203125
 eval/episode_reward/upright :  880.2639770507812
 eval/episode_reward_std :  36.42903137207031
 eval/episode_reward/angle_in_bounds_std :  0.0
 eval/episode_reward/cart_in_bounds_std :  0.0
 eval/episode_reward/centered_std :  22.47791862487793
 eval/episode_reward/small_control_std :  2.977529764175415
 eval/episode_reward/small_velocity_std :  17.282943725585938
 eval/episode_reward/upright_std :  15.896879196166992
 eval/avg_episode_length :  1000.0
 eval/std_episode_length :  0.0
 eval/epoch_eval_time :  0.18449711799621582
 eval/sps :  693777.7749060849
-------------------------------------------------------------------
-------------------------------------------------------------------
num_steps: 41287680
 eval/walltime :  17.329156160354614
 training/sps :  519336.63497656956
 training/walltime :  99.93307995796204
 training/entropy_loss :  0.006818300113081932
 training/policy_loss :  -0.007261944934725761
 training/total_loss :  41.14413070678711
 training/v_loss :  41.14457702636719
 eval/episode_reward :  475.3686828613281
 eval/episode_reward/angle_in_bounds :  0.0
 eval/episode_reward/cart_in_bounds :  0.0
 eval/episode_reward/centered :  875.2745361328125
 eval/episode_reward/small_control :  922.098876953125
 eval/episode_reward/small_velocity :  758.3494873046875
 eval/episode_reward/upright :  684.6367797851562
 eval/episode_reward_std :  159.18577575683594
 eval/episode_reward/angle_in_bounds_std :  0.0
 eval/episode_reward/cart_in_bounds_std :  0.0
 eval/episode_reward/centered_std :  39.91495132446289
 eval/episode_reward/small_control_std :  20.07476043701172
 eval/episode_reward/small_velocity_std :  123.36177062988281
 eval/episode_reward/upright_std :  112.94942474365234
 eval/avg_episode_length :  1000.0
 eval/std_episode_length :  0.0
 eval/epoch_eval_time :  0.18262743949890137
 eval/sps :  700880.4391673575
-------------------------------------------------------------------
-------------------------------------------------------------------
num_steps: 48168960
 eval/walltime :  17.5193293094635
 training/sps :  521134.3227719218
 training/walltime :  113.13750672340393
 training/entropy_loss :  0.00610236544162035
 training/policy_loss :  -0.010718748904764652
 training/total_loss :  227.57086181640625
 training/v_loss :  227.5754852294922
 eval/episode_reward :  828.42626953125
 eval/episode_reward/angle_in_bounds :  0.0
 eval/episode_reward/cart_in_bounds :  0.0
 eval/episode_reward/centered :  943.462158203125
 eval/episode_reward/small_control :  979.4429931640625
 eval/episode_reward/small_velocity :  945.1170043945312
 eval/episode_reward/upright :  874.3499755859375
 eval/episode_reward_std :  67.35539245605469
 eval/episode_reward/angle_in_bounds_std :  0.0
 eval/episode_reward/cart_in_bounds_std :  0.0
 eval/episode_reward/centered_std :  17.254867553710938
 eval/episode_reward/small_control_std :  4.177696704864502
 eval/episode_reward/small_velocity_std :  39.450286865234375
 eval/episode_reward/upright_std :  35.934288024902344
 eval/avg_episode_length :  1000.0
 eval/std_episode_length :  0.0
 eval/epoch_eval_time :  0.19017314910888672
 eval/sps :  673070.8336049666
-------------------------------------------------------------------
-------------------------------------------------------------------
num_steps: 55050240
 eval/walltime :  17.70670771598816
 training/sps :  521664.3948889861
 training/walltime :  126.3285162448883
 training/entropy_loss :  0.006997295655310154
 training/policy_loss :  -0.006291707046329975
 training/total_loss :  44.922035217285156
 training/v_loss :  44.921321868896484
 eval/episode_reward :  815.1766357421875
 eval/episode_reward/angle_in_bounds :  0.0
 eval/episode_reward/cart_in_bounds :  0.0
 eval/episode_reward/centered :  925.2178344726562
 eval/episode_reward/small_control :  976.5042114257812
 eval/episode_reward/small_velocity :  952.1968383789062
 eval/episode_reward/upright :  880.2256469726562
 eval/episode_reward_std :  13.509499549865723
 eval/episode_reward/angle_in_bounds_std :  0.0
 eval/episode_reward/cart_in_bounds_std :  0.0
 eval/episode_reward/centered_std :  11.56043815612793
 eval/episode_reward/small_control_std :  2.0550448894500732
 eval/episode_reward/small_velocity_std :  0.32754895091056824
 eval/episode_reward/upright_std :  0.5144418478012085
 eval/avg_episode_length :  1000.0
 eval/std_episode_length :  0.0
 eval/epoch_eval_time :  0.1873784065246582
 eval/sps :  683109.6622820076
-------------------------------------------------------------------
-------------------------------------------------------------------
num_steps: 61931520
 eval/walltime :  17.89090323448181
 training/sps :  497663.6187236982
 training/walltime :  140.15568733215332
 training/entropy_loss :  0.007719322107732296
 training/policy_loss :  -0.00630547059699893
 training/total_loss :  49.909034729003906
 training/v_loss :  49.907615661621094
 eval/episode_reward :  758.5455322265625
 eval/episode_reward/angle_in_bounds :  0.0
 eval/episode_reward/cart_in_bounds :  0.0
 eval/episode_reward/centered :  927.849853515625
 eval/episode_reward/small_control :  977.5882568359375
 eval/episode_reward/small_velocity :  902.71533203125
 eval/episode_reward/upright :  836.038818359375
 eval/episode_reward_std :  143.2032012939453
 eval/episode_reward/angle_in_bounds_std :  0.0
 eval/episode_reward/cart_in_bounds_std :  0.0
 eval/episode_reward/centered_std :  25.395023345947266
 eval/episode_reward/small_control_std :  8.088912963867188
 eval/episode_reward/small_velocity_std :  90.7734375
 eval/episode_reward/upright_std :  81.84607696533203
 eval/avg_episode_length :  1000.0
 eval/std_episode_length :  0.0
 eval/epoch_eval_time :  0.18419551849365234
 eval/sps :  694913.758199883
-------------------------------------------------------------------
time to jit: 0:00:29.678899
time to train: 0:02:24.531537
Saving parameters to /home/sukchul/distributionally_robust_learning/learning/logs/CartpoleSwingup/1/ppo/models
