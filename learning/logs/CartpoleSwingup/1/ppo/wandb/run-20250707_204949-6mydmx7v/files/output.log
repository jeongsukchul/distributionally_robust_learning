training with ppo
INFO:2025-07-07 20:49:50,843:jax._src.xla_bridge:752: Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
[2025-07-07 20:49:50,843][jax._src.xla_bridge][INFO] - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
[2025-07-07 20:49:51,002][root][INFO] - Using JAX default device: cuda:0.
[2025-07-07 20:49:51,003][root][INFO] - MJX Warp is disabled via MJX_WARP_ENABLED=false.
[2025-07-07 20:49:51,122][root][INFO] - Using JAX default device: cuda:0.
[2025-07-07 20:49:51,122][root][INFO] - MJX Warp is disabled via MJX_WARP_ENABLED=false.
model geom_friction (2048, 5, 3)
[2025-07-07 20:49:54,447][root][INFO] - Using JAX default device: cuda:0.
[2025-07-07 20:49:54,448][root][INFO] - MJX Warp is disabled via MJX_WARP_ENABLED=false.
model geom_friction (128, 5, 3)
[2025-07-07 20:50:08,408][root][INFO] - Using JAX default device: cuda:0.
[2025-07-07 20:50:08,408][root][INFO] - MJX Warp is disabled via MJX_WARP_ENABLED=false.
-------------------------------------------------------------------
num_steps: 0
 eval/walltime :  15.957301616668701
 eval/episode_reward :  34.50839614868164
 eval/episode_reward/angle_in_bounds :  0.0
 eval/episode_reward/cart_in_bounds :  0.0
 eval/episode_reward/centered :  826.7589111328125
 eval/episode_reward/small_control :  941.2802124023438
 eval/episode_reward/small_velocity :  911.4990234375
 eval/episode_reward/upright :  55.7447395324707
 eval/episode_reward_std :  25.49077033996582
 eval/episode_reward/angle_in_bounds_std :  0.0
 eval/episode_reward/cart_in_bounds_std :  0.0
 eval/episode_reward/centered_std :  65.50981903076172
 eval/episode_reward/small_control_std :  2.721644163131714
 eval/episode_reward/small_velocity_std :  47.325809478759766
 eval/episode_reward/upright_std :  49.66188049316406
 eval/avg_episode_length :  1000.0
 eval/std_episode_length :  0.0
 eval/epoch_eval_time :  15.957301616668701
 eval/sps :  8021.406317612846
-------------------------------------------------------------------
-------------------------------------------------------------------
num_steps: 6881280
 eval/walltime :  16.13411808013916
 training/sps :  213564.95909359754
 training/walltime :  32.22101616859436
 training/entropy_loss :  -0.00561507698148489
 training/policy_loss :  -0.006302607245743275
 training/total_loss :  262.6095886230469
 training/v_loss :  262.6214904785156
 eval/episode_reward :  239.04196166992188
 eval/episode_reward/angle_in_bounds :  0.0
 eval/episode_reward/cart_in_bounds :  0.0
 eval/episode_reward/centered :  748.8480224609375
 eval/episode_reward/small_control :  932.8672485351562
 eval/episode_reward/small_velocity :  632.2808837890625
 eval/episode_reward/upright :  514.3472900390625
 eval/episode_reward_std :  33.39768981933594
 eval/episode_reward/angle_in_bounds_std :  0.0
 eval/episode_reward/cart_in_bounds_std :  0.0
 eval/episode_reward/centered_std :  35.623600006103516
 eval/episode_reward/small_control_std :  3.441981315612793
 eval/episode_reward/small_velocity_std :  45.619667053222656
 eval/episode_reward/upright_std :  44.51274108886719
 eval/avg_episode_length :  1000.0
 eval/std_episode_length :  0.0
 eval/epoch_eval_time :  0.17681646347045898
 eval/sps :  723914.4901310911
-------------------------------------------------------------------
-------------------------------------------------------------------
num_steps: 13762560
 eval/walltime :  16.333102464675903
 training/sps :  505826.32913388987
 training/walltime :  45.825052976608276
 training/entropy_loss :  -0.004105254542082548
 training/policy_loss :  -0.006320449989289045
 training/total_loss :  445.4486083984375
 training/v_loss :  445.4590759277344
 eval/episode_reward :  774.8837890625
 eval/episode_reward/angle_in_bounds :  0.0
 eval/episode_reward/cart_in_bounds :  0.0
 eval/episode_reward/centered :  920.774658203125
 eval/episode_reward/small_control :  958.860107421875
 eval/episode_reward/small_velocity :  947.3768310546875
 eval/episode_reward/upright :  862.8353271484375
 eval/episode_reward_std :  80.35096740722656
 eval/episode_reward/angle_in_bounds_std :  0.0
 eval/episode_reward/cart_in_bounds_std :  0.0
 eval/episode_reward/centered_std :  38.279109954833984
 eval/episode_reward/small_control_std :  4.405462265014648
 eval/episode_reward/small_velocity_std :  29.714431762695312
 eval/episode_reward/upright_std :  54.3941764831543
 eval/avg_episode_length :  1000.0
 eval/std_episode_length :  0.0
 eval/epoch_eval_time :  0.19898438453674316
 eval/sps :  643266.5573130155
-------------------------------------------------------------------
-------------------------------------------------------------------
num_steps: 20643840
 eval/walltime :  16.51928997039795
 training/sps :  506845.80402571644
 training/walltime :  59.401726484298706
 training/entropy_loss :  -0.0005869196611456573
 training/policy_loss :  -0.010786847211420536
 training/total_loss :  140.42349243164062
 training/v_loss :  140.4348602294922
 eval/episode_reward :  841.6847534179688
 eval/episode_reward/angle_in_bounds :  0.0
 eval/episode_reward/cart_in_bounds :  0.0
 eval/episode_reward/centered :  951.362060546875
 eval/episode_reward/small_control :  978.7456665039062
 eval/episode_reward/small_velocity :  954.86279296875
 eval/episode_reward/upright :  882.4212036132812
 eval/episode_reward_std :  9.229683876037598
 eval/episode_reward/angle_in_bounds_std :  0.0
 eval/episode_reward/cart_in_bounds_std :  0.0
 eval/episode_reward/centered_std :  7.986045837402344
 eval/episode_reward/small_control_std :  1.0994778871536255
 eval/episode_reward/small_velocity_std :  0.8210219144821167
 eval/episode_reward/upright_std :  1.3227673768997192
 eval/avg_episode_length :  1000.0
 eval/std_episode_length :  0.0
 eval/epoch_eval_time :  0.1861875057220459
 eval/sps :  687478.9986772131
-------------------------------------------------------------------
-------------------------------------------------------------------
num_steps: 27525120
 eval/walltime :  16.70596408843994
 training/sps :  502491.74649350456
 training/walltime :  73.09604096412659
 training/entropy_loss :  0.004347920883446932
 training/policy_loss :  -0.009144444949924946
 training/total_loss :  68.16447448730469
 training/v_loss :  68.16926574707031
 eval/episode_reward :  831.0137939453125
 eval/episode_reward/angle_in_bounds :  0.0
 eval/episode_reward/cart_in_bounds :  0.0
 eval/episode_reward/centered :  938.5767822265625
 eval/episode_reward/small_control :  980.492431640625
 eval/episode_reward/small_velocity :  953.4178466796875
 eval/episode_reward/upright :  881.223388671875
 eval/episode_reward_std :  8.983697891235352
 eval/episode_reward/angle_in_bounds_std :  0.0
 eval/episode_reward/cart_in_bounds_std :  0.0
 eval/episode_reward/centered_std :  8.412882804870605
 eval/episode_reward/small_control_std :  0.7733733654022217
 eval/episode_reward/small_velocity_std :  0.44549962878227234
 eval/episode_reward/upright_std :  0.8359547257423401
 eval/avg_episode_length :  1000.0
 eval/std_episode_length :  0.0
 eval/epoch_eval_time :  0.1866741180419922
 eval/sps :  685686.9144077408
-------------------------------------------------------------------
-------------------------------------------------------------------
num_steps: 34406400
 eval/walltime :  16.886568069458008
 training/sps :  505835.94773079874
 training/walltime :  86.69981908798218
 training/entropy_loss :  0.0054873633198440075
 training/policy_loss :  -0.007031402550637722
 training/total_loss :  91.98422241210938
 training/v_loss :  91.98577117919922
 eval/episode_reward :  817.2801513671875
 eval/episode_reward/angle_in_bounds :  0.0
 eval/episode_reward/cart_in_bounds :  0.0
 eval/episode_reward/centered :  925.6922607421875
 eval/episode_reward/small_control :  980.8632202148438
 eval/episode_reward/small_velocity :  951.1602783203125
 eval/episode_reward/upright :  880.2639770507812
 eval/episode_reward_std :  36.42903137207031
 eval/episode_reward/angle_in_bounds_std :  0.0
 eval/episode_reward/cart_in_bounds_std :  0.0
 eval/episode_reward/centered_std :  22.47791862487793
 eval/episode_reward/small_control_std :  2.977529764175415
 eval/episode_reward/small_velocity_std :  17.282943725585938
 eval/episode_reward/upright_std :  15.896879196166992
 eval/avg_episode_length :  1000.0
 eval/std_episode_length :  0.0
 eval/epoch_eval_time :  0.1806039810180664
 eval/sps :  708732.9929188867
-------------------------------------------------------------------
-------------------------------------------------------------------
num_steps: 41287680
 eval/walltime :  17.068138360977173
 training/sps :  500194.2435270465
 training/walltime :  100.45703458786011
 training/entropy_loss :  0.006818300113081932
 training/policy_loss :  -0.007261944934725761
 training/total_loss :  41.14413070678711
 training/v_loss :  41.14457702636719
 eval/episode_reward :  475.3686828613281
 eval/episode_reward/angle_in_bounds :  0.0
 eval/episode_reward/cart_in_bounds :  0.0
 eval/episode_reward/centered :  875.2745361328125
 eval/episode_reward/small_control :  922.098876953125
 eval/episode_reward/small_velocity :  758.3494873046875
 eval/episode_reward/upright :  684.6367797851562
 eval/episode_reward_std :  159.18577575683594
 eval/episode_reward/angle_in_bounds_std :  0.0
 eval/episode_reward/cart_in_bounds_std :  0.0
 eval/episode_reward/centered_std :  39.91495132446289
 eval/episode_reward/small_control_std :  20.07476043701172
 eval/episode_reward/small_velocity_std :  123.36177062988281
 eval/episode_reward/upright_std :  112.94942474365234
 eval/avg_episode_length :  1000.0
 eval/std_episode_length :  0.0
 eval/epoch_eval_time :  0.18157029151916504
 eval/sps :  704961.1416551005
-------------------------------------------------------------------
-------------------------------------------------------------------
num_steps: 48168960
 eval/walltime :  17.24528455734253
 training/sps :  506205.9072734505
 training/walltime :  114.05087041854858
 training/entropy_loss :  0.00610236544162035
 training/policy_loss :  -0.010718748904764652
 training/total_loss :  227.57086181640625
 training/v_loss :  227.5754852294922
 eval/episode_reward :  828.42626953125
 eval/episode_reward/angle_in_bounds :  0.0
 eval/episode_reward/cart_in_bounds :  0.0
 eval/episode_reward/centered :  943.462158203125
 eval/episode_reward/small_control :  979.4429931640625
 eval/episode_reward/small_velocity :  945.1170043945312
 eval/episode_reward/upright :  874.3499755859375
 eval/episode_reward_std :  67.35539245605469
 eval/episode_reward/angle_in_bounds_std :  0.0
 eval/episode_reward/cart_in_bounds_std :  0.0
 eval/episode_reward/centered_std :  17.254867553710938
 eval/episode_reward/small_control_std :  4.177696704864502
 eval/episode_reward/small_velocity_std :  39.450286865234375
 eval/episode_reward/upright_std :  35.934288024902344
 eval/avg_episode_length :  1000.0
 eval/std_episode_length :  0.0
 eval/epoch_eval_time :  0.17714619636535645
 eval/sps :  722567.0244480185
-------------------------------------------------------------------
-------------------------------------------------------------------
num_steps: 55050240
 eval/walltime :  17.420619010925293
 training/sps :  498720.9142761089
 training/walltime :  127.84872770309448
 training/entropy_loss :  0.006997295655310154
 training/policy_loss :  -0.006291707046329975
 training/total_loss :  44.922035217285156
 training/v_loss :  44.921321868896484
 eval/episode_reward :  815.1766357421875
 eval/episode_reward/angle_in_bounds :  0.0
 eval/episode_reward/cart_in_bounds :  0.0
 eval/episode_reward/centered :  925.2178344726562
 eval/episode_reward/small_control :  976.5042114257812
 eval/episode_reward/small_velocity :  952.1968383789062
 eval/episode_reward/upright :  880.2256469726562
 eval/episode_reward_std :  13.509499549865723
 eval/episode_reward/angle_in_bounds_std :  0.0
 eval/episode_reward/cart_in_bounds_std :  0.0
 eval/episode_reward/centered_std :  11.56043815612793
 eval/episode_reward/small_control_std :  2.0550448894500732
 eval/episode_reward/small_velocity_std :  0.32754895091056824
 eval/episode_reward/upright_std :  0.5144418478012085
 eval/avg_episode_length :  1000.0
 eval/std_episode_length :  0.0
 eval/epoch_eval_time :  0.17533445358276367
 eval/sps :  730033.3584441792
-------------------------------------------------------------------
-------------------------------------------------------------------
num_steps: 61931520
 eval/walltime :  17.64249873161316
 training/sps :  481522.0082749129
 training/walltime :  142.13941407203674
 training/entropy_loss :  0.007719322107732296
 training/policy_loss :  -0.00630547059699893
 training/total_loss :  49.909034729003906
 training/v_loss :  49.907615661621094
 eval/episode_reward :  758.5455322265625
 eval/episode_reward/angle_in_bounds :  0.0
 eval/episode_reward/cart_in_bounds :  0.0
 eval/episode_reward/centered :  927.849853515625
 eval/episode_reward/small_control :  977.5882568359375
 eval/episode_reward/small_velocity :  902.71533203125
 eval/episode_reward/upright :  836.038818359375
 eval/episode_reward_std :  143.2032012939453
 eval/episode_reward/angle_in_bounds_std :  0.0
 eval/episode_reward/cart_in_bounds_std :  0.0
 eval/episode_reward/centered_std :  25.395023345947266
 eval/episode_reward/small_control_std :  8.088912963867188
 eval/episode_reward/small_velocity_std :  90.7734375
 eval/episode_reward/upright_std :  81.84607696533203
 eval/avg_episode_length :  1000.0
 eval/std_episode_length :  0.0
 eval/epoch_eval_time :  0.2218797206878662
 eval/sps :  576889.1343615246
-------------------------------------------------------------------
time to jit: 0:00:33.822389
time to train: 0:02:26.577692
Saving parameters to /home/sukchul/distributionally_robust_learning/learning/logs/CartpoleSwingup/1/ppo/models
