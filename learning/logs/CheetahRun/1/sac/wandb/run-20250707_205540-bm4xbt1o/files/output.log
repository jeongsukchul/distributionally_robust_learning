[34m[1mwandb[0m: [33mWARNING[0m Saving files without folders. If you want to preserve subdirectories pass base_path to wandb.save, i.e. wandb.save("/mnt/folder/file.h5", base_path="/mnt")
INFO:2025-07-07 20:55:41,474:jax._src.xla_bridge:752: Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
[2025-07-07 20:55:41,474][jax._src.xla_bridge][INFO] - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
[2025-07-07 20:55:41,701][root][INFO] - Using JAX default device: cuda:0.
[2025-07-07 20:55:41,701][root][INFO] - MJX Warp is disabled via MJX_WARP_ENABLED=false.
[2025-07-07 20:55:41,880][root][INFO] - Using JAX default device: cuda:0.
[2025-07-07 20:55:41,881][root][INFO] - MJX Warp is disabled via MJX_WARP_ENABLED=false.
[2025-07-07 20:55:44,447][root][INFO] - Using JAX default device: cuda:0.
[2025-07-07 20:55:44,447][root][INFO] - MJX Warp is disabled via MJX_WARP_ENABLED=false.
[2025-07-07 20:55:50,875][root][INFO] - Using JAX default device: cuda:0.
[2025-07-07 20:55:50,876][root][INFO] - MJX Warp is disabled via MJX_WARP_ENABLED=false.
[2025-07-07 20:56:22,142][root][INFO] - Using JAX default device: cuda:0.
[2025-07-07 20:56:22,143][root][INFO] - MJX Warp is disabled via MJX_WARP_ENABLED=false.
 eval/walltime :  48.640331506729126
 eval/episode_reward :  1.127026081085205
 eval/episode_reward_std :  1.347081184387207
 eval/avg_episode_length :  1000.0
 eval/std_episode_length :  0.0
 eval/epoch_eval_time :  48.640331506729126
 eval/sps :  2631.5610119205685
 eval/walltime :  49.7863073348999
 training/sps :  19679.930942206887
 training/walltime :  75.14645266532898
 training/actor_loss :  -37.69600296020508
 training/alpha :  0.0636591911315918
 training/alpha_loss :  0.4097677767276764
 training/buffer_current_size :  563392.0625
 training/critic_loss :  0.011918200179934502
 eval/episode_reward :  552.1892700195312
 eval/episode_reward_std :  27.239234924316406
 eval/avg_episode_length :  1000.0
 eval/std_episode_length :  0.0
 eval/epoch_eval_time :  1.1459758281707764
 eval/sps :  111695.20059102424
 eval/walltime :  50.872206687927246
 training/sps :  37067.678668012806
 training/walltime :  105.0990161895752
 training/actor_loss :  -48.53097915649414
 training/alpha :  0.00640987791121006
 training/alpha_loss :  4.00143071601633e-05
 training/buffer_current_size :  1673664.125
 training/critic_loss :  0.012283256277441978
 eval/episode_reward :  546.6854248046875
 eval/episode_reward_std :  28.033641815185547
 eval/avg_episode_length :  1000.0
 eval/std_episode_length :  0.0
 eval/epoch_eval_time :  1.0858993530273438
 eval/sps :  117874.64431501219
 eval/walltime :  51.92849326133728
 training/sps :  37552.274577592194
 training/walltime :  134.66505479812622
 training/actor_loss :  -52.44612503051758
 training/alpha :  0.004391396418213844
 training/alpha_loss :  1.2078648978786077e-05
 training/buffer_current_size :  2783936.25
 training/critic_loss :  0.008243739604949951
 eval/episode_reward :  547.911376953125
 eval/episode_reward_std :  28.860349655151367
 eval/avg_episode_length :  1000.0
 eval/std_episode_length :  0.0
 eval/epoch_eval_time :  1.0562865734100342
 eval/sps :  121179.23603513643
 eval/walltime :  52.97438144683838
 training/sps :  29524.389245843053
 training/walltime :  172.2703034877777
 training/actor_loss :  -53.44715881347656
 training/alpha :  0.0035383577924221754
 training/alpha_loss :  1.2690823496086523e-05
 training/buffer_current_size :  3864915.75
 training/critic_loss :  0.0065782638266682625
 eval/episode_reward :  533.32666015625
 eval/episode_reward_std :  26.555191040039062
 eval/avg_episode_length :  1000.0
 eval/std_episode_length :  0.0
 eval/epoch_eval_time :  1.0458881855010986
 eval/sps :  122384.01941472695
 eval/walltime :  54.0327262878418
 training/sps :  17945.660026871756
 training/walltime :  234.1388554573059
 training/actor_loss :  -55.46134567260742
 training/alpha :  0.002139674499630928
 training/alpha_loss :  1.2302143659326248e-05
 training/buffer_current_size :  4194304.0
 training/critic_loss :  0.0034113063011318445
 eval/episode_reward :  533.82373046875
 eval/episode_reward_std :  29.431907653808594
 eval/avg_episode_length :  1000.0
 eval/std_episode_length :  0.0
 eval/epoch_eval_time :  1.058344841003418
 eval/sps :  120943.56682330785
 eval/walltime :  55.157121896743774
 training/sps :  18080.239392362535
 training/walltime :  295.5468919277191
 training/actor_loss :  -55.14929962158203
 training/alpha :  0.002269247081130743
 training/alpha_loss :  -2.3142740701587172e-06
 training/buffer_current_size :  4194304.0
 training/critic_loss :  0.004196078982204199
 eval/episode_reward :  532.904541015625
 eval/episode_reward_std :  29.358373641967773
 eval/avg_episode_length :  1000.0
 eval/std_episode_length :  0.0
 eval/epoch_eval_time :  1.1243956089019775
 eval/sps :  113838.93621302712
 eval/walltime :  56.21646237373352
 training/sps :  18421.873400832363
 training/walltime :  355.8161151409149
 training/actor_loss :  -54.50655746459961
 training/alpha :  0.0024956283159554005
 training/alpha_loss :  -3.1626075269741705e-06
 training/buffer_current_size :  4194304.0
 training/critic_loss :  0.0040088375099003315
 eval/episode_reward :  524.801513671875
 eval/episode_reward_std :  27.923372268676758
 eval/avg_episode_length :  1000.0
 eval/std_episode_length :  0.0
 eval/epoch_eval_time :  1.059340476989746
 eval/sps :  120829.8963178757
 eval/walltime :  57.36165452003479
 training/sps :  18179.045313227823
 training/walltime :  416.89038944244385
 training/actor_loss :  -53.89773941040039
 training/alpha :  0.0025783772580325603
 training/alpha_loss :  -4.974766056875524e-07
 training/buffer_current_size :  4194304.0
 training/critic_loss :  0.003967473283410072
 eval/episode_reward :  519.511962890625
 eval/episode_reward_std :  28.996625900268555
 eval/avg_episode_length :  1000.0
 eval/std_episode_length :  0.0
 eval/epoch_eval_time :  1.1451921463012695
 eval/sps :  111771.63623887324
 eval/walltime :  58.44174599647522
 training/sps :  18406.3892033813
 training/walltime :  477.2103135585785
 training/actor_loss :  -53.247989654541016
 training/alpha :  0.0029726626817137003
 training/alpha_loss :  -4.186741989542497e-06
 training/buffer_current_size :  4194304.0
 training/critic_loss :  0.004748442675918341
 eval/episode_reward :  524.926513671875
 eval/episode_reward_std :  28.695234298706055
 eval/avg_episode_length :  1000.0
 eval/std_episode_length :  0.0
 eval/epoch_eval_time :  1.0800914764404297
 eval/sps :  118508.48080186622
time to jit: 0:01:29.688288
time to train: 0:08:07.096270
Saving parameters to /home/sukchul/distributionally_robust_learning/learning/logs/CheetahRun/1/sac/models
