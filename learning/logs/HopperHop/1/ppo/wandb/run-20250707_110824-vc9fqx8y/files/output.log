INFO:2025-07-07 11:08:26,056:jax._src.xla_bridge:752: Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
[2025-07-07 11:08:26,056][jax._src.xla_bridge][INFO] - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
[2025-07-07 11:08:26,207][root][INFO] - Using JAX default device: cuda:0.
[2025-07-07 11:08:26,207][root][INFO] - MJX Warp is disabled via MJX_WARP_ENABLED=false.
Error executing job with overrides: ['task=HopperHop', 'policy=sac']
Traceback (most recent call last):
  File "/home/sukchul/distributionally_robust_learning/learning/train.py", line 201, in train
    make_inference_fn, params, metrics = train_sac(cfg)
                                         ^^^^^^^^^^^^^^
  File "/home/sukchul/distributionally_robust_learning/learning/train.py", line 148, in train_sac
    progress = functools.partial(progress, wandb=cfg.use_wandb)
                                 ^^^^^^^^
UnboundLocalError: cannot access local variable 'progress' where it is not associated with a value

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
