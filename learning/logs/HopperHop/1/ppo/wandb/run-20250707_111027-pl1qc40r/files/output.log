INFO:2025-07-07 11:10:28,494:jax._src.xla_bridge:752: Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
[2025-07-07 11:10:28,494][jax._src.xla_bridge][INFO] - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
[2025-07-07 11:10:28,682][root][INFO] - Using JAX default device: cuda:0.
[2025-07-07 11:10:28,682][root][INFO] - MJX Warp is disabled via MJX_WARP_ENABLED=false.
[2025-07-07 11:10:28,916][absl][INFO] - local_device_count: 1; total_device_count: 1
[2025-07-07 11:10:29,296][root][INFO] - Using JAX default device: cuda:0.
[2025-07-07 11:10:29,297][root][INFO] - MJX Warp is disabled via MJX_WARP_ENABLED=false.
[2025-07-07 11:10:35,297][root][INFO] - Using JAX default device: cuda:0.
[2025-07-07 11:10:35,297][root][INFO] - MJX Warp is disabled via MJX_WARP_ENABLED=false.
[2025-07-07 11:10:56,265][root][INFO] - Using JAX default device: cuda:0.
[2025-07-07 11:10:56,265][root][INFO] - MJX Warp is disabled via MJX_WARP_ENABLED=false.
[2025-07-07 11:11:42,732][absl][INFO] - {'eval/walltime': 46.31942844390869, 'eval/episode_reward': Array(0.049, dtype=float32), 'eval/episode_reward/hopping': Array(43.843, dtype=float32), 'eval/episode_reward/standing': Array(1.344, dtype=float32), 'eval/episode_reward_std': Array(0.308, dtype=float32), 'eval/episode_reward/hopping_std': Array(13.87, dtype=float32), 'eval/episode_reward/standing_std': Array(3.817, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 46.31942844390869, 'eval/sps': 2763.4192454469467}
 eval/walltime :  46.31942844390869
 eval/episode_reward :  0.04947715997695923
 eval/episode_reward/hopping :  43.843162536621094
 eval/episode_reward/standing :  1.34375
 eval/episode_reward_std :  0.30774253606796265
 eval/episode_reward/hopping_std :  13.870162963867188
 eval/episode_reward/standing_std :  3.8169798851013184
 eval/avg_episode_length :  1000.0
 eval/std_episode_length :  0.0
 eval/epoch_eval_time :  46.31942844390869
 eval/sps :  2763.4192454469467
[2025-07-07 11:12:05,894][absl][INFO] - replay size after prefill 8192
[2025-07-07 11:12:05,945][absl][INFO] - step 0
[2025-07-07 11:13:07,684][absl][INFO] - {'eval/walltime': 49.99871826171875, 'training/sps': 9558.04674959125, 'training/walltime': 81.24696350097656, 'training/actor_loss': Array(-23.946, dtype=float32), 'training/alpha': Array(0.117, dtype=float32), 'training/alpha_loss': Array(0.553, dtype=float32), 'training/buffer_current_size': Array(285632., dtype=float32), 'training/critic_loss': Array(0.006, dtype=float32), 'eval/episode_reward': Array(1.275, dtype=float32), 'eval/episode_reward/hopping': Array(20.688, dtype=float32), 'eval/episode_reward/standing': Array(6.5, dtype=float32), 'eval/episode_reward_std': Array(3.789, dtype=float32), 'eval/episode_reward/hopping_std': Array(7.987, dtype=float32), 'eval/episode_reward/standing_std': Array(15.054, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 3.6792898178100586, 'eval/sps': 34789.32248837809}
 eval/walltime :  49.99871826171875
 training/sps :  9558.04674959125
 training/walltime :  81.24696350097656
 training/actor_loss :  -23.94630241394043
 training/alpha :  0.11736278980970383
 training/alpha_loss :  0.5529067516326904
 training/buffer_current_size :  285632.0
 training/critic_loss :  0.005657809320837259
 eval/episode_reward :  1.2750194072723389
 eval/episode_reward/hopping :  20.68766212463379
 eval/episode_reward/standing :  6.5
 eval/episode_reward_std :  3.78853178024292
 eval/episode_reward/hopping_std :  7.986677646636963
 eval/episode_reward/standing_std :  15.054068565368652
 eval/avg_episode_length :  1000.0
 eval/std_episode_length :  0.0
 eval/epoch_eval_time :  3.6792898178100586
 eval/sps :  34789.32248837809
[2025-07-07 11:13:07,689][absl][INFO] - step 562944
[2025-07-07 11:13:38,049][absl][INFO] - {'eval/walltime': 53.622517108917236, 'training/sps': 20752.74958593476, 'training/walltime': 107.9784574508667, 'training/actor_loss': Array(-6.748, dtype=float32), 'training/alpha': Array(0.001, dtype=float32), 'training/alpha_loss': Array(-0., dtype=float32), 'training/buffer_current_size': Array(840383.94, dtype=float32), 'training/critic_loss': Array(0.002, dtype=float32), 'eval/episode_reward': Array(30.675, dtype=float32), 'eval/episode_reward/hopping': Array(85.803, dtype=float32), 'eval/episode_reward/standing': Array(141.43, dtype=float32), 'eval/episode_reward_std': Array(41.84, dtype=float32), 'eval/episode_reward/hopping_std': Array(83.868, dtype=float32), 'eval/episode_reward/standing_std': Array(191.961, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 3.6237988471984863, 'eval/sps': 35322.04887667957}
 eval/walltime :  53.622517108917236
 training/sps :  20752.74958593476
 training/walltime :  107.9784574508667
 training/actor_loss :  -6.748167514801025
 training/alpha :  0.0009356099180877209
 training/alpha_loss :  -1.830839755712077e-05
 training/buffer_current_size :  840383.9375
 training/critic_loss :  0.0021749234292656183
 eval/episode_reward :  30.674917221069336
 eval/episode_reward/hopping :  85.80261993408203
 eval/episode_reward/standing :  141.4296875
 eval/episode_reward_std :  41.83994674682617
 eval/episode_reward/hopping_std :  83.8680191040039
 eval/episode_reward/standing_std :  191.96116638183594
 eval/avg_episode_length :  1000.0
 eval/std_episode_length :  0.0
 eval/epoch_eval_time :  3.6237988471984863
 eval/sps :  35322.04887667957
[2025-07-07 11:13:38,054][absl][INFO] - step 1117696
[2025-07-07 11:14:08,500][absl][INFO] - {'eval/walltime': 57.26041793823242, 'training/sps': 20697.815094705107, 'training/walltime': 134.78090000152588, 'training/actor_loss': Array(-3.512, dtype=float32), 'training/alpha': Array(0.001, dtype=float32), 'training/alpha_loss': Array(-0., dtype=float32), 'training/buffer_current_size': Array(1.395e+06, dtype=float32), 'training/critic_loss': Array(0.002, dtype=float32), 'eval/episode_reward': Array(59.052, dtype=float32), 'eval/episode_reward/hopping': Array(96.167, dtype=float32), 'eval/episode_reward/standing': Array(248.641, dtype=float32), 'eval/episode_reward_std': Array(64.955, dtype=float32), 'eval/episode_reward/hopping_std': Array(93.706, dtype=float32), 'eval/episode_reward/standing_std': Array(271.598, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 3.6379008293151855, 'eval/sps': 35185.12625977638}
 eval/walltime :  57.26041793823242
 training/sps :  20697.815094705107
 training/walltime :  134.78090000152588
 training/actor_loss :  -3.512446165084839
 training/alpha :  0.0007906723185442388
 training/alpha_loss :  -3.6450871903070947e-06
 training/buffer_current_size :  1395135.875
 training/critic_loss :  0.001975160790607333
 eval/episode_reward :  59.051734924316406
 eval/episode_reward/hopping :  96.16654968261719
 eval/episode_reward/standing :  248.640625
 eval/episode_reward_std :  64.95543670654297
 eval/episode_reward/hopping_std :  93.70612335205078
 eval/episode_reward/standing_std :  271.5979309082031
 eval/avg_episode_length :  1000.0
 eval/std_episode_length :  0.0
 eval/epoch_eval_time :  3.6379008293151855
 eval/sps :  35185.12625977638
[2025-07-07 11:14:08,512][absl][INFO] - step 1672448
[2025-07-07 11:14:39,497][absl][INFO] - {'eval/walltime': 61.3230881690979, 'training/sps': 20610.127409234225, 'training/walltime': 161.69737601280212, 'training/actor_loss': Array(-4.201, dtype=float32), 'training/alpha': Array(0.001, dtype=float32), 'training/alpha_loss': Array(0., dtype=float32), 'training/buffer_current_size': Array(1.95e+06, dtype=float32), 'training/critic_loss': Array(0.002, dtype=float32), 'eval/episode_reward': Array(58.889, dtype=float32), 'eval/episode_reward/hopping': Array(102.494, dtype=float32), 'eval/episode_reward/standing': Array(220.438, dtype=float32), 'eval/episode_reward_std': Array(68.99, dtype=float32), 'eval/episode_reward/hopping_std': Array(99.719, dtype=float32), 'eval/episode_reward/standing_std': Array(256.412, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 4.0626702308654785, 'eval/sps': 31506.372096740895}
 eval/walltime :  61.3230881690979
 training/sps :  20610.127409234225
 training/walltime :  161.69737601280212
 training/actor_loss :  -4.201380252838135
 training/alpha :  0.0008518605609424412
 training/alpha_loss :  7.192081170614983e-07
 training/buffer_current_size :  1949887.875
 training/critic_loss :  0.0022381653543561697
 eval/episode_reward :  58.889190673828125
 eval/episode_reward/hopping :  102.4936752319336
 eval/episode_reward/standing :  220.4375
 eval/episode_reward_std :  68.99031829833984
 eval/episode_reward/hopping_std :  99.71923065185547
 eval/episode_reward/standing_std :  256.411865234375
 eval/avg_episode_length :  1000.0
 eval/std_episode_length :  0.0
 eval/epoch_eval_time :  4.0626702308654785
 eval/sps :  31506.372096740895
[2025-07-07 11:14:39,503][absl][INFO] - step 2227200
[2025-07-07 11:15:09,943][absl][INFO] - {'eval/walltime': 64.92634534835815, 'training/sps': 20675.182806682005, 'training/walltime': 188.52915811538696, 'training/actor_loss': Array(-5.017, dtype=float32), 'training/alpha': Array(0.001, dtype=float32), 'training/alpha_loss': Array(-0., dtype=float32), 'training/buffer_current_size': Array(2.505e+06, dtype=float32), 'training/critic_loss': Array(0.002, dtype=float32), 'eval/episode_reward': Array(78.909, dtype=float32), 'eval/episode_reward/hopping': Array(142.589, dtype=float32), 'eval/episode_reward/standing': Array(264.68, dtype=float32), 'eval/episode_reward_std': Array(77.747, dtype=float32), 'eval/episode_reward/hopping_std': Array(125.579, dtype=float32), 'eval/episode_reward/standing_std': Array(258.577, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 3.603257179260254, 'eval/sps': 35523.4149637574}
 eval/walltime :  64.92634534835815
 training/sps :  20675.182806682005
 training/walltime :  188.52915811538696
 training/actor_loss :  -5.017239093780518
 training/alpha :  0.0009134455467574298
 training/alpha_loss :  -2.480195007592556e-06
 training/buffer_current_size :  2504640.0
 training/critic_loss :  0.002402374753728509
 eval/episode_reward :  78.90936279296875
 eval/episode_reward/hopping :  142.58885192871094
 eval/episode_reward/standing :  264.6796875
 eval/episode_reward_std :  77.74738311767578
 eval/episode_reward/hopping_std :  125.57850646972656
 eval/episode_reward/standing_std :  258.5772399902344
 eval/avg_episode_length :  1000.0
 eval/std_episode_length :  0.0
 eval/epoch_eval_time :  3.603257179260254
 eval/sps :  35523.4149637574
[2025-07-07 11:15:09,948][absl][INFO] - step 2781952
[2025-07-07 11:15:40,639][absl][INFO] - {'eval/walltime': 68.71191954612732, 'training/sps': 20622.89470701835, 'training/walltime': 215.42897057533264, 'training/actor_loss': Array(-5.745, dtype=float32), 'training/alpha': Array(0.001, dtype=float32), 'training/alpha_loss': Array(-0., dtype=float32), 'training/buffer_current_size': Array(3.059e+06, dtype=float32), 'training/critic_loss': Array(0.003, dtype=float32), 'eval/episode_reward': Array(78.607, dtype=float32), 'eval/episode_reward/hopping': Array(144.858, dtype=float32), 'eval/episode_reward/standing': Array(244.414, dtype=float32), 'eval/episode_reward_std': Array(83.765, dtype=float32), 'eval/episode_reward/hopping_std': Array(140.148, dtype=float32), 'eval/episode_reward/standing_std': Array(258.961, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 3.785574197769165, 'eval/sps': 33812.57196739936}
 eval/walltime :  68.71191954612732
 training/sps :  20622.89470701835
 training/walltime :  215.42897057533264
 training/actor_loss :  -5.745486259460449
 training/alpha :  0.0010810776147991419
 training/alpha_loss :  -3.6644985357270343e-06
 training/buffer_current_size :  3059392.0
 training/critic_loss :  0.0028253698255866766
 eval/episode_reward :  78.60675048828125
 eval/episode_reward/hopping :  144.85816955566406
 eval/episode_reward/standing :  244.4140625
 eval/episode_reward_std :  83.76477813720703
 eval/episode_reward/hopping_std :  140.14791870117188
 eval/episode_reward/standing_std :  258.9608154296875
 eval/avg_episode_length :  1000.0
 eval/std_episode_length :  0.0
 eval/epoch_eval_time :  3.785574197769165
 eval/sps :  33812.57196739936
[2025-07-07 11:15:40,650][absl][INFO] - step 3336704
[2025-07-07 11:16:11,550][absl][INFO] - {'eval/walltime': 72.4956226348877, 'training/sps': 20463.35953141023, 'training/walltime': 242.5384976863861, 'training/actor_loss': Array(-6.476, dtype=float32), 'training/alpha': Array(0.001, dtype=float32), 'training/alpha_loss': Array(-0., dtype=float32), 'training/buffer_current_size': Array(3.614e+06, dtype=float32), 'training/critic_loss': Array(0.004, dtype=float32), 'eval/episode_reward': Array(109.577, dtype=float32), 'eval/episode_reward/hopping': Array(193.411, dtype=float32), 'eval/episode_reward/standing': Array(318.375, dtype=float32), 'eval/episode_reward_std': Array(89.224, dtype=float32), 'eval/episode_reward/hopping_std': Array(150.274, dtype=float32), 'eval/episode_reward/standing_std': Array(255.654, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 3.783703088760376, 'eval/sps': 33829.292890403725}
 eval/walltime :  72.4956226348877
 training/sps :  20463.35953141023
 training/walltime :  242.5384976863861
 training/actor_loss :  -6.476324558258057
 training/alpha :  0.001391295692883432
 training/alpha_loss :  -1.3358108844840899e-05
 training/buffer_current_size :  3614144.0
 training/critic_loss :  0.004053208045661449
 eval/episode_reward :  109.57684326171875
 eval/episode_reward/hopping :  193.41104125976562
 eval/episode_reward/standing :  318.375
 eval/episode_reward_std :  89.22437286376953
 eval/episode_reward/hopping_std :  150.27420043945312
 eval/episode_reward/standing_std :  255.65379333496094
 eval/avg_episode_length :  1000.0
 eval/std_episode_length :  0.0
 eval/epoch_eval_time :  3.783703088760376
 eval/sps :  33829.292890403725
[2025-07-07 11:16:11,561][absl][INFO] - step 3891456
[2025-07-07 11:16:49,041][absl][INFO] - {'eval/walltime': 76.25210571289062, 'training/sps': 16453.443299615257, 'training/walltime': 276.2549660205841, 'training/actor_loss': Array(-7.537, dtype=float32), 'training/alpha': Array(0.003, dtype=float32), 'training/alpha_loss': Array(-0., dtype=float32), 'training/buffer_current_size': Array(4.112e+06, dtype=float32), 'training/critic_loss': Array(0.008, dtype=float32), 'eval/episode_reward': Array(169.589, dtype=float32), 'eval/episode_reward/hopping': Array(313.648, dtype=float32), 'eval/episode_reward/standing': Array(484.844, dtype=float32), 'eval/episode_reward_std': Array(34.811, dtype=float32), 'eval/episode_reward/hopping_std': Array(61.61, dtype=float32), 'eval/episode_reward/standing_std': Array(99.83, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 3.7564830780029297, 'eval/sps': 34074.42475903526}
 eval/walltime :  76.25210571289062
 training/sps :  16453.443299615257
 training/walltime :  276.2549660205841
 training/actor_loss :  -7.537106513977051
 training/alpha :  0.003134840866550803
 training/alpha_loss :  -0.00022786611225456
 training/buffer_current_size :  4111674.25
 training/critic_loss :  0.007800960447639227
 eval/episode_reward :  169.58914184570312
 eval/episode_reward/hopping :  313.64764404296875
 eval/episode_reward/standing :  484.84375
 eval/episode_reward_std :  34.81147003173828
 eval/episode_reward/hopping_std :  61.6102180480957
 eval/episode_reward/standing_std :  99.82965850830078
 eval/avg_episode_length :  1000.0
 eval/std_episode_length :  0.0
 eval/epoch_eval_time :  3.7564830780029297
 eval/sps :  34074.42475903526
[2025-07-07 11:16:49,046][absl][INFO] - step 4446208
[2025-07-07 11:17:34,219][absl][INFO] - {'eval/walltime': 79.98113226890564, 'training/sps': 13387.286020673899, 'training/walltime': 317.69368624687195, 'training/actor_loss': Array(-11.766, dtype=float32), 'training/alpha': Array(0.006, dtype=float32), 'training/alpha_loss': Array(0., dtype=float32), 'training/buffer_current_size': Array(4.194e+06, dtype=float32), 'training/critic_loss': Array(0.007, dtype=float32), 'eval/episode_reward': Array(211.692, dtype=float32), 'eval/episode_reward/hopping': Array(379.072, dtype=float32), 'eval/episode_reward/standing': Array(516.414, dtype=float32), 'eval/episode_reward_std': Array(5.95, dtype=float32), 'eval/episode_reward/hopping_std': Array(9.268, dtype=float32), 'eval/episode_reward/standing_std': Array(14.485, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 3.7290265560150146, 'eval/sps': 34325.312002279185}
 eval/walltime :  79.98113226890564
 training/sps :  13387.286020673899
 training/walltime :  317.69368624687195
 training/actor_loss :  -11.766188621520996
 training/alpha :  0.0063659572042524815
 training/alpha_loss :  0.00011307894601486623
 training/buffer_current_size :  4194304.0
 training/critic_loss :  0.0069669331423938274
 eval/episode_reward :  211.69248962402344
 eval/episode_reward/hopping :  379.07232666015625
 eval/episode_reward/standing :  516.4140625
 eval/episode_reward_std :  5.949743270874023
 eval/episode_reward/hopping_std :  9.267657279968262
 eval/episode_reward/standing_std :  14.485190391540527
 eval/avg_episode_length :  1000.0
 eval/std_episode_length :  0.0
 eval/epoch_eval_time :  3.7290265560150146
 eval/sps :  34325.312002279185
[2025-07-07 11:17:35,692][absl][INFO] - total steps: 5000960
time to jit: 0:01:13.821196
time to train: 0:05:51.489986
