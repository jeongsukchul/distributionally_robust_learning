INFO:2025-07-06 19:11:27,481:jax._src.xla_bridge:752: Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
[2025-07-06 19:11:27,481][jax._src.xla_bridge][INFO] - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
[2025-07-06 19:11:27,858][root][INFO] - Using JAX default device: cuda:0.
[2025-07-06 19:11:27,859][root][INFO] - MJX Warp is disabled via MJX_WARP_ENABLED=false.
[2025-07-06 19:11:28,690][absl][INFO] - Device count: 1, process count: 1 (id 0), local device count: 1, devices to be used count: 1
[2025-07-06 19:11:29,480][root][INFO] - Using JAX default device: cuda:0.
[2025-07-06 19:11:29,480][root][INFO] - MJX Warp is disabled via MJX_WARP_ENABLED=false.
[2025-07-06 19:12:02,508][root][INFO] - Using JAX default device: cuda:0.
[2025-07-06 19:12:02,508][root][INFO] - MJX Warp is disabled via MJX_WARP_ENABLED=false.
[2025-07-06 19:13:28,169][absl][INFO] - {'eval/walltime': 85.54149174690247, 'eval/episode_reward': Array(1.725, dtype=float32), 'eval/episode_reward/move': Array(191.252, dtype=float32), 'eval/episode_reward/small_control': Array(895.802, dtype=float32), 'eval/episode_reward/stand': Array(11.075, dtype=float32), 'eval/episode_reward/standing': Array(11.123, dtype=float32), 'eval/episode_reward/upright': Array(615.075, dtype=float32), 'eval/episode_reward_std': Array(0.154, dtype=float32), 'eval/episode_reward/move_std': Array(1.896, dtype=float32), 'eval/episode_reward/small_control_std': Array(1.332, dtype=float32), 'eval/episode_reward/stand_std': Array(0.688, dtype=float32), 'eval/episode_reward/standing_std': Array(0.691, dtype=float32), 'eval/episode_reward/upright_std': Array(62.345, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 85.54149174690247, 'eval/sps': 1496.34986935606}
[2025-07-06 19:13:28,193][absl][INFO] - starting iteration 0 119.5031189918518
[2025-07-06 19:18:21,916][absl][INFO] - {'eval/walltime': 101.67962718009949, 'training/sps': np.float64(24825.15321140024), 'training/walltime': 277.18983006477356, 'training/entropy_loss': Array(nan, dtype=float32), 'training/policy_loss': Array(nan, dtype=float32), 'training/total_loss': Array(nan, dtype=float32), 'training/v_loss': Array(nan, dtype=float32), 'eval/episode_reward': Array(nan, dtype=float32), 'eval/episode_reward/move': Array(0.167, dtype=float32), 'eval/episode_reward/small_control': Array(0.8, dtype=float32), 'eval/episode_reward/stand': Array(nan, dtype=float32), 'eval/episode_reward/standing': Array(nan, dtype=float32), 'eval/episode_reward/upright': Array(0., dtype=float32), 'eval/episode_reward_std': Array(nan, dtype=float32), 'eval/episode_reward/move_std': Array(0., dtype=float32), 'eval/episode_reward/small_control_std': Array(0., dtype=float32), 'eval/episode_reward/stand_std': Array(nan, dtype=float32), 'eval/episode_reward/standing_std': Array(nan, dtype=float32), 'eval/episode_reward/upright_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 16.13813543319702, 'eval/sps': 7931.523473070938}
[2025-07-06 19:18:21,937][absl][INFO] - starting iteration 1 413.2469937801361
Traceback (most recent call last):
  File "/home/ros/mujoco_playground/learning/train.py", line 208, in <module>
    save_dir = make_dir(cfg.wrok_dir / "models")
    ^^^^^^^
  File "/home/ros/miniconda3/envs/mujoco/lib/python3.12/site-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
  File "/home/ros/miniconda3/envs/mujoco/lib/python3.12/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
  File "/home/ros/miniconda3/envs/mujoco/lib/python3.12/site-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
  File "/home/ros/miniconda3/envs/mujoco/lib/python3.12/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
           ^^^^^^
  File "/home/ros/miniconda3/envs/mujoco/lib/python3.12/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
            ^^^^^^^^^^
  File "/home/ros/miniconda3/envs/mujoco/lib/python3.12/site-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
          ^^^^^^^^
  File "/home/ros/miniconda3/envs/mujoco/lib/python3.12/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
                       ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ros/mujoco_playground/learning/train.py", line 197, in train
    config=OmegaConf.to_container(cfg, resolve=True),
                                         ^^^^^^^^^^^^^
  File "/home/ros/mujoco_playground/learning/train.py", line 123, in train_ppo
    progress_fn=progress

  File "/home/ros/miniconda3/envs/mujoco/lib/python3.12/site-packages/brax/training/agents/ppo/train.py", line 702, in train
    training_epoch_with_timing(training_state, env_state, epoch_keys)
  File "/home/ros/miniconda3/envs/mujoco/lib/python3.12/site-packages/brax/training/agents/ppo/train.py", line 575, in training_epoch_with_timing
    result = training_epoch(training_state, env_state, key)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<string>", line 2, in __init__
KeyboardInterrupt
