training with ppo
INFO:2025-07-06 23:04:29,256:jax._src.xla_bridge:752: Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
[2025-07-06 23:04:29,256][jax._src.xla_bridge][INFO] - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
[2025-07-06 23:04:29,461][root][INFO] - Using JAX default device: cuda:0.
[2025-07-06 23:04:29,462][root][INFO] - MJX Warp is disabled via MJX_WARP_ENABLED=false.
[2025-07-06 23:04:29,852][absl][INFO] - Device count: 1, process count: 1 (id 0), local device count: 1, devices to be used count: 1
[2025-07-06 23:04:30,577][root][INFO] - Using JAX default device: cuda:0.
[2025-07-06 23:04:30,577][root][INFO] - MJX Warp is disabled via MJX_WARP_ENABLED=false.
[2025-07-06 23:05:06,229][root][INFO] - Using JAX default device: cuda:0.
[2025-07-06 23:05:06,230][root][INFO] - MJX Warp is disabled via MJX_WARP_ENABLED=false.
[2025-07-06 23:06:37,730][absl][INFO] - {'eval/walltime': 91.37902975082397, 'eval/episode_reward': Array(1.726, dtype=float32), 'eval/episode_reward/move': Array(191.399, dtype=float32), 'eval/episode_reward/small_control': Array(895.745, dtype=float32), 'eval/episode_reward/stand': Array(11.08, dtype=float32), 'eval/episode_reward/standing': Array(11.129, dtype=float32), 'eval/episode_reward/upright': Array(607.909, dtype=float32), 'eval/episode_reward_std': Array(0.154, dtype=float32), 'eval/episode_reward/move_std': Array(1.906, dtype=float32), 'eval/episode_reward/small_control_std': Array(1.487, dtype=float32), 'eval/episode_reward/stand_std': Array(0.695, dtype=float32), 'eval/episode_reward/standing_std': Array(0.699, dtype=float32), 'eval/episode_reward/upright_std': Array(59.026, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 91.37902975082397, 'eval/sps': 1400.7590182237168}
 eval/walltime :  91.37902975082397
 eval/episode_reward :  1.726409912109375
 eval/episode_reward/move :  191.3986053466797
 eval/episode_reward/small_control :  895.7445068359375
 eval/episode_reward/stand :  11.080455780029297
 eval/episode_reward/standing :  11.129257202148438
 eval/episode_reward/upright :  607.9085693359375
 eval/episode_reward_std :  0.15426456928253174
 eval/episode_reward/move_std :  1.9064940214157104
 eval/episode_reward/small_control_std :  1.4874683618545532
 eval/episode_reward/stand_std :  0.6948354840278625
 eval/episode_reward/standing_std :  0.6985899806022644
 eval/episode_reward/upright_std :  59.025814056396484
 eval/avg_episode_length :  1000.0
 eval/std_episode_length :  0.0
 eval/epoch_eval_time :  91.37902975082397
 eval/sps :  1400.7590182237168
[2025-07-06 23:06:37,752][absl][INFO] - starting iteration 0 127.89973449707031
[2025-07-06 23:11:48,123][absl][INFO] - {'eval/walltime': 107.89715766906738, 'training/sps': np.float64(23450.477951645604), 'training/walltime': 293.43879532814026, 'training/entropy_loss': Array(nan, dtype=float32), 'training/policy_loss': Array(nan, dtype=float32), 'training/total_loss': Array(nan, dtype=float32), 'training/v_loss': Array(nan, dtype=float32), 'eval/episode_reward': Array(nan, dtype=float32), 'eval/episode_reward/move': Array(0.167, dtype=float32), 'eval/episode_reward/small_control': Array(0.8, dtype=float32), 'eval/episode_reward/stand': Array(nan, dtype=float32), 'eval/episode_reward/standing': Array(nan, dtype=float32), 'eval/episode_reward/upright': Array(0., dtype=float32), 'eval/episode_reward_std': Array(nan, dtype=float32), 'eval/episode_reward/move_std': Array(0., dtype=float32), 'eval/episode_reward/small_control_std': Array(0., dtype=float32), 'eval/episode_reward/stand_std': Array(nan, dtype=float32), 'eval/episode_reward/standing_std': Array(nan, dtype=float32), 'eval/episode_reward/upright_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 16.518127918243408, 'eval/sps': 7749.062159679166}
 eval/walltime :  107.89715766906738
 training/sps :  23450.477951645604
 training/walltime :  293.43879532814026
 training/entropy_loss :  nan
 training/policy_loss :  nan
 training/total_loss :  nan
 training/v_loss :  nan
 eval/episode_reward :  nan
 eval/episode_reward/move :  0.1666666716337204
 eval/episode_reward/small_control :  0.800000011920929
 eval/episode_reward/stand :  nan
 eval/episode_reward/standing :  nan
 eval/episode_reward/upright :  0.0
 eval/episode_reward_std :  nan
 eval/episode_reward/move_std :  0.0
 eval/episode_reward/small_control_std :  0.0
 eval/episode_reward/stand_std :  nan
 eval/episode_reward/standing_std :  nan
 eval/episode_reward/upright_std :  0.0
 eval/avg_episode_length :  1.0
 eval/std_episode_length :  0.0
 eval/epoch_eval_time :  16.518127918243408
 eval/sps :  7749.062159679166
[2025-07-06 23:11:48,140][absl][INFO] - starting iteration 1 438.2880599498749
