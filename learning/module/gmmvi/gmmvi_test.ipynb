{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-28 17:31:29.216758: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from types import SimpleNamespace\n",
    "from typing import Callable, NamedTuple, Tuple\n",
    "proj = Path.home() / \"distributionally_robust_learning\"\n",
    "sys.path.insert(0, str(proj))\n",
    "os.environ['PYTHONPATH'] = os.environ.get(\"PYTHONPATH\",\"\") + \"~/distributionally_robust_learning\"\n",
    "import hydra\n",
    "import jax\n",
    "import matplotlib\n",
    "import distrax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from learning.module.target_examples.funnel import Funnel\n",
    "from learning.module.target_examples.gmm40 import GMM40\n",
    "import functools\n",
    "import chex\n",
    "from omegaconf import OmegaConf\n",
    "os.environ['HYDRA_FULL_ERROR'] = '1'\n",
    "os.environ['XLA_PYTHON_CLIENT_PREALLOCATE'] = 'false'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup GMMVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from learning.module.gmmvi.network import create_gmm_network_and_state\n",
    "\n",
    "\n",
    "dim=2\n",
    "key= jax.random.PRNGKey(0)\n",
    "num_envs=128\n",
    "batch_size=1024\n",
    "initial_train_state, gmm_network = create_gmm_network_and_state(dim, num_envs, batch_size, key, prior_scale=10.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from learning.module.gmmvi.network import GMMTrainingState\n",
    "from learning.module.target_examples.student_t_mixture import StudentTMixtureModel\n",
    "\n",
    "target = StudentTMixtureModel(dim=dim, sample_bounds=[-30., 30.], num_components=40)\n",
    "target = GMM40(dim=dim)\n",
    "target = Funnel(dim=dim, sample_bounds=[-30, 30])\n",
    "low = jnp.array([-10,-5])\n",
    "# low = jnp.array([-30,-30])\n",
    "# low = jnp.array([-target._plot_bound, -target._plot_bound])\n",
    "high = jnp.array([5, 5])\n",
    "# high = jnp.array([target._plot_bound, target._plot_bound])\n",
    "\n",
    "def train_iter(train_state: GMMTrainingState, key: chex.Array, target_log_prob_fn):\n",
    "    def get_target_grads(samples: chex.Array) -> Tuple[chex.Array, chex.Array]:\n",
    "        # samples = jnp.clip(samples, low+1e-6, high-1e-6)\n",
    "        target, gradient = jax.vmap(jax.value_and_grad(target_log_prob_fn))(samples)\n",
    "        cond = jnp.all((samples>=low) * (samples<=high), axis=-1) \n",
    "        target = jnp.where(cond, target,  -jnp.inf)\n",
    "        return gradient, target\n",
    "    key, subkey = jax.random.split(key)\n",
    "    new_samples, mapping = gmm_network.sample_selector.select_samples(train_state.model_state,\n",
    "                                        subkey)\n",
    "\n",
    "    new_target_grads, new_target_lnpdfs = get_target_grads(new_samples)\n",
    "    new_sample_db_state = gmm_network.sample_selector.save_samples(train_state.model_state, train_state.sample_db_state, new_samples, new_target_lnpdfs, new_target_grads, mapping)\n",
    "    samples, mapping, sample_dist_densities, target_lnpdfs, target_lnpdf_grads = \\\n",
    "        gmm_network.sample_selector.select_train_datas(new_sample_db_state)\n",
    "\n",
    "    new_component_stepsizes = gmm_network.component_stepsize_fn(train_state.model_state)\n",
    "    new_model_state = gmm_network.model.update_stepsizes(train_state.model_state, new_component_stepsizes)\n",
    "    expected_hessian_neg, expected_grad_neg = gmm_network.ng_estimator(new_model_state,\n",
    "                                                            samples,\n",
    "                                                            sample_dist_densities,\n",
    "                                                            target_lnpdfs,\n",
    "                                                            target_lnpdf_grads)\n",
    "    expected_hessian_neg, expected_grad_neg = gmm_network.more_ng_estimator(new_model_state,\n",
    "                                                            samples,\n",
    "                                                            sample_dist_densities,\n",
    "                                                            target_lnpdfs,\n",
    "                                                            target_lnpdf_grads)\n",
    "    new_model_state = gmm_network.component_updater(new_model_state,\n",
    "                                    expected_hessian_neg,\n",
    "                                    expected_grad_neg,\n",
    "                                    new_model_state.stepsizes)\n",
    "\n",
    "    new_model_state = gmm_network.weight_updater(new_model_state, samples, sample_dist_densities, target_lnpdfs,\n",
    "                                                    train_state.weight_stepsize)\n",
    "    new_num_updates = train_state.num_updates + 1\n",
    "    key, subkey = jax.random.split(key)\n",
    "    new_model_state, new_component_adapter_state, new_sample_db_state = \\\n",
    "        gmm_network.component_adapter(train_state.component_adaptation_state,\n",
    "                                                    new_sample_db_state,\n",
    "                                                    new_model_state,\n",
    "                                                    new_num_updates,\n",
    "                                                    subkey)\n",
    "    return GMMTrainingState(temperature=train_state.temperature,\n",
    "                        model_state=new_model_state,\n",
    "                        component_adaptation_state=new_component_adapter_state,\n",
    "                        num_updates=new_num_updates,\n",
    "                        sample_db_state=new_sample_db_state,\n",
    "                        weight_stepsize=train_state.weight_stepsize)\n",
    "def eval(seed: chex.Array, train_state: GMMTrainingState, target_log_prob_fn, n_eval_samples, target_samples=None):\n",
    "    samples = gmm_network.model.sample(train_state.model_state.gmm_state, seed, n_eval_samples)[0]\n",
    "    log_prob_model_fn = jax.vmap(functools.partial(gmm_network.model.log_density, gmm_state=train_state.model_state.gmm_state))\n",
    "    log_prob_model = log_prob_model_fn(sample=samples)\n",
    "    # log_prob_model = jax.vmap(gmm_network.model.log_density, in_axes=(None, 0))(train_state.model_state.gmm_state, samples)\n",
    "    log_prob_target = jax.vmap(target_log_prob_fn)(samples)\n",
    "    log_ratio = log_prob_target - log_prob_model\n",
    "\n",
    "    if target_samples is not None:\n",
    "        fwd_log_prob_model = jax.vmap(gmm_network.model.log_density, in_axes=(None, 0))(train_state.model_state.gmm_state, target_samples)\n",
    "        fwd_log_prob_target = jax.vmap(target_log_prob_fn)(target_samples)\n",
    "        fwd_log_ratio = fwd_log_prob_target - fwd_log_prob_model\n",
    "    else:\n",
    "        fwd_log_ratio = None\n",
    "\n",
    "    return samples, log_ratio, log_prob_target, fwd_log_ratio, n_eval_samples, log_prob_model_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "import wandb\n",
    "\n",
    "from learning.module.target_examples.student_t_mixture import StudentTMixtureModel\n",
    "\n",
    "\n",
    "logger = {\n",
    "    'KL/elbo': [],\n",
    "    'KL/eubo': [],\n",
    "    'logZ/delta_forward': [],\n",
    "    'logZ/forward': [],\n",
    "    'logZ/delta_reverse': [],\n",
    "    'logZ/reverse': [],\n",
    "    'ESS/forward': [],\n",
    "    'ESS/reverse': [],\n",
    "    'discrepancies/mmd': [],\n",
    "    'discrepancies/sd': [],\n",
    "    'other/target_log_prob': [],\n",
    "    'other/EMC': [],\n",
    "    \"stats/step\": [],\n",
    "    \"stats/wallclock\": [],\n",
    "    \"stats/nfe\": [],\n",
    "}\n",
    "def eval_fn(samples, log_ratio, target_log_prob, fwd_log_ratio, n_eval_samples, model_log_prob_fn):\n",
    "    ln_z = jax.nn.logsumexp(log_ratio) - jnp.log(n_eval_samples)\n",
    "    elbo = jnp.mean(log_ratio)\n",
    "\n",
    "    if target.log_Z is not None:\n",
    "        logger['logZ/delta_reverse'].append(jnp.abs(ln_z - target.log_Z))\n",
    "\n",
    "    logger['logZ/reverse'].append(ln_z)\n",
    "    logger['KL/elbo'].append(elbo)\n",
    "    # logger['ESS/reverse'].append(compute_reverse_ess(log_ratio, n_eval_samples))\n",
    "    logger['other/target_log_prob'].append(jnp.mean(target_log_prob))\n",
    "\n",
    "    logger.update(target.visualise(samples=samples, model_log_prob_fn=model_log_prob_fn ,show=True))\n",
    "    return logger\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 3000\n",
    "seed=0\n",
    "num_evals = 3000\n",
    "eval_freq = 8#iterations//num_evals\n",
    "n_eval_samples= 1000\n",
    "target_samples = target.sample(jax.random.PRNGKey(0), (n_eval_samples,))\n",
    "target_log_prob = jax.jit(lambda x : target.log_prob(x))\n",
    "rng =jax.random.PRNGKey(seed)\n",
    "key, rng = jax.random.split(rng)\n",
    "timer = 0\n",
    "state = initial_train_state\n",
    "\n",
    "\n",
    "def _insert_buffer(train_state: GMMTrainingState, key: chex.Array, target_log_prob_fn):\n",
    "    def get_target_grads(samples: chex.Array) -> Tuple[chex.Array, chex.Array]:\n",
    "        # samples = jnp.clip(samples, low+1e-6, high-1e-6)\n",
    "        target, gradient = jax.vmap(jax.value_and_grad(target_log_prob_fn))(samples)\n",
    "        cond = jnp.all((samples>=low) * (samples<=high), axis=-1) \n",
    "        target = jnp.where(cond, target,  -jnp.inf)\n",
    "        return gradient, target\n",
    "    key, subkey = jax.random.split(key)\n",
    "    new_samples, mapping = gmm_network.sample_selector.select_samples(train_state.model_state,\n",
    "                                        subkey)\n",
    "    new_target_grads, new_target_lnpdfs = get_target_grads(new_samples)\n",
    "    new_sample_db_state = gmm_network.sample_selector.save_samples(train_state.model_state, train_state.sample_db_state, new_samples, new_target_lnpdfs, new_target_grads, mapping)\n",
    "    return train_state._replace(sample_db_state=new_sample_db_state)\n",
    "def _train(carry, _):\n",
    "    state, key = carry\n",
    "    key, subkey = jax.random.split(key)\n",
    "    state = train_iter(state, subkey, target_log_prob)\n",
    "    return (state, key), _\n",
    "@jax.jit\n",
    "def jitted_train(state, key):\n",
    "    (state, _), _ = jax.lax.scan(_train, (state, key), (), length=eval_freq)\n",
    "    return state\n",
    "for _ in range(batch_size//num_envs):\n",
    "    key, subkey = jax.random.split(key)\n",
    "    state = _insert_buffer(state, key, target_log_prob)\n",
    "logger = eval_fn(*eval(rng, state, target_log_prob, n_eval_samples, target_samples))\n",
    "# jax.config.update(\"jax_disable_jit\", True) \n",
    "# jax.config.update(\"jax_debug_nans\", True)\n",
    "for step in range(0, iterations):\n",
    "    iter_time = time()\n",
    "    key, subkey = jax.random.split(key)\n",
    "    \n",
    "    # state = train_iter(state, subkey, target_log_prob)\n",
    "    # (state, _), _ = jax.lax.scan(_train, (state, subkey), (), length=eval_freq)\n",
    "    state = jitted_train(state, subkey)\n",
    "    step+=eval_freq\n",
    "    # step+=1\n",
    "    timer += time() - iter_time\n",
    "    if (step % eval_freq == 0) or (step == iterations - 1):\n",
    "        key, subkey = jax.random.split(key)\n",
    "        logger = eval_fn(*eval(subkey, state, target_log_prob, n_eval_samples, target_samples))\n",
    "        logger[\"stats/step\"].append(step)\n",
    "        logger[\"stats/wallclock\"].append(timer)\n",
    "        logger['stats/num_samples'] = [state.sample_db_state.num_samples_written]\n",
    "        logger['stats/num_components'] = [state.model_state.gmm_state.num_components]\n",
    "        print(f\"{step}/{iterations}: \"\n",
    "                f\"The model now has {state.model_state.gmm_state.num_components} components \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sampling_bench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
