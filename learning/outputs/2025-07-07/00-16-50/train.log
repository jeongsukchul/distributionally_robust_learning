[2025-07-07 00:16:52,047][jax._src.xla_bridge][INFO] - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
[2025-07-07 00:16:52,326][root][INFO] - Using JAX default device: cuda:0.
[2025-07-07 00:16:52,327][root][INFO] - MJX Warp is disabled via MJX_WARP_ENABLED=false.
[2025-07-07 00:16:53,924][absl][INFO] - Device count: 1, process count: 1 (id 0), local device count: 1, devices to be used count: 1
[2025-07-07 00:16:55,156][root][INFO] - Using JAX default device: cuda:0.
[2025-07-07 00:16:55,156][root][INFO] - MJX Warp is disabled via MJX_WARP_ENABLED=false.
[2025-07-07 00:17:28,208][root][INFO] - Using JAX default device: cuda:0.
[2025-07-07 00:17:28,209][root][INFO] - MJX Warp is disabled via MJX_WARP_ENABLED=false.
[2025-07-07 00:18:11,932][absl][INFO] - {'eval/walltime': 43.613654136657715, 'eval/episode_reward': Array(0.043, dtype=float32), 'eval/episode_reward/hopping': Array(28.696, dtype=float32), 'eval/episode_reward/standing': Array(1.273, dtype=float32), 'eval/episode_reward_std': Array(0.235, dtype=float32), 'eval/episode_reward/hopping_std': Array(6.736, dtype=float32), 'eval/episode_reward/standing_std': Array(3.954, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 43.613654136657715, 'eval/sps': 2934.860711256357}
[2025-07-07 00:18:11,943][absl][INFO] - starting iteration 0 78.01906085014343
[2025-07-07 01:41:48,499][absl][INFO] - {'eval/walltime': 52.64236044883728, 'training/sps': np.float64(1374.2909819577565), 'training/walltime': 5007.149206638336, 'training/entropy_loss': Array(-0.025, dtype=float32), 'training/policy_loss': Array(-0.002, dtype=float32), 'training/total_loss': Array(-0.003, dtype=float32), 'training/v_loss': Array(0.023, dtype=float32), 'eval/episode_reward': Array(0.213, dtype=float32), 'eval/episode_reward/hopping': Array(28.574, dtype=float32), 'eval/episode_reward/standing': Array(4.289, dtype=float32), 'eval/episode_reward_std': Array(1.257, dtype=float32), 'eval/episode_reward/hopping_std': Array(5.889, dtype=float32), 'eval/episode_reward/standing_std': Array(9.189, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 9.028706312179565, 'eval/sps': 14177.003390544474}
[2025-07-07 01:41:48,515][absl][INFO] - starting iteration 1 5094.591333150864
[2025-07-07 02:10:31,653][absl][INFO] - {'eval/walltime': 61.42512559890747, 'training/sps': np.float64(4013.9501876145137), 'training/walltime': 6721.490361452103, 'training/entropy_loss': Array(-0.027, dtype=float32), 'training/policy_loss': Array(-0.002, dtype=float32), 'training/total_loss': Array(0.068, dtype=float32), 'training/v_loss': Array(0.097, dtype=float32), 'eval/episode_reward': Array(1.219, dtype=float32), 'eval/episode_reward/hopping': Array(30.802, dtype=float32), 'eval/episode_reward/standing': Array(7.969, dtype=float32), 'eval/episode_reward_std': Array(2.816, dtype=float32), 'eval/episode_reward/hopping_std': Array(6.233, dtype=float32), 'eval/episode_reward/standing_std': Array(13.799, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 8.78276515007019, 'eval/sps': 14573.997802841972}
[2025-07-07 02:10:31,667][absl][INFO] - starting iteration 2 6817.743040323257
[2025-07-07 02:38:54,949][absl][INFO] - {'eval/walltime': 70.26432204246521, 'training/sps': np.float64(4061.1176921798856), 'training/walltime': 8415.920447349548, 'training/entropy_loss': Array(-0.027, dtype=float32), 'training/policy_loss': Array(-0.001, dtype=float32), 'training/total_loss': Array(0.092, dtype=float32), 'training/v_loss': Array(0.12, dtype=float32), 'eval/episode_reward': Array(0.813, dtype=float32), 'eval/episode_reward/hopping': Array(31.198, dtype=float32), 'eval/episode_reward/standing': Array(8.469, dtype=float32), 'eval/episode_reward_std': Array(2.598, dtype=float32), 'eval/episode_reward/hopping_std': Array(7.176, dtype=float32), 'eval/episode_reward/standing_std': Array(14.505, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 8.83919644355774, 'eval/sps': 14480.954328522712}
[2025-07-07 02:38:54,959][absl][INFO] - starting iteration 3 8521.0354013443
[2025-07-07 03:05:56,379][absl][INFO] - {'eval/walltime': 78.98343396186829, 'training/sps': np.float64(4266.960621199615), 'training/walltime': 10028.609340190887, 'training/entropy_loss': Array(-0.027, dtype=float32), 'training/policy_loss': Array(-0.001, dtype=float32), 'training/total_loss': Array(0.051, dtype=float32), 'training/v_loss': Array(0.079, dtype=float32), 'eval/episode_reward': Array(0.663, dtype=float32), 'eval/episode_reward/hopping': Array(29.382, dtype=float32), 'eval/episode_reward/standing': Array(5.195, dtype=float32), 'eval/episode_reward_std': Array(2.607, dtype=float32), 'eval/episode_reward/hopping_std': Array(6.686, dtype=float32), 'eval/episode_reward/standing_std': Array(12.551, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 8.719111919403076, 'eval/sps': 14680.394194178789}
[2025-07-07 03:05:56,395][absl][INFO] - starting iteration 4 10142.471567630768
[2025-07-07 03:39:36,223][absl][INFO] - {'eval/walltime': 88.72107362747192, 'training/sps': np.float64(3423.391386317762), 'training/walltime': 12038.686256170273, 'training/entropy_loss': Array(-0.027, dtype=float32), 'training/policy_loss': Array(-0.001, dtype=float32), 'training/total_loss': Array(0.035, dtype=float32), 'training/v_loss': Array(0.063, dtype=float32), 'eval/episode_reward': Array(0.704, dtype=float32), 'eval/episode_reward/hopping': Array(30.158, dtype=float32), 'eval/episode_reward/standing': Array(4.984, dtype=float32), 'eval/episode_reward_std': Array(2.3, dtype=float32), 'eval/episode_reward/hopping_std': Array(6.97, dtype=float32), 'eval/episode_reward/standing_std': Array(10.788, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 9.737639665603638, 'eval/sps': 13144.869228642305}
[2025-07-07 03:39:36,232][absl][INFO] - starting iteration 5 12162.308320760727
[2025-07-07 04:08:27,707][absl][INFO] - {'eval/walltime': 97.65499782562256, 'training/sps': np.float64(3994.8740105880556), 'training/walltime': 13761.213670492172, 'training/entropy_loss': Array(-0.027, dtype=float32), 'training/policy_loss': Array(-0.001, dtype=float32), 'training/total_loss': Array(0.07, dtype=float32), 'training/v_loss': Array(0.098, dtype=float32), 'eval/episode_reward': Array(1.109, dtype=float32), 'eval/episode_reward/hopping': Array(30.87, dtype=float32), 'eval/episode_reward/standing': Array(6.125, dtype=float32), 'eval/episode_reward_std': Array(2.996, dtype=float32), 'eval/episode_reward/hopping_std': Array(6.375, dtype=float32), 'eval/episode_reward/standing_std': Array(11.238, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 8.933924198150635, 'eval/sps': 14327.410571325041}
[2025-07-07 04:08:27,718][absl][INFO] - starting iteration 6 13893.794706821442
[2025-07-07 04:40:04,435][absl][INFO] - {'eval/walltime': 106.45702505111694, 'training/sps': np.float64(3644.934073546853), 'training/walltime': 15649.116129398346, 'training/entropy_loss': Array(-0.027, dtype=float32), 'training/policy_loss': Array(-0.001, dtype=float32), 'training/total_loss': Array(0.03, dtype=float32), 'training/v_loss': Array(0.058, dtype=float32), 'eval/episode_reward': Array(0.935, dtype=float32), 'eval/episode_reward/hopping': Array(29.591, dtype=float32), 'eval/episode_reward/standing': Array(6.273, dtype=float32), 'eval/episode_reward_std': Array(2.895, dtype=float32), 'eval/episode_reward/hopping_std': Array(6.302, dtype=float32), 'eval/episode_reward/standing_std': Array(13.954, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 8.802027225494385, 'eval/sps': 14542.104531244575}
[2025-07-07 04:40:04,454][absl][INFO] - starting iteration 7 15790.530614614487
[2025-07-07 05:06:25,538][absl][INFO] - {'eval/walltime': 115.55727648735046, 'training/sps': np.float64(4377.478858814095), 'training/walltime': 17221.089455127716, 'training/entropy_loss': Array(-0.027, dtype=float32), 'training/policy_loss': Array(-0.001, dtype=float32), 'training/total_loss': Array(0.04, dtype=float32), 'training/v_loss': Array(0.068, dtype=float32), 'eval/episode_reward': Array(0.654, dtype=float32), 'eval/episode_reward/hopping': Array(29.211, dtype=float32), 'eval/episode_reward/standing': Array(4.305, dtype=float32), 'eval/episode_reward_std': Array(2.4, dtype=float32), 'eval/episode_reward/hopping_std': Array(6.308, dtype=float32), 'eval/episode_reward/standing_std': Array(10.651, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 9.10025143623352, 'eval/sps': 14065.5454299159}
[2025-07-07 05:06:25,551][absl][INFO] - starting iteration 8 17371.62707734108
[2025-07-07 05:39:10,332][absl][INFO] - {'eval/walltime': 125.1017758846283, 'training/sps': np.float64(3519.4349661487026), 'training/walltime': 19176.312400341034, 'training/entropy_loss': Array(-0.027, dtype=float32), 'training/policy_loss': Array(-0.001, dtype=float32), 'training/total_loss': Array(0.041, dtype=float32), 'training/v_loss': Array(0.069, dtype=float32), 'eval/episode_reward': Array(0.919, dtype=float32), 'eval/episode_reward/hopping': Array(29.636, dtype=float32), 'eval/episode_reward/standing': Array(7.109, dtype=float32), 'eval/episode_reward_std': Array(2.964, dtype=float32), 'eval/episode_reward/hopping_std': Array(6.021, dtype=float32), 'eval/episode_reward/standing_std': Array(17.759, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 9.544499397277832, 'eval/sps': 13410.865742891307}
[2025-07-07 05:39:11,039][absl][INFO] - total steps: 61931520
