[2025-07-07 10:43:17,001][jax._src.xla_bridge][INFO] - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
[2025-07-07 10:43:17,155][root][INFO] - Using JAX default device: cuda:0.
[2025-07-07 10:43:17,156][root][INFO] - MJX Warp is disabled via MJX_WARP_ENABLED=false.
[2025-07-07 10:43:17,370][absl][INFO] - Device count: 1, process count: 1 (id 0), local device count: 1, devices to be used count: 1
[2025-07-07 10:43:18,481][root][INFO] - Using JAX default device: cuda:0.
[2025-07-07 10:43:18,482][root][INFO] - MJX Warp is disabled via MJX_WARP_ENABLED=false.
[2025-07-07 10:43:28,816][root][INFO] - Using JAX default device: cuda:0.
[2025-07-07 10:43:28,817][root][INFO] - MJX Warp is disabled via MJX_WARP_ENABLED=false.
[2025-07-07 10:43:42,595][absl][INFO] - {'eval/walltime': 13.63163709640503, 'eval/episode_reward': Array(280.97, dtype=float32), 'eval/episode_reward/angle_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/centered': Array(722.488, dtype=float32), 'eval/episode_reward/small_control': Array(923.89, dtype=float32), 'eval/episode_reward/small_velocity': Array(632.353, dtype=float32), 'eval/episode_reward/upright': Array(570.899, dtype=float32), 'eval/episode_reward_std': Array(59.525, dtype=float32), 'eval/episode_reward/angle_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/centered_std': Array(65.659, dtype=float32), 'eval/episode_reward/small_control_std': Array(11.044, dtype=float32), 'eval/episode_reward/small_velocity_std': Array(68.195, dtype=float32), 'eval/episode_reward/upright_std': Array(88.874, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 13.63163709640503, 'eval/sps': 9389.921334815794}
[2025-07-07 10:43:42,608][absl][INFO] - starting iteration 0 25.238395929336548
[2025-07-07 10:44:13,556][absl][INFO] - {'eval/walltime': 13.81781816482544, 'training/sps': np.float64(227591.82533244742), 'training/walltime': 30.235180854797363, 'training/entropy_loss': Array(-0.005, dtype=float32), 'training/policy_loss': Array(-0.007, dtype=float32), 'training/total_loss': Array(518.706, dtype=float32), 'training/v_loss': Array(518.718, dtype=float32), 'eval/episode_reward': Array(634.307, dtype=float32), 'eval/episode_reward/angle_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/centered': Array(888.879, dtype=float32), 'eval/episode_reward/small_control': Array(947.936, dtype=float32), 'eval/episode_reward/small_velocity': Array(831.937, dtype=float32), 'eval/episode_reward/upright': Array(806.585, dtype=float32), 'eval/episode_reward_std': Array(100.204, dtype=float32), 'eval/episode_reward/angle_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/centered_std': Array(39.684, dtype=float32), 'eval/episode_reward/small_control_std': Array(5.802, dtype=float32), 'eval/episode_reward/small_velocity_std': Array(58.9, dtype=float32), 'eval/episode_reward/upright_std': Array(73.503, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 0.18618106842041016, 'eval/sps': 687502.7686003329}
[2025-07-07 10:44:13,568][absl][INFO] - starting iteration 1 56.19894504547119
[2025-07-07 10:44:27,380][absl][INFO] - {'eval/walltime': 13.989440679550171, 'training/sps': np.float64(505265.12185536703), 'training/walltime': 43.854327917099, 'training/entropy_loss': Array(-0., dtype=float32), 'training/policy_loss': Array(-0.027, dtype=float32), 'training/total_loss': Array(114.046, dtype=float32), 'training/v_loss': Array(114.073, dtype=float32), 'eval/episode_reward': Array(995.977, dtype=float32), 'eval/episode_reward/angle_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/centered': Array(999.805, dtype=float32), 'eval/episode_reward/small_control': Array(996.227, dtype=float32), 'eval/episode_reward/small_velocity': Array(999.95, dtype=float32), 'eval/episode_reward/upright': Array(999.998, dtype=float32), 'eval/episode_reward_std': Array(0.283, dtype=float32), 'eval/episode_reward/angle_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/centered_std': Array(0.19, dtype=float32), 'eval/episode_reward/small_control_std': Array(0.173, dtype=float32), 'eval/episode_reward/small_velocity_std': Array(0.011, dtype=float32), 'eval/episode_reward/upright_std': Array(0.001, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 0.17162251472473145, 'eval/sps': 745822.8904599235}
[2025-07-07 10:44:27,395][absl][INFO] - starting iteration 2 70.02564144134521
[2025-07-07 10:44:40,913][absl][INFO] - {'eval/walltime': 14.170387983322144, 'training/sps': np.float64(516705.00925782725), 'training/walltime': 57.17194604873657, 'training/entropy_loss': Array(0.013, dtype=float32), 'training/policy_loss': Array(-0.011, dtype=float32), 'training/total_loss': Array(0.031, dtype=float32), 'training/v_loss': Array(0.029, dtype=float32), 'eval/episode_reward': Array(998.938, dtype=float32), 'eval/episode_reward/angle_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/centered': Array(999.513, dtype=float32), 'eval/episode_reward/small_control': Array(999.438, dtype=float32), 'eval/episode_reward/small_velocity': Array(999.991, dtype=float32), 'eval/episode_reward/upright': Array(999.999, dtype=float32), 'eval/episode_reward_std': Array(0.195, dtype=float32), 'eval/episode_reward/angle_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/centered_std': Array(0.179, dtype=float32), 'eval/episode_reward/small_control_std': Array(0.042, dtype=float32), 'eval/episode_reward/small_velocity_std': Array(0.007, dtype=float32), 'eval/episode_reward/upright_std': Array(0.001, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 0.18094730377197266, 'eval/sps': 707388.2690250188}
[2025-07-07 10:44:40,919][absl][INFO] - starting iteration 3 83.54955577850342
[2025-07-07 10:44:54,520][absl][INFO] - {'eval/walltime': 14.351708889007568, 'training/sps': np.float64(513146.57837040053), 'training/walltime': 70.58191561698914, 'training/entropy_loss': Array(0.019, dtype=float32), 'training/policy_loss': Array(-0., dtype=float32), 'training/total_loss': Array(0.046, dtype=float32), 'training/v_loss': Array(0.027, dtype=float32), 'eval/episode_reward': Array(999.318, dtype=float32), 'eval/episode_reward/angle_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/centered': Array(999.601, dtype=float32), 'eval/episode_reward/small_control': Array(999.728, dtype=float32), 'eval/episode_reward/small_velocity': Array(999.994, dtype=float32), 'eval/episode_reward/upright': Array(999.999, dtype=float32), 'eval/episode_reward_std': Array(0.45, dtype=float32), 'eval/episode_reward/angle_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/centered_std': Array(0.421, dtype=float32), 'eval/episode_reward/small_control_std': Array(0.033, dtype=float32), 'eval/episode_reward/small_velocity_std': Array(0.005, dtype=float32), 'eval/episode_reward/upright_std': Array(0.001, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 0.1813209056854248, 'eval/sps': 705930.7337790839}
[2025-07-07 10:44:54,527][absl][INFO] - starting iteration 4 97.1575858592987
[2025-07-07 10:45:08,113][absl][INFO] - {'eval/walltime': 14.529025554656982, 'training/sps': np.float64(513648.0852245447), 'training/walltime': 83.97879219055176, 'training/entropy_loss': Array(0.022, dtype=float32), 'training/policy_loss': Array(0., dtype=float32), 'training/total_loss': Array(0.044, dtype=float32), 'training/v_loss': Array(0.022, dtype=float32), 'eval/episode_reward': Array(999.542, dtype=float32), 'eval/episode_reward/angle_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/centered': Array(999.711, dtype=float32), 'eval/episode_reward/small_control': Array(999.843, dtype=float32), 'eval/episode_reward/small_velocity': Array(999.993, dtype=float32), 'eval/episode_reward/upright': Array(999.998, dtype=float32), 'eval/episode_reward_std': Array(0.346, dtype=float32), 'eval/episode_reward/angle_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/centered_std': Array(0.324, dtype=float32), 'eval/episode_reward/small_control_std': Array(0.023, dtype=float32), 'eval/episode_reward/small_velocity_std': Array(0.006, dtype=float32), 'eval/episode_reward/upright_std': Array(0.002, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 0.17731666564941406, 'eval/sps': 721872.3605658043}
[2025-07-07 10:45:08,123][absl][INFO] - starting iteration 5 110.75302910804749
[2025-07-07 10:45:21,893][absl][INFO] - {'eval/walltime': 14.712270021438599, 'training/sps': np.float64(506942.1987826297), 'training/walltime': 97.55288410186768, 'training/entropy_loss': Array(0.024, dtype=float32), 'training/policy_loss': Array(0.001, dtype=float32), 'training/total_loss': Array(0.04, dtype=float32), 'training/v_loss': Array(0.015, dtype=float32), 'eval/episode_reward': Array(999.621, dtype=float32), 'eval/episode_reward/angle_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/centered': Array(999.743, dtype=float32), 'eval/episode_reward/small_control': Array(999.888, dtype=float32), 'eval/episode_reward/small_velocity': Array(999.994, dtype=float32), 'eval/episode_reward/upright': Array(999.998, dtype=float32), 'eval/episode_reward_std': Array(0.306, dtype=float32), 'eval/episode_reward/angle_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/centered_std': Array(0.285, dtype=float32), 'eval/episode_reward/small_control_std': Array(0.021, dtype=float32), 'eval/episode_reward/small_velocity_std': Array(0.006, dtype=float32), 'eval/episode_reward/upright_std': Array(0.002, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 0.1832444667816162, 'eval/sps': 698520.4096369552}
[2025-07-07 10:45:21,907][absl][INFO] - starting iteration 6 124.53765177726746
[2025-07-07 10:45:36,076][absl][INFO] - {'eval/walltime': 14.898519277572632, 'training/sps': np.float64(492764.375675259), 'training/walltime': 111.51752996444702, 'training/entropy_loss': Array(0.026, dtype=float32), 'training/policy_loss': Array(0., dtype=float32), 'training/total_loss': Array(0.038, dtype=float32), 'training/v_loss': Array(0.012, dtype=float32), 'eval/episode_reward': Array(999.645, dtype=float32), 'eval/episode_reward/angle_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/centered': Array(999.743, dtype=float32), 'eval/episode_reward/small_control': Array(999.916, dtype=float32), 'eval/episode_reward/small_velocity': Array(999.994, dtype=float32), 'eval/episode_reward/upright': Array(999.997, dtype=float32), 'eval/episode_reward_std': Array(0.298, dtype=float32), 'eval/episode_reward/angle_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/centered_std': Array(0.284, dtype=float32), 'eval/episode_reward/small_control_std': Array(0.014, dtype=float32), 'eval/episode_reward/small_velocity_std': Array(0.005, dtype=float32), 'eval/episode_reward/upright_std': Array(0.002, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 0.1862492561340332, 'eval/sps': 687251.066967406}
[2025-07-07 10:45:36,084][absl][INFO] - starting iteration 7 138.71440601348877
[2025-07-07 10:45:50,251][absl][INFO] - {'eval/walltime': 15.074322700500488, 'training/sps': np.float64(492248.0074862435), 'training/walltime': 125.49682474136353, 'training/entropy_loss': Array(0.023, dtype=float32), 'training/policy_loss': Array(0.009, dtype=float32), 'training/total_loss': Array(328.636, dtype=float32), 'training/v_loss': Array(328.603, dtype=float32), 'eval/episode_reward': Array(440.327, dtype=float32), 'eval/episode_reward/angle_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/centered': Array(835.267, dtype=float32), 'eval/episode_reward/small_control': Array(888.225, dtype=float32), 'eval/episode_reward/small_velocity': Array(721.741, dtype=float32), 'eval/episode_reward/upright': Array(682.198, dtype=float32), 'eval/episode_reward_std': Array(143.453, dtype=float32), 'eval/episode_reward/angle_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/centered_std': Array(57.266, dtype=float32), 'eval/episode_reward/small_control_std': Array(24.614, dtype=float32), 'eval/episode_reward/small_velocity_std': Array(89.923, dtype=float32), 'eval/episode_reward/upright_std': Array(115.141, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 0.17580342292785645, 'eval/sps': 728085.9375105951}
[2025-07-07 10:45:50,264][absl][INFO] - starting iteration 8 152.89408612251282
[2025-07-07 10:46:04,689][absl][INFO] - {'eval/walltime': 15.265300989151001, 'training/sps': np.float64(484093.63047526655), 'training/walltime': 139.71159553527832, 'training/entropy_loss': Array(0.007, dtype=float32), 'training/policy_loss': Array(-0.024, dtype=float32), 'training/total_loss': Array(224.752, dtype=float32), 'training/v_loss': Array(224.769, dtype=float32), 'eval/episode_reward': Array(992.737, dtype=float32), 'eval/episode_reward/angle_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/centered': Array(996.216, dtype=float32), 'eval/episode_reward/small_control': Array(996.571, dtype=float32), 'eval/episode_reward/small_velocity': Array(999.944, dtype=float32), 'eval/episode_reward/upright': Array(999.996, dtype=float32), 'eval/episode_reward_std': Array(0.396, dtype=float32), 'eval/episode_reward/angle_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/centered_std': Array(0.212, dtype=float32), 'eval/episode_reward/small_control_std': Array(0.428, dtype=float32), 'eval/episode_reward/small_velocity_std': Array(0.029, dtype=float32), 'eval/episode_reward/upright_std': Array(0.003, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 0.1909782886505127, 'eval/sps': 670233.2548085506}
[2025-07-07 10:46:05,652][absl][INFO] - total steps: 61931520
