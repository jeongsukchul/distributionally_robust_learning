[2025-07-07 10:52:17,596][jax._src.xla_bridge][INFO] - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
[2025-07-07 10:52:17,768][root][INFO] - Using JAX default device: cuda:0.
[2025-07-07 10:52:17,769][root][INFO] - MJX Warp is disabled via MJX_WARP_ENABLED=false.
[2025-07-07 10:52:18,071][absl][INFO] - Device count: 1, process count: 1 (id 0), local device count: 1, devices to be used count: 1
[2025-07-07 10:52:19,221][root][INFO] - Using JAX default device: cuda:0.
[2025-07-07 10:52:19,222][root][INFO] - MJX Warp is disabled via MJX_WARP_ENABLED=false.
[2025-07-07 10:52:59,304][root][INFO] - Using JAX default device: cuda:0.
[2025-07-07 10:52:59,305][root][INFO] - MJX Warp is disabled via MJX_WARP_ENABLED=false.
[2025-07-07 10:54:31,430][absl][INFO] - {'eval/walltime': 91.98755550384521, 'eval/episode_reward': Array(1.726, dtype=float32), 'eval/episode_reward/move': Array(191.442, dtype=float32), 'eval/episode_reward/small_control': Array(895.867, dtype=float32), 'eval/episode_reward/stand': Array(11.077, dtype=float32), 'eval/episode_reward/standing': Array(11.126, dtype=float32), 'eval/episode_reward/upright': Array(610.897, dtype=float32), 'eval/episode_reward_std': Array(0.155, dtype=float32), 'eval/episode_reward/move_std': Array(1.787, dtype=float32), 'eval/episode_reward/small_control_std': Array(1.665, dtype=float32), 'eval/episode_reward/stand_std': Array(0.695, dtype=float32), 'eval/episode_reward/standing_std': Array(0.698, dtype=float32), 'eval/episode_reward/upright_std': Array(64.62, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 91.98755550384521, 'eval/sps': 1391.4925698253762}
[2025-07-07 10:54:31,438][absl][INFO] - starting iteration 0 133.36639833450317
[2025-07-07 10:57:03,585][absl][INFO] - {'eval/walltime': 99.91562700271606, 'training/sps': np.float64(47902.52080972042), 'training/walltime': 143.65173029899597, 'training/entropy_loss': Array(nan, dtype=float32), 'training/policy_loss': Array(nan, dtype=float32), 'training/total_loss': Array(nan, dtype=float32), 'training/v_loss': Array(nan, dtype=float32), 'eval/episode_reward': Array(nan, dtype=float32), 'eval/episode_reward/move': Array(0.167, dtype=float32), 'eval/episode_reward/small_control': Array(0.8, dtype=float32), 'eval/episode_reward/stand': Array(nan, dtype=float32), 'eval/episode_reward/standing': Array(nan, dtype=float32), 'eval/episode_reward/upright': Array(0., dtype=float32), 'eval/episode_reward_std': Array(nan, dtype=float32), 'eval/episode_reward/move_std': Array(0., dtype=float32), 'eval/episode_reward/small_control_std': Array(0., dtype=float32), 'eval/episode_reward/stand_std': Array(nan, dtype=float32), 'eval/episode_reward/standing_std': Array(nan, dtype=float32), 'eval/episode_reward/upright_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 7.92807149887085, 'eval/sps': 16145.162164371288}
[2025-07-07 10:57:03,600][absl][INFO] - starting iteration 1 285.5280923843384
[2025-07-07 10:58:26,509][absl][INFO] - {'eval/walltime': 107.74986386299133, 'training/sps': np.float64(91680.65459997919), 'training/walltime': 218.7087860107422, 'training/entropy_loss': Array(nan, dtype=float32), 'training/policy_loss': Array(nan, dtype=float32), 'training/total_loss': Array(nan, dtype=float32), 'training/v_loss': Array(nan, dtype=float32), 'eval/episode_reward': Array(nan, dtype=float32), 'eval/episode_reward/move': Array(0.167, dtype=float32), 'eval/episode_reward/small_control': Array(0.8, dtype=float32), 'eval/episode_reward/stand': Array(nan, dtype=float32), 'eval/episode_reward/standing': Array(nan, dtype=float32), 'eval/episode_reward/upright': Array(0., dtype=float32), 'eval/episode_reward_std': Array(nan, dtype=float32), 'eval/episode_reward/move_std': Array(0., dtype=float32), 'eval/episode_reward/small_control_std': Array(0., dtype=float32), 'eval/episode_reward/stand_std': Array(nan, dtype=float32), 'eval/episode_reward/standing_std': Array(nan, dtype=float32), 'eval/episode_reward/upright_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 7.8342368602752686, 'eval/sps': 16338.54098145081}
[2025-07-07 10:58:26,515][absl][INFO] - starting iteration 2 368.4435365200043
[2025-07-07 10:59:48,675][absl][INFO] - {'eval/walltime': 115.6474871635437, 'training/sps': np.float64(92675.32670407803), 'training/walltime': 292.9602642059326, 'training/entropy_loss': Array(nan, dtype=float32), 'training/policy_loss': Array(nan, dtype=float32), 'training/total_loss': Array(nan, dtype=float32), 'training/v_loss': Array(nan, dtype=float32), 'eval/episode_reward': Array(nan, dtype=float32), 'eval/episode_reward/move': Array(0.167, dtype=float32), 'eval/episode_reward/small_control': Array(0.8, dtype=float32), 'eval/episode_reward/stand': Array(nan, dtype=float32), 'eval/episode_reward/standing': Array(nan, dtype=float32), 'eval/episode_reward/upright': Array(0., dtype=float32), 'eval/episode_reward_std': Array(nan, dtype=float32), 'eval/episode_reward/move_std': Array(0., dtype=float32), 'eval/episode_reward/small_control_std': Array(0., dtype=float32), 'eval/episode_reward/stand_std': Array(nan, dtype=float32), 'eval/episode_reward/standing_std': Array(nan, dtype=float32), 'eval/episode_reward/upright_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 7.897623300552368, 'eval/sps': 16207.407612242983}
[2025-07-07 10:59:48,682][absl][INFO] - starting iteration 3 450.610417842865
[2025-07-07 11:01:10,970][absl][INFO] - {'eval/walltime': 123.46341252326965, 'training/sps': np.float64(92422.47141467374), 'training/walltime': 367.41488432884216, 'training/entropy_loss': Array(nan, dtype=float32), 'training/policy_loss': Array(nan, dtype=float32), 'training/total_loss': Array(nan, dtype=float32), 'training/v_loss': Array(nan, dtype=float32), 'eval/episode_reward': Array(nan, dtype=float32), 'eval/episode_reward/move': Array(0.167, dtype=float32), 'eval/episode_reward/small_control': Array(0.8, dtype=float32), 'eval/episode_reward/stand': Array(nan, dtype=float32), 'eval/episode_reward/standing': Array(nan, dtype=float32), 'eval/episode_reward/upright': Array(0., dtype=float32), 'eval/episode_reward_std': Array(nan, dtype=float32), 'eval/episode_reward/move_std': Array(0., dtype=float32), 'eval/episode_reward/small_control_std': Array(0., dtype=float32), 'eval/episode_reward/stand_std': Array(nan, dtype=float32), 'eval/episode_reward/standing_std': Array(nan, dtype=float32), 'eval/episode_reward/upright_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 7.815925359725952, 'eval/sps': 16376.81964819685}
[2025-07-07 11:01:10,984][absl][INFO] - starting iteration 4 532.9121644496918
[2025-07-07 11:02:34,633][absl][INFO] - {'eval/walltime': 131.98009824752808, 'training/sps': np.float64(91611.92705415229), 'training/walltime': 442.52824807167053, 'training/entropy_loss': Array(nan, dtype=float32), 'training/policy_loss': Array(nan, dtype=float32), 'training/total_loss': Array(nan, dtype=float32), 'training/v_loss': Array(nan, dtype=float32), 'eval/episode_reward': Array(nan, dtype=float32), 'eval/episode_reward/move': Array(0.167, dtype=float32), 'eval/episode_reward/small_control': Array(0.8, dtype=float32), 'eval/episode_reward/stand': Array(nan, dtype=float32), 'eval/episode_reward/standing': Array(nan, dtype=float32), 'eval/episode_reward/upright': Array(0., dtype=float32), 'eval/episode_reward_std': Array(nan, dtype=float32), 'eval/episode_reward/move_std': Array(0., dtype=float32), 'eval/episode_reward/small_control_std': Array(0., dtype=float32), 'eval/episode_reward/stand_std': Array(nan, dtype=float32), 'eval/episode_reward/standing_std': Array(nan, dtype=float32), 'eval/episode_reward/upright_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 8.516685724258423, 'eval/sps': 15029.320576596174}
[2025-07-07 11:02:34,639][absl][INFO] - starting iteration 5 616.5673720836639
