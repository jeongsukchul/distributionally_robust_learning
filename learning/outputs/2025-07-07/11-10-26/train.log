[2025-07-07 11:10:28,494][jax._src.xla_bridge][INFO] - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
[2025-07-07 11:10:28,682][root][INFO] - Using JAX default device: cuda:0.
[2025-07-07 11:10:28,682][root][INFO] - MJX Warp is disabled via MJX_WARP_ENABLED=false.
[2025-07-07 11:10:28,916][absl][INFO] - local_device_count: 1; total_device_count: 1
[2025-07-07 11:10:29,296][root][INFO] - Using JAX default device: cuda:0.
[2025-07-07 11:10:29,297][root][INFO] - MJX Warp is disabled via MJX_WARP_ENABLED=false.
[2025-07-07 11:10:35,297][root][INFO] - Using JAX default device: cuda:0.
[2025-07-07 11:10:35,297][root][INFO] - MJX Warp is disabled via MJX_WARP_ENABLED=false.
[2025-07-07 11:10:56,265][root][INFO] - Using JAX default device: cuda:0.
[2025-07-07 11:10:56,265][root][INFO] - MJX Warp is disabled via MJX_WARP_ENABLED=false.
[2025-07-07 11:11:42,732][absl][INFO] - {'eval/walltime': 46.31942844390869, 'eval/episode_reward': Array(0.049, dtype=float32), 'eval/episode_reward/hopping': Array(43.843, dtype=float32), 'eval/episode_reward/standing': Array(1.344, dtype=float32), 'eval/episode_reward_std': Array(0.308, dtype=float32), 'eval/episode_reward/hopping_std': Array(13.87, dtype=float32), 'eval/episode_reward/standing_std': Array(3.817, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 46.31942844390869, 'eval/sps': 2763.4192454469467}
[2025-07-07 11:12:05,894][absl][INFO] - replay size after prefill 8192
[2025-07-07 11:12:05,945][absl][INFO] - step 0
[2025-07-07 11:13:07,684][absl][INFO] - {'eval/walltime': 49.99871826171875, 'training/sps': 9558.04674959125, 'training/walltime': 81.24696350097656, 'training/actor_loss': Array(-23.946, dtype=float32), 'training/alpha': Array(0.117, dtype=float32), 'training/alpha_loss': Array(0.553, dtype=float32), 'training/buffer_current_size': Array(285632., dtype=float32), 'training/critic_loss': Array(0.006, dtype=float32), 'eval/episode_reward': Array(1.275, dtype=float32), 'eval/episode_reward/hopping': Array(20.688, dtype=float32), 'eval/episode_reward/standing': Array(6.5, dtype=float32), 'eval/episode_reward_std': Array(3.789, dtype=float32), 'eval/episode_reward/hopping_std': Array(7.987, dtype=float32), 'eval/episode_reward/standing_std': Array(15.054, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 3.6792898178100586, 'eval/sps': 34789.32248837809}
[2025-07-07 11:13:07,689][absl][INFO] - step 562944
[2025-07-07 11:13:38,049][absl][INFO] - {'eval/walltime': 53.622517108917236, 'training/sps': 20752.74958593476, 'training/walltime': 107.9784574508667, 'training/actor_loss': Array(-6.748, dtype=float32), 'training/alpha': Array(0.001, dtype=float32), 'training/alpha_loss': Array(-0., dtype=float32), 'training/buffer_current_size': Array(840383.94, dtype=float32), 'training/critic_loss': Array(0.002, dtype=float32), 'eval/episode_reward': Array(30.675, dtype=float32), 'eval/episode_reward/hopping': Array(85.803, dtype=float32), 'eval/episode_reward/standing': Array(141.43, dtype=float32), 'eval/episode_reward_std': Array(41.84, dtype=float32), 'eval/episode_reward/hopping_std': Array(83.868, dtype=float32), 'eval/episode_reward/standing_std': Array(191.961, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 3.6237988471984863, 'eval/sps': 35322.04887667957}
[2025-07-07 11:13:38,054][absl][INFO] - step 1117696
[2025-07-07 11:14:08,500][absl][INFO] - {'eval/walltime': 57.26041793823242, 'training/sps': 20697.815094705107, 'training/walltime': 134.78090000152588, 'training/actor_loss': Array(-3.512, dtype=float32), 'training/alpha': Array(0.001, dtype=float32), 'training/alpha_loss': Array(-0., dtype=float32), 'training/buffer_current_size': Array(1.395e+06, dtype=float32), 'training/critic_loss': Array(0.002, dtype=float32), 'eval/episode_reward': Array(59.052, dtype=float32), 'eval/episode_reward/hopping': Array(96.167, dtype=float32), 'eval/episode_reward/standing': Array(248.641, dtype=float32), 'eval/episode_reward_std': Array(64.955, dtype=float32), 'eval/episode_reward/hopping_std': Array(93.706, dtype=float32), 'eval/episode_reward/standing_std': Array(271.598, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 3.6379008293151855, 'eval/sps': 35185.12625977638}
[2025-07-07 11:14:08,512][absl][INFO] - step 1672448
[2025-07-07 11:14:39,497][absl][INFO] - {'eval/walltime': 61.3230881690979, 'training/sps': 20610.127409234225, 'training/walltime': 161.69737601280212, 'training/actor_loss': Array(-4.201, dtype=float32), 'training/alpha': Array(0.001, dtype=float32), 'training/alpha_loss': Array(0., dtype=float32), 'training/buffer_current_size': Array(1.95e+06, dtype=float32), 'training/critic_loss': Array(0.002, dtype=float32), 'eval/episode_reward': Array(58.889, dtype=float32), 'eval/episode_reward/hopping': Array(102.494, dtype=float32), 'eval/episode_reward/standing': Array(220.438, dtype=float32), 'eval/episode_reward_std': Array(68.99, dtype=float32), 'eval/episode_reward/hopping_std': Array(99.719, dtype=float32), 'eval/episode_reward/standing_std': Array(256.412, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 4.0626702308654785, 'eval/sps': 31506.372096740895}
[2025-07-07 11:14:39,503][absl][INFO] - step 2227200
[2025-07-07 11:15:09,943][absl][INFO] - {'eval/walltime': 64.92634534835815, 'training/sps': 20675.182806682005, 'training/walltime': 188.52915811538696, 'training/actor_loss': Array(-5.017, dtype=float32), 'training/alpha': Array(0.001, dtype=float32), 'training/alpha_loss': Array(-0., dtype=float32), 'training/buffer_current_size': Array(2.505e+06, dtype=float32), 'training/critic_loss': Array(0.002, dtype=float32), 'eval/episode_reward': Array(78.909, dtype=float32), 'eval/episode_reward/hopping': Array(142.589, dtype=float32), 'eval/episode_reward/standing': Array(264.68, dtype=float32), 'eval/episode_reward_std': Array(77.747, dtype=float32), 'eval/episode_reward/hopping_std': Array(125.579, dtype=float32), 'eval/episode_reward/standing_std': Array(258.577, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 3.603257179260254, 'eval/sps': 35523.4149637574}
[2025-07-07 11:15:09,948][absl][INFO] - step 2781952
[2025-07-07 11:15:40,639][absl][INFO] - {'eval/walltime': 68.71191954612732, 'training/sps': 20622.89470701835, 'training/walltime': 215.42897057533264, 'training/actor_loss': Array(-5.745, dtype=float32), 'training/alpha': Array(0.001, dtype=float32), 'training/alpha_loss': Array(-0., dtype=float32), 'training/buffer_current_size': Array(3.059e+06, dtype=float32), 'training/critic_loss': Array(0.003, dtype=float32), 'eval/episode_reward': Array(78.607, dtype=float32), 'eval/episode_reward/hopping': Array(144.858, dtype=float32), 'eval/episode_reward/standing': Array(244.414, dtype=float32), 'eval/episode_reward_std': Array(83.765, dtype=float32), 'eval/episode_reward/hopping_std': Array(140.148, dtype=float32), 'eval/episode_reward/standing_std': Array(258.961, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 3.785574197769165, 'eval/sps': 33812.57196739936}
[2025-07-07 11:15:40,650][absl][INFO] - step 3336704
[2025-07-07 11:16:11,550][absl][INFO] - {'eval/walltime': 72.4956226348877, 'training/sps': 20463.35953141023, 'training/walltime': 242.5384976863861, 'training/actor_loss': Array(-6.476, dtype=float32), 'training/alpha': Array(0.001, dtype=float32), 'training/alpha_loss': Array(-0., dtype=float32), 'training/buffer_current_size': Array(3.614e+06, dtype=float32), 'training/critic_loss': Array(0.004, dtype=float32), 'eval/episode_reward': Array(109.577, dtype=float32), 'eval/episode_reward/hopping': Array(193.411, dtype=float32), 'eval/episode_reward/standing': Array(318.375, dtype=float32), 'eval/episode_reward_std': Array(89.224, dtype=float32), 'eval/episode_reward/hopping_std': Array(150.274, dtype=float32), 'eval/episode_reward/standing_std': Array(255.654, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 3.783703088760376, 'eval/sps': 33829.292890403725}
[2025-07-07 11:16:11,561][absl][INFO] - step 3891456
[2025-07-07 11:16:49,041][absl][INFO] - {'eval/walltime': 76.25210571289062, 'training/sps': 16453.443299615257, 'training/walltime': 276.2549660205841, 'training/actor_loss': Array(-7.537, dtype=float32), 'training/alpha': Array(0.003, dtype=float32), 'training/alpha_loss': Array(-0., dtype=float32), 'training/buffer_current_size': Array(4.112e+06, dtype=float32), 'training/critic_loss': Array(0.008, dtype=float32), 'eval/episode_reward': Array(169.589, dtype=float32), 'eval/episode_reward/hopping': Array(313.648, dtype=float32), 'eval/episode_reward/standing': Array(484.844, dtype=float32), 'eval/episode_reward_std': Array(34.811, dtype=float32), 'eval/episode_reward/hopping_std': Array(61.61, dtype=float32), 'eval/episode_reward/standing_std': Array(99.83, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 3.7564830780029297, 'eval/sps': 34074.42475903526}
[2025-07-07 11:16:49,046][absl][INFO] - step 4446208
[2025-07-07 11:17:34,219][absl][INFO] - {'eval/walltime': 79.98113226890564, 'training/sps': 13387.286020673899, 'training/walltime': 317.69368624687195, 'training/actor_loss': Array(-11.766, dtype=float32), 'training/alpha': Array(0.006, dtype=float32), 'training/alpha_loss': Array(0., dtype=float32), 'training/buffer_current_size': Array(4.194e+06, dtype=float32), 'training/critic_loss': Array(0.007, dtype=float32), 'eval/episode_reward': Array(211.692, dtype=float32), 'eval/episode_reward/hopping': Array(379.072, dtype=float32), 'eval/episode_reward/standing': Array(516.414, dtype=float32), 'eval/episode_reward_std': Array(5.95, dtype=float32), 'eval/episode_reward/hopping_std': Array(9.268, dtype=float32), 'eval/episode_reward/standing_std': Array(14.485, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 3.7290265560150146, 'eval/sps': 34325.312002279185}
[2025-07-07 11:17:35,692][absl][INFO] - total steps: 5000960
