[2025-07-07 12:22:56,648][jax._src.xla_bridge][INFO] - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
[2025-07-07 12:22:56,800][root][INFO] - Using JAX default device: cuda:0.
[2025-07-07 12:22:56,800][root][INFO] - MJX Warp is disabled via MJX_WARP_ENABLED=false.
[2025-07-07 12:22:57,062][absl][INFO] - local_device_count: 1; total_device_count: 1
[2025-07-07 12:22:57,387][root][INFO] - Using JAX default device: cuda:0.
[2025-07-07 12:22:57,388][root][INFO] - MJX Warp is disabled via MJX_WARP_ENABLED=false.
[2025-07-07 12:23:04,068][root][INFO] - Using JAX default device: cuda:0.
[2025-07-07 12:23:04,068][root][INFO] - MJX Warp is disabled via MJX_WARP_ENABLED=false.
[2025-07-07 12:23:34,361][root][INFO] - Using JAX default device: cuda:0.
[2025-07-07 12:23:34,361][root][INFO] - MJX Warp is disabled via MJX_WARP_ENABLED=false.
[2025-07-07 12:25:01,878][absl][INFO] - {'eval/walltime': 87.38008213043213, 'eval/episode_reward': Array(nan, dtype=float32), 'eval/episode_reward/move': Array(179.269, dtype=float32), 'eval/episode_reward/small_control': Array(748.312, dtype=float32), 'eval/episode_reward/stand': Array(nan, dtype=float32), 'eval/episode_reward/standing': Array(nan, dtype=float32), 'eval/episode_reward/upright': Array(521.963, dtype=float32), 'eval/episode_reward_std': Array(nan, dtype=float32), 'eval/episode_reward/move_std': Array(52.134, dtype=float32), 'eval/episode_reward/small_control_std': Array(219.063, dtype=float32), 'eval/episode_reward/stand_std': Array(nan, dtype=float32), 'eval/episode_reward/standing_std': Array(nan, dtype=float32), 'eval/episode_reward/upright_std': Array(153.635, dtype=float32), 'eval/avg_episode_length': Array(887.742, dtype=float32), 'eval/std_episode_length': Array(259.965, dtype=float32), 'eval/epoch_eval_time': 87.38008213043213, 'eval/sps': 1464.8647252234734}
[2025-07-07 12:25:48,797][absl][INFO] - replay size after prefill 8192
[2025-07-07 12:25:48,865][absl][INFO] - step 0
[2025-07-07 12:27:36,035][absl][INFO] - {'eval/walltime': 94.98134970664978, 'training/sps': 5572.645962223754, 'training/walltime': 146.5285370349884, 'training/actor_loss': Array(nan, dtype=float32), 'training/alpha': Array(nan, dtype=float32), 'training/alpha_loss': Array(nan, dtype=float32), 'training/buffer_current_size': Array(285632., dtype=float32), 'training/critic_loss': Array(nan, dtype=float32), 'eval/episode_reward': Array(nan, dtype=float32), 'eval/episode_reward/move': Array(0.167, dtype=float32), 'eval/episode_reward/small_control': Array(0.8, dtype=float32), 'eval/episode_reward/stand': Array(nan, dtype=float32), 'eval/episode_reward/standing': Array(nan, dtype=float32), 'eval/episode_reward/upright': Array(0., dtype=float32), 'eval/episode_reward_std': Array(nan, dtype=float32), 'eval/episode_reward/move_std': Array(0., dtype=float32), 'eval/episode_reward/small_control_std': Array(0., dtype=float32), 'eval/episode_reward/stand_std': Array(nan, dtype=float32), 'eval/episode_reward/standing_std': Array(nan, dtype=float32), 'eval/episode_reward/upright_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 7.601267576217651, 'eval/sps': 16839.29669841883}
[2025-07-07 12:27:36,042][absl][INFO] - step 562944
[2025-07-07 12:28:28,111][absl][INFO] - {'eval/walltime': 102.54538011550903, 'training/sps': 12466.428583204928, 'training/walltime': 191.02821040153503, 'training/actor_loss': Array(nan, dtype=float32), 'training/alpha': Array(nan, dtype=float32), 'training/alpha_loss': Array(nan, dtype=float32), 'training/buffer_current_size': Array(840383.94, dtype=float32), 'training/critic_loss': Array(nan, dtype=float32), 'eval/episode_reward': Array(nan, dtype=float32), 'eval/episode_reward/move': Array(0.167, dtype=float32), 'eval/episode_reward/small_control': Array(0.8, dtype=float32), 'eval/episode_reward/stand': Array(nan, dtype=float32), 'eval/episode_reward/standing': Array(nan, dtype=float32), 'eval/episode_reward/upright': Array(0., dtype=float32), 'eval/episode_reward_std': Array(nan, dtype=float32), 'eval/episode_reward/move_std': Array(0., dtype=float32), 'eval/episode_reward/small_control_std': Array(0., dtype=float32), 'eval/episode_reward/stand_std': Array(nan, dtype=float32), 'eval/episode_reward/standing_std': Array(nan, dtype=float32), 'eval/episode_reward/upright_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 7.564030408859253, 'eval/sps': 16922.195321965126}
[2025-07-07 12:28:28,118][absl][INFO] - step 1117696
[2025-07-07 12:29:19,745][absl][INFO] - {'eval/walltime': 110.07583022117615, 'training/sps': 12582.05912204512, 'training/walltime': 235.11892676353455, 'training/actor_loss': Array(nan, dtype=float32), 'training/alpha': Array(nan, dtype=float32), 'training/alpha_loss': Array(nan, dtype=float32), 'training/buffer_current_size': Array(1.395e+06, dtype=float32), 'training/critic_loss': Array(nan, dtype=float32), 'eval/episode_reward': Array(nan, dtype=float32), 'eval/episode_reward/move': Array(0.167, dtype=float32), 'eval/episode_reward/small_control': Array(0.8, dtype=float32), 'eval/episode_reward/stand': Array(nan, dtype=float32), 'eval/episode_reward/standing': Array(nan, dtype=float32), 'eval/episode_reward/upright': Array(0., dtype=float32), 'eval/episode_reward_std': Array(nan, dtype=float32), 'eval/episode_reward/move_std': Array(0., dtype=float32), 'eval/episode_reward/small_control_std': Array(0., dtype=float32), 'eval/episode_reward/stand_std': Array(nan, dtype=float32), 'eval/episode_reward/standing_std': Array(nan, dtype=float32), 'eval/episode_reward/upright_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 7.530450105667114, 'eval/sps': 16997.655944054703}
[2025-07-07 12:29:19,751][absl][INFO] - step 1672448
[2025-07-07 12:30:11,309][absl][INFO] - {'eval/walltime': 117.61081004142761, 'training/sps': 12603.257662542288, 'training/walltime': 279.1354830265045, 'training/actor_loss': Array(nan, dtype=float32), 'training/alpha': Array(nan, dtype=float32), 'training/alpha_loss': Array(nan, dtype=float32), 'training/buffer_current_size': Array(1.95e+06, dtype=float32), 'training/critic_loss': Array(nan, dtype=float32), 'eval/episode_reward': Array(nan, dtype=float32), 'eval/episode_reward/move': Array(0.167, dtype=float32), 'eval/episode_reward/small_control': Array(0.8, dtype=float32), 'eval/episode_reward/stand': Array(nan, dtype=float32), 'eval/episode_reward/standing': Array(nan, dtype=float32), 'eval/episode_reward/upright': Array(0., dtype=float32), 'eval/episode_reward_std': Array(nan, dtype=float32), 'eval/episode_reward/move_std': Array(0., dtype=float32), 'eval/episode_reward/small_control_std': Array(0., dtype=float32), 'eval/episode_reward/stand_std': Array(nan, dtype=float32), 'eval/episode_reward/standing_std': Array(nan, dtype=float32), 'eval/episode_reward/upright_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 7.534979820251465, 'eval/sps': 16987.437664528246}
[2025-07-07 12:30:11,324][absl][INFO] - step 2227200
[2025-07-07 12:31:02,869][absl][INFO] - {'eval/walltime': 125.10875082015991, 'training/sps': 12596.320635635382, 'training/walltime': 323.1762800216675, 'training/actor_loss': Array(nan, dtype=float32), 'training/alpha': Array(nan, dtype=float32), 'training/alpha_loss': Array(nan, dtype=float32), 'training/buffer_current_size': Array(2.505e+06, dtype=float32), 'training/critic_loss': Array(nan, dtype=float32), 'eval/episode_reward': Array(nan, dtype=float32), 'eval/episode_reward/move': Array(0.167, dtype=float32), 'eval/episode_reward/small_control': Array(0.8, dtype=float32), 'eval/episode_reward/stand': Array(nan, dtype=float32), 'eval/episode_reward/standing': Array(nan, dtype=float32), 'eval/episode_reward/upright': Array(0., dtype=float32), 'eval/episode_reward_std': Array(nan, dtype=float32), 'eval/episode_reward/move_std': Array(0., dtype=float32), 'eval/episode_reward/small_control_std': Array(0., dtype=float32), 'eval/episode_reward/stand_std': Array(nan, dtype=float32), 'eval/episode_reward/standing_std': Array(nan, dtype=float32), 'eval/episode_reward/upright_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 7.4979407787323, 'eval/sps': 17071.353825982253}
[2025-07-07 12:31:02,876][absl][INFO] - step 2781952
[2025-07-07 12:31:54,605][absl][INFO] - {'eval/walltime': 132.6350383758545, 'training/sps': 12552.025733632598, 'training/walltime': 367.37249279022217, 'training/actor_loss': Array(nan, dtype=float32), 'training/alpha': Array(nan, dtype=float32), 'training/alpha_loss': Array(nan, dtype=float32), 'training/buffer_current_size': Array(3.059e+06, dtype=float32), 'training/critic_loss': Array(nan, dtype=float32), 'eval/episode_reward': Array(nan, dtype=float32), 'eval/episode_reward/move': Array(0.167, dtype=float32), 'eval/episode_reward/small_control': Array(0.8, dtype=float32), 'eval/episode_reward/stand': Array(nan, dtype=float32), 'eval/episode_reward/standing': Array(nan, dtype=float32), 'eval/episode_reward/upright': Array(0., dtype=float32), 'eval/episode_reward_std': Array(nan, dtype=float32), 'eval/episode_reward/move_std': Array(0., dtype=float32), 'eval/episode_reward/small_control_std': Array(0., dtype=float32), 'eval/episode_reward/stand_std': Array(nan, dtype=float32), 'eval/episode_reward/standing_std': Array(nan, dtype=float32), 'eval/episode_reward/upright_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 7.52628755569458, 'eval/sps': 17007.05680626725}
[2025-07-07 12:31:54,611][absl][INFO] - step 3336704
[2025-07-07 12:32:46,275][absl][INFO] - {'eval/walltime': 140.14102363586426, 'training/sps': 12564.52150244686, 'training/walltime': 411.52475118637085, 'training/actor_loss': Array(nan, dtype=float32), 'training/alpha': Array(nan, dtype=float32), 'training/alpha_loss': Array(nan, dtype=float32), 'training/buffer_current_size': Array(3.614e+06, dtype=float32), 'training/critic_loss': Array(nan, dtype=float32), 'eval/episode_reward': Array(nan, dtype=float32), 'eval/episode_reward/move': Array(0.167, dtype=float32), 'eval/episode_reward/small_control': Array(0.8, dtype=float32), 'eval/episode_reward/stand': Array(nan, dtype=float32), 'eval/episode_reward/standing': Array(nan, dtype=float32), 'eval/episode_reward/upright': Array(0., dtype=float32), 'eval/episode_reward_std': Array(nan, dtype=float32), 'eval/episode_reward/move_std': Array(0., dtype=float32), 'eval/episode_reward/small_control_std': Array(0., dtype=float32), 'eval/episode_reward/stand_std': Array(nan, dtype=float32), 'eval/episode_reward/standing_std': Array(nan, dtype=float32), 'eval/episode_reward/upright_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 7.505985260009766, 'eval/sps': 17053.057735398947}
[2025-07-07 12:32:46,281][absl][INFO] - step 3891456
[2025-07-07 12:34:03,016][absl][INFO] - {'eval/walltime': 147.68607926368713, 'training/sps': 8018.545433038842, 'training/walltime': 480.70837116241455, 'training/actor_loss': Array(nan, dtype=float32), 'training/alpha': Array(nan, dtype=float32), 'training/alpha_loss': Array(nan, dtype=float32), 'training/buffer_current_size': Array(4.112e+06, dtype=float32), 'training/critic_loss': Array(nan, dtype=float32), 'eval/episode_reward': Array(nan, dtype=float32), 'eval/episode_reward/move': Array(0.167, dtype=float32), 'eval/episode_reward/small_control': Array(0.8, dtype=float32), 'eval/episode_reward/stand': Array(nan, dtype=float32), 'eval/episode_reward/standing': Array(nan, dtype=float32), 'eval/episode_reward/upright': Array(0., dtype=float32), 'eval/episode_reward_std': Array(nan, dtype=float32), 'eval/episode_reward/move_std': Array(0., dtype=float32), 'eval/episode_reward/small_control_std': Array(0., dtype=float32), 'eval/episode_reward/stand_std': Array(nan, dtype=float32), 'eval/episode_reward/standing_std': Array(nan, dtype=float32), 'eval/episode_reward/upright_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 7.545055627822876, 'eval/sps': 16964.75232442181}
[2025-07-07 12:34:03,022][absl][INFO] - step 4446208
[2025-07-07 12:35:49,940][absl][INFO] - {'eval/walltime': 155.29354429244995, 'training/sps': 5586.399789752633, 'training/walltime': 580.0123989582062, 'training/actor_loss': Array(nan, dtype=float32), 'training/alpha': Array(nan, dtype=float32), 'training/alpha_loss': Array(nan, dtype=float32), 'training/buffer_current_size': Array(4.194e+06, dtype=float32), 'training/critic_loss': Array(nan, dtype=float32), 'eval/episode_reward': Array(nan, dtype=float32), 'eval/episode_reward/move': Array(0.167, dtype=float32), 'eval/episode_reward/small_control': Array(0.8, dtype=float32), 'eval/episode_reward/stand': Array(nan, dtype=float32), 'eval/episode_reward/standing': Array(nan, dtype=float32), 'eval/episode_reward/upright': Array(0., dtype=float32), 'eval/episode_reward_std': Array(nan, dtype=float32), 'eval/episode_reward/move_std': Array(0., dtype=float32), 'eval/episode_reward/small_control_std': Array(0., dtype=float32), 'eval/episode_reward/stand_std': Array(nan, dtype=float32), 'eval/episode_reward/standing_std': Array(nan, dtype=float32), 'eval/episode_reward/upright_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 7.607465028762817, 'eval/sps': 16825.578496391237}
