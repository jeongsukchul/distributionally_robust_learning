[2025-07-07 13:12:16,557][jax._src.xla_bridge][INFO] - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
[2025-07-07 13:12:16,702][root][INFO] - Using JAX default device: cuda:0.
[2025-07-07 13:12:16,703][root][INFO] - MJX Warp is disabled via MJX_WARP_ENABLED=false.
[2025-07-07 13:12:16,799][absl][INFO] - local_device_count: 1; total_device_count: 1
[2025-07-07 13:12:17,125][root][INFO] - Using JAX default device: cuda:0.
[2025-07-07 13:12:17,125][root][INFO] - MJX Warp is disabled via MJX_WARP_ENABLED=false.
[2025-07-07 13:12:22,124][root][INFO] - Using JAX default device: cuda:0.
[2025-07-07 13:12:22,125][root][INFO] - MJX Warp is disabled via MJX_WARP_ENABLED=false.
[2025-07-07 13:12:29,604][root][INFO] - Using JAX default device: cuda:0.
[2025-07-07 13:12:29,604][root][INFO] - MJX Warp is disabled via MJX_WARP_ENABLED=false.
[2025-07-07 13:12:43,554][absl][INFO] - {'eval/walltime': 13.80003547668457, 'eval/episode_reward': Array(150.641, dtype=float32), 'eval/episode_reward/angle_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/centered': Array(649.6, dtype=float32), 'eval/episode_reward/small_control': Array(849.234, dtype=float32), 'eval/episode_reward/small_velocity': Array(578.647, dtype=float32), 'eval/episode_reward/upright': Array(482.176, dtype=float32), 'eval/episode_reward_std': Array(15.348, dtype=float32), 'eval/episode_reward/angle_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/centered_std': Array(19.005, dtype=float32), 'eval/episode_reward/small_control_std': Array(9.627, dtype=float32), 'eval/episode_reward/small_velocity_std': Array(20.793, dtype=float32), 'eval/episode_reward/upright_std': Array(14.801, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 13.80003547668457, 'eval/sps': 9275.338474039325}
[2025-07-07 13:12:51,740][absl][INFO] - replay size after prefill 8192
[2025-07-07 13:12:51,785][absl][INFO] - step 0
[2025-07-07 13:13:17,469][absl][INFO] - {'eval/walltime': 13.966475486755371, 'training/sps': 21755.640049996862, 'training/walltime': 33.71790814399719, 'training/actor_loss': Array(-17.734, dtype=float32), 'training/alpha': Array(0.131, dtype=float32), 'training/alpha_loss': Array(0.132, dtype=float32), 'training/buffer_current_size': Array(285632., dtype=float32), 'training/critic_loss': Array(0.018, dtype=float32), 'eval/episode_reward': Array(662.884, dtype=float32), 'eval/episode_reward/angle_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/centered': Array(782.149, dtype=float32), 'eval/episode_reward/small_control': Array(963.634, dtype=float32), 'eval/episode_reward/small_velocity': Array(957.212, dtype=float32), 'eval/episode_reward/upright': Array(884.474, dtype=float32), 'eval/episode_reward_std': Array(4.527, dtype=float32), 'eval/episode_reward/angle_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/centered_std': Array(6.59, dtype=float32), 'eval/episode_reward/small_control_std': Array(2.227, dtype=float32), 'eval/episode_reward/small_velocity_std': Array(0.965, dtype=float32), 'eval/episode_reward/upright_std': Array(2.273, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 0.16644001007080078, 'eval/sps': 769045.8558945709}
[2025-07-07 13:13:17,477][absl][INFO] - step 562944
[2025-07-07 13:13:29,028][absl][INFO] - {'eval/walltime': 14.133050680160522, 'training/sps': 48752.37858890061, 'training/walltime': 45.09688115119934, 'training/actor_loss': Array(-50.284, dtype=float32), 'training/alpha': Array(0.035, dtype=float32), 'training/alpha_loss': Array(0., dtype=float32), 'training/buffer_current_size': Array(840383.94, dtype=float32), 'training/critic_loss': Array(0.04, dtype=float32), 'eval/episode_reward': Array(838.956, dtype=float32), 'eval/episode_reward/angle_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/centered': Array(950.909, dtype=float32), 'eval/episode_reward/small_control': Array(972.874, dtype=float32), 'eval/episode_reward/small_velocity': Array(957.447, dtype=float32), 'eval/episode_reward/upright': Array(886.659, dtype=float32), 'eval/episode_reward_std': Array(9.627, dtype=float32), 'eval/episode_reward/angle_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/centered_std': Array(7.677, dtype=float32), 'eval/episode_reward/small_control_std': Array(2.111, dtype=float32), 'eval/episode_reward/small_velocity_std': Array(0.762, dtype=float32), 'eval/episode_reward/upright_std': Array(0.649, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 0.16657519340515137, 'eval/sps': 768421.7402568033}
[2025-07-07 13:13:29,036][absl][INFO] - step 1117696
[2025-07-07 13:13:40,597][absl][INFO] - {'eval/walltime': 14.299201011657715, 'training/sps': 48706.860763978104, 'training/walltime': 56.48648810386658, 'training/actor_loss': Array(-69.575, dtype=float32), 'training/alpha': Array(0.026, dtype=float32), 'training/alpha_loss': Array(0., dtype=float32), 'training/buffer_current_size': Array(1.395e+06, dtype=float32), 'training/critic_loss': Array(0.022, dtype=float32), 'eval/episode_reward': Array(851.758, dtype=float32), 'eval/episode_reward/angle_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/centered': Array(958.792, dtype=float32), 'eval/episode_reward/small_control': Array(977.21, dtype=float32), 'eval/episode_reward/small_velocity': Array(956.304, dtype=float32), 'eval/episode_reward/upright': Array(887.372, dtype=float32), 'eval/episode_reward_std': Array(2.618, dtype=float32), 'eval/episode_reward/angle_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/centered_std': Array(1.939, dtype=float32), 'eval/episode_reward/small_control_std': Array(0.704, dtype=float32), 'eval/episode_reward/small_velocity_std': Array(0.481, dtype=float32), 'eval/episode_reward/upright_std': Array(0.534, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 0.16615033149719238, 'eval/sps': 770386.6663796753}
[2025-07-07 13:13:40,610][absl][INFO] - step 1672448
[2025-07-07 13:13:52,180][absl][INFO] - {'eval/walltime': 14.465245723724365, 'training/sps': 48674.99832087049, 'training/walltime': 67.8835506439209, 'training/actor_loss': Array(-77.134, dtype=float32), 'training/alpha': Array(0.021, dtype=float32), 'training/alpha_loss': Array(0., dtype=float32), 'training/buffer_current_size': Array(1.95e+06, dtype=float32), 'training/critic_loss': Array(0.016, dtype=float32), 'eval/episode_reward': Array(848.073, dtype=float32), 'eval/episode_reward/angle_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/centered': Array(954.172, dtype=float32), 'eval/episode_reward/small_control': Array(978.51, dtype=float32), 'eval/episode_reward/small_velocity': Array(956.184, dtype=float32), 'eval/episode_reward/upright': Array(887.344, dtype=float32), 'eval/episode_reward_std': Array(1.306, dtype=float32), 'eval/episode_reward/angle_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/centered_std': Array(0.74, dtype=float32), 'eval/episode_reward/small_control_std': Array(0.608, dtype=float32), 'eval/episode_reward/small_velocity_std': Array(0.518, dtype=float32), 'eval/episode_reward/upright_std': Array(0.492, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 0.1660447120666504, 'eval/sps': 770876.7018646204}
[2025-07-07 13:13:52,186][absl][INFO] - step 2227200
[2025-07-07 13:14:03,759][absl][INFO] - {'eval/walltime': 14.631640672683716, 'training/sps': 48665.286183414995, 'training/walltime': 79.28288769721985, 'training/actor_loss': Array(-80.956, dtype=float32), 'training/alpha': Array(0.018, dtype=float32), 'training/alpha_loss': Array(0., dtype=float32), 'training/buffer_current_size': Array(2.505e+06, dtype=float32), 'training/critic_loss': Array(0.011, dtype=float32), 'eval/episode_reward': Array(854.505, dtype=float32), 'eval/episode_reward/angle_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/centered': Array(958.657, dtype=float32), 'eval/episode_reward/small_control': Array(979.99, dtype=float32), 'eval/episode_reward/small_velocity': Array(957.075, dtype=float32), 'eval/episode_reward/upright': Array(887.967, dtype=float32), 'eval/episode_reward_std': Array(0.681, dtype=float32), 'eval/episode_reward/angle_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/centered_std': Array(0.459, dtype=float32), 'eval/episode_reward/small_control_std': Array(0.431, dtype=float32), 'eval/episode_reward/small_velocity_std': Array(0.46, dtype=float32), 'eval/episode_reward/upright_std': Array(0.392, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 0.16639494895935059, 'eval/sps': 769254.1197946443}
[2025-07-07 13:14:03,773][absl][INFO] - step 2781952
[2025-07-07 13:14:15,316][absl][INFO] - {'eval/walltime': 14.797600984573364, 'training/sps': 48784.37722751047, 'training/walltime': 90.65439701080322, 'training/actor_loss': Array(-83.439, dtype=float32), 'training/alpha': Array(0.017, dtype=float32), 'training/alpha_loss': Array(0., dtype=float32), 'training/buffer_current_size': Array(3.059e+06, dtype=float32), 'training/critic_loss': Array(0.01, dtype=float32), 'eval/episode_reward': Array(855.72, dtype=float32), 'eval/episode_reward/angle_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/centered': Array(959.681, dtype=float32), 'eval/episode_reward/small_control': Array(979.956, dtype=float32), 'eval/episode_reward/small_velocity': Array(957.106, dtype=float32), 'eval/episode_reward/upright': Array(888.191, dtype=float32), 'eval/episode_reward_std': Array(1.764, dtype=float32), 'eval/episode_reward/angle_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/centered_std': Array(1.857, dtype=float32), 'eval/episode_reward/small_control_std': Array(0.497, dtype=float32), 'eval/episode_reward/small_velocity_std': Array(0.533, dtype=float32), 'eval/episode_reward/upright_std': Array(0.444, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 0.16596031188964844, 'eval/sps': 771268.7361368103}
[2025-07-07 13:14:15,323][absl][INFO] - step 3336704
[2025-07-07 13:14:26,692][absl][INFO] - {'eval/walltime': 14.963581085205078, 'training/sps': 49540.546329180106, 'training/walltime': 101.85233569145203, 'training/actor_loss': Array(-84.944, dtype=float32), 'training/alpha': Array(0.016, dtype=float32), 'training/alpha_loss': Array(0., dtype=float32), 'training/buffer_current_size': Array(3.614e+06, dtype=float32), 'training/critic_loss': Array(0.009, dtype=float32), 'eval/episode_reward': Array(857.065, dtype=float32), 'eval/episode_reward/angle_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/centered': Array(959.532, dtype=float32), 'eval/episode_reward/small_control': Array(980.315, dtype=float32), 'eval/episode_reward/small_velocity': Array(957.395, dtype=float32), 'eval/episode_reward/upright': Array(889.086, dtype=float32), 'eval/episode_reward_std': Array(0.683, dtype=float32), 'eval/episode_reward/angle_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/centered_std': Array(0.836, dtype=float32), 'eval/episode_reward/small_control_std': Array(0.49, dtype=float32), 'eval/episode_reward/small_velocity_std': Array(0.422, dtype=float32), 'eval/episode_reward/upright_std': Array(0.405, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 0.16598010063171387, 'eval/sps': 771176.7827157408}
[2025-07-07 13:14:26,699][absl][INFO] - step 3891456
[2025-07-07 13:14:40,352][absl][INFO] - {'eval/walltime': 15.130728721618652, 'training/sps': 41154.92691817446, 'training/walltime': 115.33193683624268, 'training/actor_loss': Array(-86.527, dtype=float32), 'training/alpha': Array(0.014, dtype=float32), 'training/alpha_loss': Array(0., dtype=float32), 'training/buffer_current_size': Array(4.112e+06, dtype=float32), 'training/critic_loss': Array(0.007, dtype=float32), 'eval/episode_reward': Array(852.418, dtype=float32), 'eval/episode_reward/angle_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/centered': Array(953.092, dtype=float32), 'eval/episode_reward/small_control': Array(981.85, dtype=float32), 'eval/episode_reward/small_velocity': Array(958.13, dtype=float32), 'eval/episode_reward/upright': Array(889.339, dtype=float32), 'eval/episode_reward_std': Array(2.405, dtype=float32), 'eval/episode_reward/angle_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/centered_std': Array(2.692, dtype=float32), 'eval/episode_reward/small_control_std': Array(0.451, dtype=float32), 'eval/episode_reward/small_velocity_std': Array(0.474, dtype=float32), 'eval/episode_reward/upright_std': Array(0.381, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 0.16714763641357422, 'eval/sps': 765790.0688663581}
[2025-07-07 13:14:40,358][absl][INFO] - step 4446208
[2025-07-07 13:14:56,888][absl][INFO] - {'eval/walltime': 15.299388408660889, 'training/sps': 33920.648209126266, 'training/walltime': 131.68634128570557, 'training/actor_loss': Array(-91.078, dtype=float32), 'training/alpha': Array(0.011, dtype=float32), 'training/alpha_loss': Array(0., dtype=float32), 'training/buffer_current_size': Array(4.194e+06, dtype=float32), 'training/critic_loss': Array(0.001, dtype=float32), 'eval/episode_reward': Array(859.407, dtype=float32), 'eval/episode_reward/angle_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/centered': Array(959.203, dtype=float32), 'eval/episode_reward/small_control': Array(982.276, dtype=float32), 'eval/episode_reward/small_velocity': Array(958.822, dtype=float32), 'eval/episode_reward/upright': Array(889.394, dtype=float32), 'eval/episode_reward_std': Array(0.852, dtype=float32), 'eval/episode_reward/angle_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/centered_std': Array(1.091, dtype=float32), 'eval/episode_reward/small_control_std': Array(0.419, dtype=float32), 'eval/episode_reward/small_velocity_std': Array(0.49, dtype=float32), 'eval/episode_reward/upright_std': Array(0.381, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 0.16865968704223633, 'eval/sps': 758924.6858257587}
[2025-07-07 13:14:58,065][absl][INFO] - total steps: 5000960
