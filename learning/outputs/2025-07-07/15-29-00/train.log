[2025-07-07 15:29:01,897][jax._src.xla_bridge][INFO] - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
[2025-07-07 15:29:02,040][root][INFO] - Using JAX default device: cuda:0.
[2025-07-07 15:29:02,040][root][INFO] - MJX Warp is disabled via MJX_WARP_ENABLED=false.
[2025-07-07 15:29:02,243][absl][INFO] - local_device_count: 1; total_device_count: 1
[2025-07-07 15:29:02,552][root][INFO] - Using JAX default device: cuda:0.
[2025-07-07 15:29:02,552][root][INFO] - MJX Warp is disabled via MJX_WARP_ENABLED=false.
[2025-07-07 15:29:07,475][root][INFO] - Using JAX default device: cuda:0.
[2025-07-07 15:29:07,475][root][INFO] - MJX Warp is disabled via MJX_WARP_ENABLED=false.
[2025-07-07 15:29:15,208][root][INFO] - Using JAX default device: cuda:0.
[2025-07-07 15:29:15,209][root][INFO] - MJX Warp is disabled via MJX_WARP_ENABLED=false.
[2025-07-07 15:29:29,233][absl][INFO] - {'eval/walltime': 13.842458486557007, 'eval/episode_reward': Array(150.641, dtype=float32), 'eval/episode_reward/angle_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/centered': Array(649.6, dtype=float32), 'eval/episode_reward/small_control': Array(849.234, dtype=float32), 'eval/episode_reward/small_velocity': Array(578.647, dtype=float32), 'eval/episode_reward/upright': Array(482.176, dtype=float32), 'eval/episode_reward_std': Array(15.348, dtype=float32), 'eval/episode_reward/angle_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/centered_std': Array(19.005, dtype=float32), 'eval/episode_reward/small_control_std': Array(9.627, dtype=float32), 'eval/episode_reward/small_velocity_std': Array(20.793, dtype=float32), 'eval/episode_reward/upright_std': Array(14.801, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 13.842458486557007, 'eval/sps': 9246.912325892556}
[2025-07-07 15:29:37,415][absl][INFO] - replay size after prefill 8192
[2025-07-07 15:29:37,477][absl][INFO] - step 0
[2025-07-07 15:30:04,938][absl][INFO] - {'eval/walltime': 14.020749568939209, 'training/sps': 20349.212334282114, 'training/walltime': 35.49535655975342, 'training/actor_loss': Array(-17.734, dtype=float32), 'training/alpha': Array(0.131, dtype=float32), 'training/alpha_loss': Array(0.132, dtype=float32), 'training/buffer_current_size': Array(285632., dtype=float32), 'training/critic_loss': Array(0.018, dtype=float32), 'eval/episode_reward': Array(662.884, dtype=float32), 'eval/episode_reward/angle_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/centered': Array(782.149, dtype=float32), 'eval/episode_reward/small_control': Array(963.634, dtype=float32), 'eval/episode_reward/small_velocity': Array(957.212, dtype=float32), 'eval/episode_reward/upright': Array(884.474, dtype=float32), 'eval/episode_reward_std': Array(4.527, dtype=float32), 'eval/episode_reward/angle_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/centered_std': Array(6.59, dtype=float32), 'eval/episode_reward/small_control_std': Array(2.227, dtype=float32), 'eval/episode_reward/small_velocity_std': Array(0.965, dtype=float32), 'eval/episode_reward/upright_std': Array(2.273, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 0.17829108238220215, 'eval/sps': 717927.1015114862}
[2025-07-07 15:30:04,952][absl][INFO] - step 562944
[2025-07-07 15:30:16,924][absl][INFO] - {'eval/walltime': 14.190418481826782, 'training/sps': 47033.74096152851, 'training/walltime': 47.29012322425842, 'training/actor_loss': Array(-50.284, dtype=float32), 'training/alpha': Array(0.035, dtype=float32), 'training/alpha_loss': Array(0., dtype=float32), 'training/buffer_current_size': Array(840383.94, dtype=float32), 'training/critic_loss': Array(0.04, dtype=float32), 'eval/episode_reward': Array(838.956, dtype=float32), 'eval/episode_reward/angle_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/centered': Array(950.909, dtype=float32), 'eval/episode_reward/small_control': Array(972.874, dtype=float32), 'eval/episode_reward/small_velocity': Array(957.447, dtype=float32), 'eval/episode_reward/upright': Array(886.659, dtype=float32), 'eval/episode_reward_std': Array(9.627, dtype=float32), 'eval/episode_reward/angle_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/centered_std': Array(7.677, dtype=float32), 'eval/episode_reward/small_control_std': Array(2.111, dtype=float32), 'eval/episode_reward/small_velocity_std': Array(0.762, dtype=float32), 'eval/episode_reward/upright_std': Array(0.649, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 0.16966891288757324, 'eval/sps': 754410.4445627935}
[2025-07-07 15:30:16,939][absl][INFO] - step 1117696
[2025-07-07 15:30:28,537][absl][INFO] - {'eval/walltime': 14.359688997268677, 'training/sps': 48570.93345109934, 'training/walltime': 58.71160435676575, 'training/actor_loss': Array(-69.575, dtype=float32), 'training/alpha': Array(0.026, dtype=float32), 'training/alpha_loss': Array(0., dtype=float32), 'training/buffer_current_size': Array(1.395e+06, dtype=float32), 'training/critic_loss': Array(0.022, dtype=float32), 'eval/episode_reward': Array(851.758, dtype=float32), 'eval/episode_reward/angle_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/centered': Array(958.792, dtype=float32), 'eval/episode_reward/small_control': Array(977.21, dtype=float32), 'eval/episode_reward/small_velocity': Array(956.304, dtype=float32), 'eval/episode_reward/upright': Array(887.372, dtype=float32), 'eval/episode_reward_std': Array(2.618, dtype=float32), 'eval/episode_reward/angle_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/centered_std': Array(1.939, dtype=float32), 'eval/episode_reward/small_control_std': Array(0.704, dtype=float32), 'eval/episode_reward/small_velocity_std': Array(0.481, dtype=float32), 'eval/episode_reward/upright_std': Array(0.534, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 0.16927051544189453, 'eval/sps': 756186.0355056255}
[2025-07-07 15:30:28,543][absl][INFO] - step 1672448
[2025-07-07 15:30:40,203][absl][INFO] - {'eval/walltime': 14.537201642990112, 'training/sps': 48338.397344037316, 'training/walltime': 70.18802952766418, 'training/actor_loss': Array(-77.134, dtype=float32), 'training/alpha': Array(0.021, dtype=float32), 'training/alpha_loss': Array(0., dtype=float32), 'training/buffer_current_size': Array(1.95e+06, dtype=float32), 'training/critic_loss': Array(0.016, dtype=float32), 'eval/episode_reward': Array(848.073, dtype=float32), 'eval/episode_reward/angle_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/centered': Array(954.172, dtype=float32), 'eval/episode_reward/small_control': Array(978.51, dtype=float32), 'eval/episode_reward/small_velocity': Array(956.184, dtype=float32), 'eval/episode_reward/upright': Array(887.344, dtype=float32), 'eval/episode_reward_std': Array(1.306, dtype=float32), 'eval/episode_reward/angle_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/centered_std': Array(0.74, dtype=float32), 'eval/episode_reward/small_control_std': Array(0.608, dtype=float32), 'eval/episode_reward/small_velocity_std': Array(0.518, dtype=float32), 'eval/episode_reward/upright_std': Array(0.492, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 0.17751264572143555, 'eval/sps': 721075.3886281768}
[2025-07-07 15:30:40,210][absl][INFO] - step 2227200
[2025-07-07 15:30:51,732][absl][INFO] - {'eval/walltime': 14.704206943511963, 'training/sps': 48882.23790471622, 'training/walltime': 81.53677344322205, 'training/actor_loss': Array(-80.956, dtype=float32), 'training/alpha': Array(0.018, dtype=float32), 'training/alpha_loss': Array(0., dtype=float32), 'training/buffer_current_size': Array(2.505e+06, dtype=float32), 'training/critic_loss': Array(0.011, dtype=float32), 'eval/episode_reward': Array(854.505, dtype=float32), 'eval/episode_reward/angle_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/centered': Array(958.657, dtype=float32), 'eval/episode_reward/small_control': Array(979.99, dtype=float32), 'eval/episode_reward/small_velocity': Array(957.075, dtype=float32), 'eval/episode_reward/upright': Array(887.967, dtype=float32), 'eval/episode_reward_std': Array(0.681, dtype=float32), 'eval/episode_reward/angle_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/centered_std': Array(0.459, dtype=float32), 'eval/episode_reward/small_control_std': Array(0.431, dtype=float32), 'eval/episode_reward/small_velocity_std': Array(0.46, dtype=float32), 'eval/episode_reward/upright_std': Array(0.392, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 0.16700530052185059, 'eval/sps': 766442.7392425954}
[2025-07-07 15:30:51,738][absl][INFO] - step 2781952
[2025-07-07 15:31:03,516][absl][INFO] - {'eval/walltime': 14.877501249313354, 'training/sps': 47838.47748969796, 'training/walltime': 93.13312911987305, 'training/actor_loss': Array(-83.439, dtype=float32), 'training/alpha': Array(0.017, dtype=float32), 'training/alpha_loss': Array(0., dtype=float32), 'training/buffer_current_size': Array(3.059e+06, dtype=float32), 'training/critic_loss': Array(0.01, dtype=float32), 'eval/episode_reward': Array(855.72, dtype=float32), 'eval/episode_reward/angle_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/centered': Array(959.681, dtype=float32), 'eval/episode_reward/small_control': Array(979.956, dtype=float32), 'eval/episode_reward/small_velocity': Array(957.106, dtype=float32), 'eval/episode_reward/upright': Array(888.191, dtype=float32), 'eval/episode_reward_std': Array(1.764, dtype=float32), 'eval/episode_reward/angle_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/centered_std': Array(1.857, dtype=float32), 'eval/episode_reward/small_control_std': Array(0.497, dtype=float32), 'eval/episode_reward/small_velocity_std': Array(0.533, dtype=float32), 'eval/episode_reward/upright_std': Array(0.444, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 0.1732943058013916, 'eval/sps': 738627.8470493872}
[2025-07-07 15:31:03,524][absl][INFO] - step 3336704
[2025-07-07 15:31:15,067][absl][INFO] - {'eval/walltime': 15.067154884338379, 'training/sps': 48895.09338874165, 'training/walltime': 104.47888922691345, 'training/actor_loss': Array(-84.944, dtype=float32), 'training/alpha': Array(0.016, dtype=float32), 'training/alpha_loss': Array(0., dtype=float32), 'training/buffer_current_size': Array(3.614e+06, dtype=float32), 'training/critic_loss': Array(0.009, dtype=float32), 'eval/episode_reward': Array(857.065, dtype=float32), 'eval/episode_reward/angle_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/centered': Array(959.532, dtype=float32), 'eval/episode_reward/small_control': Array(980.315, dtype=float32), 'eval/episode_reward/small_velocity': Array(957.395, dtype=float32), 'eval/episode_reward/upright': Array(889.086, dtype=float32), 'eval/episode_reward_std': Array(0.683, dtype=float32), 'eval/episode_reward/angle_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/centered_std': Array(0.836, dtype=float32), 'eval/episode_reward/small_control_std': Array(0.49, dtype=float32), 'eval/episode_reward/small_velocity_std': Array(0.422, dtype=float32), 'eval/episode_reward/upright_std': Array(0.405, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 0.18965363502502441, 'eval/sps': 674914.5619229005}
[2025-07-07 15:31:15,084][absl][INFO] - step 3891456
[2025-07-07 15:31:29,174][absl][INFO] - {'eval/walltime': 15.245530605316162, 'training/sps': 39895.55636826619, 'training/walltime': 118.3839967250824, 'training/actor_loss': Array(-86.527, dtype=float32), 'training/alpha': Array(0.014, dtype=float32), 'training/alpha_loss': Array(0., dtype=float32), 'training/buffer_current_size': Array(4.112e+06, dtype=float32), 'training/critic_loss': Array(0.007, dtype=float32), 'eval/episode_reward': Array(852.418, dtype=float32), 'eval/episode_reward/angle_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/centered': Array(953.092, dtype=float32), 'eval/episode_reward/small_control': Array(981.85, dtype=float32), 'eval/episode_reward/small_velocity': Array(958.13, dtype=float32), 'eval/episode_reward/upright': Array(889.339, dtype=float32), 'eval/episode_reward_std': Array(2.405, dtype=float32), 'eval/episode_reward/angle_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/centered_std': Array(2.692, dtype=float32), 'eval/episode_reward/small_control_std': Array(0.451, dtype=float32), 'eval/episode_reward/small_velocity_std': Array(0.474, dtype=float32), 'eval/episode_reward/upright_std': Array(0.381, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 0.1783757209777832, 'eval/sps': 717586.4478548764}
[2025-07-07 15:31:29,184][absl][INFO] - step 4446208
[2025-07-07 15:31:46,024][absl][INFO] - {'eval/walltime': 15.42238712310791, 'training/sps': 33307.240630622066, 'training/walltime': 135.03959441184998, 'training/actor_loss': Array(-91.078, dtype=float32), 'training/alpha': Array(0.011, dtype=float32), 'training/alpha_loss': Array(0., dtype=float32), 'training/buffer_current_size': Array(4.194e+06, dtype=float32), 'training/critic_loss': Array(0.001, dtype=float32), 'eval/episode_reward': Array(859.407, dtype=float32), 'eval/episode_reward/angle_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/centered': Array(959.203, dtype=float32), 'eval/episode_reward/small_control': Array(982.276, dtype=float32), 'eval/episode_reward/small_velocity': Array(958.822, dtype=float32), 'eval/episode_reward/upright': Array(889.394, dtype=float32), 'eval/episode_reward_std': Array(0.852, dtype=float32), 'eval/episode_reward/angle_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/centered_std': Array(1.091, dtype=float32), 'eval/episode_reward/small_control_std': Array(0.419, dtype=float32), 'eval/episode_reward/small_velocity_std': Array(0.49, dtype=float32), 'eval/episode_reward/upright_std': Array(0.381, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 0.17685651779174805, 'eval/sps': 723750.5385621267}
[2025-07-07 15:31:47,274][absl][INFO] - total steps: 5000960
