[2025-07-07 15:32:57,289][jax._src.xla_bridge][INFO] - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
[2025-07-07 15:32:57,447][root][INFO] - Using JAX default device: cuda:0.
[2025-07-07 15:32:57,448][root][INFO] - MJX Warp is disabled via MJX_WARP_ENABLED=false.
[2025-07-07 15:32:57,657][absl][INFO] - local_device_count: 1; total_device_count: 1
[2025-07-07 15:32:57,996][root][INFO] - Using JAX default device: cuda:0.
[2025-07-07 15:32:57,996][root][INFO] - MJX Warp is disabled via MJX_WARP_ENABLED=false.
[2025-07-07 15:33:03,019][root][INFO] - Using JAX default device: cuda:0.
[2025-07-07 15:33:03,020][root][INFO] - MJX Warp is disabled via MJX_WARP_ENABLED=false.
[2025-07-07 15:33:11,311][root][INFO] - Using JAX default device: cuda:0.
[2025-07-07 15:33:11,311][root][INFO] - MJX Warp is disabled via MJX_WARP_ENABLED=false.
[2025-07-07 15:33:26,371][absl][INFO] - {'eval/walltime': 14.942791223526001, 'eval/episode_reward': Array(150.641, dtype=float32), 'eval/episode_reward/angle_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/centered': Array(649.6, dtype=float32), 'eval/episode_reward/small_control': Array(849.234, dtype=float32), 'eval/episode_reward/small_velocity': Array(578.647, dtype=float32), 'eval/episode_reward/upright': Array(482.176, dtype=float32), 'eval/episode_reward_std': Array(15.348, dtype=float32), 'eval/episode_reward/angle_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/centered_std': Array(19.005, dtype=float32), 'eval/episode_reward/small_control_std': Array(9.627, dtype=float32), 'eval/episode_reward/small_velocity_std': Array(20.793, dtype=float32), 'eval/episode_reward/upright_std': Array(14.801, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 14.942791223526001, 'eval/sps': 8566.003371476956}
[2025-07-07 15:33:35,030][absl][INFO] - replay size after prefill 8192
[2025-07-07 15:33:35,087][absl][INFO] - step 0
[2025-07-07 15:34:01,921][absl][INFO] - {'eval/walltime': 15.114792823791504, 'training/sps': 20821.83882427947, 'training/walltime': 35.35142278671265, 'training/actor_loss': Array(-17.317, dtype=float32), 'training/alpha': Array(0.13, dtype=float32), 'training/alpha_loss': Array(0.132, dtype=float32), 'training/buffer_current_size': Array(285632., dtype=float32), 'training/critic_loss': Array(0.017, dtype=float32), 'eval/episode_reward': Array(587.61, dtype=float32), 'eval/episode_reward/angle_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/centered': Array(703.643, dtype=float32), 'eval/episode_reward/small_control': Array(960.574, dtype=float32), 'eval/episode_reward/small_velocity': Array(956.129, dtype=float32), 'eval/episode_reward/upright': Array(887.87, dtype=float32), 'eval/episode_reward_std': Array(6.664, dtype=float32), 'eval/episode_reward/angle_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/centered_std': Array(3.562, dtype=float32), 'eval/episode_reward/small_control_std': Array(2.223, dtype=float32), 'eval/episode_reward/small_velocity_std': Array(6.437, dtype=float32), 'eval/episode_reward/upright_std': Array(6.216, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 0.17200160026550293, 'eval/sps': 744179.122766406}
[2025-07-07 15:34:01,928][absl][INFO] - step 562944
[2025-07-07 15:34:13,691][absl][INFO] - {'eval/walltime': 15.296580076217651, 'training/sps': 47950.17474597808, 'training/walltime': 46.92076539993286, 'training/actor_loss': Array(-46.677, dtype=float32), 'training/alpha': Array(0.033, dtype=float32), 'training/alpha_loss': Array(0., dtype=float32), 'training/buffer_current_size': Array(840383.94, dtype=float32), 'training/critic_loss': Array(0.042, dtype=float32), 'eval/episode_reward': Array(840.985, dtype=float32), 'eval/episode_reward/angle_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/centered': Array(953.383, dtype=float32), 'eval/episode_reward/small_control': Array(973.093, dtype=float32), 'eval/episode_reward/small_velocity': Array(956.685, dtype=float32), 'eval/episode_reward/upright': Array(885.683, dtype=float32), 'eval/episode_reward_std': Array(1.8, dtype=float32), 'eval/episode_reward/angle_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/centered_std': Array(1.678, dtype=float32), 'eval/episode_reward/small_control_std': Array(0.728, dtype=float32), 'eval/episode_reward/small_velocity_std': Array(0.732, dtype=float32), 'eval/episode_reward/upright_std': Array(0.828, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 0.18178725242614746, 'eval/sps': 704119.778981758}
[2025-07-07 15:34:13,707][absl][INFO] - step 1117696
[2025-07-07 15:34:25,475][absl][INFO] - {'eval/walltime': 15.467999696731567, 'training/sps': 47873.405185486416, 'training/walltime': 58.508660554885864, 'training/actor_loss': Array(-65.745, dtype=float32), 'training/alpha': Array(0.026, dtype=float32), 'training/alpha_loss': Array(0., dtype=float32), 'training/buffer_current_size': Array(1.395e+06, dtype=float32), 'training/critic_loss': Array(0.025, dtype=float32), 'eval/episode_reward': Array(840.636, dtype=float32), 'eval/episode_reward/angle_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/centered': Array(951.045, dtype=float32), 'eval/episode_reward/small_control': Array(976.089, dtype=float32), 'eval/episode_reward/small_velocity': Array(954.651, dtype=float32), 'eval/episode_reward/upright': Array(885.379, dtype=float32), 'eval/episode_reward_std': Array(2.504, dtype=float32), 'eval/episode_reward/angle_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/centered_std': Array(2.105, dtype=float32), 'eval/episode_reward/small_control_std': Array(0.562, dtype=float32), 'eval/episode_reward/small_velocity_std': Array(0.43, dtype=float32), 'eval/episode_reward/upright_std': Array(0.588, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 0.17141962051391602, 'eval/sps': 746705.6549084405}
[2025-07-07 15:34:25,489][absl][INFO] - step 1672448
[2025-07-07 15:34:37,048][absl][INFO] - {'eval/walltime': 15.641752481460571, 'training/sps': 48771.41223360004, 'training/walltime': 69.88319277763367, 'training/actor_loss': Array(-74.518, dtype=float32), 'training/alpha': Array(0.022, dtype=float32), 'training/alpha_loss': Array(0., dtype=float32), 'training/buffer_current_size': Array(1.95e+06, dtype=float32), 'training/critic_loss': Array(0.015, dtype=float32), 'eval/episode_reward': Array(839.666, dtype=float32), 'eval/episode_reward/angle_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/centered': Array(946.296, dtype=float32), 'eval/episode_reward/small_control': Array(978.797, dtype=float32), 'eval/episode_reward/small_velocity': Array(955.83, dtype=float32), 'eval/episode_reward/upright': Array(886.32, dtype=float32), 'eval/episode_reward_std': Array(1.566, dtype=float32), 'eval/episode_reward/angle_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/centered_std': Array(1.285, dtype=float32), 'eval/episode_reward/small_control_std': Array(0.552, dtype=float32), 'eval/episode_reward/small_velocity_std': Array(0.437, dtype=float32), 'eval/episode_reward/upright_std': Array(0.427, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 0.1737527847290039, 'eval/sps': 736678.8405701646}
[2025-07-07 15:34:37,062][absl][INFO] - step 2227200
[2025-07-07 15:34:48,693][absl][INFO] - {'eval/walltime': 15.808572053909302, 'training/sps': 48419.73864744948, 'training/walltime': 81.34033846855164, 'training/actor_loss': Array(-78.874, dtype=float32), 'training/alpha': Array(0.019, dtype=float32), 'training/alpha_loss': Array(0., dtype=float32), 'training/buffer_current_size': Array(2.505e+06, dtype=float32), 'training/critic_loss': Array(0.011, dtype=float32), 'eval/episode_reward': Array(850.05, dtype=float32), 'eval/episode_reward/angle_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/centered': Array(955.675, dtype=float32), 'eval/episode_reward/small_control': Array(979.011, dtype=float32), 'eval/episode_reward/small_velocity': Array(956.537, dtype=float32), 'eval/episode_reward/upright': Array(887.479, dtype=float32), 'eval/episode_reward_std': Array(1.783, dtype=float32), 'eval/episode_reward/angle_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/centered_std': Array(1.447, dtype=float32), 'eval/episode_reward/small_control_std': Array(0.474, dtype=float32), 'eval/episode_reward/small_velocity_std': Array(0.476, dtype=float32), 'eval/episode_reward/upright_std': Array(0.455, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 0.16681957244873047, 'eval/sps': 767296.0559789165}
[2025-07-07 15:34:48,700][absl][INFO] - step 2781952
[2025-07-07 15:35:00,199][absl][INFO] - {'eval/walltime': 15.981400489807129, 'training/sps': 49013.8067988605, 'training/walltime': 92.65861868858337, 'training/actor_loss': Array(-81.299, dtype=float32), 'training/alpha': Array(0.017, dtype=float32), 'training/alpha_loss': Array(0., dtype=float32), 'training/buffer_current_size': Array(3.059e+06, dtype=float32), 'training/critic_loss': Array(0.009, dtype=float32), 'eval/episode_reward': Array(848.652, dtype=float32), 'eval/episode_reward/angle_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/centered': Array(953.2, dtype=float32), 'eval/episode_reward/small_control': Array(979.82, dtype=float32), 'eval/episode_reward/small_velocity': Array(957., dtype=float32), 'eval/episode_reward/upright': Array(887.715, dtype=float32), 'eval/episode_reward_std': Array(1.238, dtype=float32), 'eval/episode_reward/angle_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/centered_std': Array(1.1, dtype=float32), 'eval/episode_reward/small_control_std': Array(0.494, dtype=float32), 'eval/episode_reward/small_velocity_std': Array(0.529, dtype=float32), 'eval/episode_reward/upright_std': Array(0.436, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 0.17282843589782715, 'eval/sps': 740618.8648011091}
[2025-07-07 15:35:00,205][absl][INFO] - step 3336704
[2025-07-07 15:35:11,822][absl][INFO] - {'eval/walltime': 16.14902114868164, 'training/sps': 48479.72650249639, 'training/walltime': 104.1015875339508, 'training/actor_loss': Array(-83.006, dtype=float32), 'training/alpha': Array(0.015, dtype=float32), 'training/alpha_loss': Array(0., dtype=float32), 'training/buffer_current_size': Array(3.614e+06, dtype=float32), 'training/critic_loss': Array(0.007, dtype=float32), 'eval/episode_reward': Array(852.629, dtype=float32), 'eval/episode_reward/angle_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/centered': Array(957.536, dtype=float32), 'eval/episode_reward/small_control': Array(979.544, dtype=float32), 'eval/episode_reward/small_velocity': Array(956.443, dtype=float32), 'eval/episode_reward/upright': Array(887.681, dtype=float32), 'eval/episode_reward_std': Array(1.171, dtype=float32), 'eval/episode_reward/angle_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/centered_std': Array(1.202, dtype=float32), 'eval/episode_reward/small_control_std': Array(0.463, dtype=float32), 'eval/episode_reward/small_velocity_std': Array(0.476, dtype=float32), 'eval/episode_reward/upright_std': Array(0.445, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 0.16762065887451172, 'eval/sps': 763629.0231732504}
[2025-07-07 15:35:11,829][absl][INFO] - step 3891456
[2025-07-07 15:35:25,522][absl][INFO] - {'eval/walltime': 16.328985929489136, 'training/sps': 41069.50967016528, 'training/walltime': 117.60922384262085, 'training/actor_loss': Array(-84.945, dtype=float32), 'training/alpha': Array(0.014, dtype=float32), 'training/alpha_loss': Array(0., dtype=float32), 'training/buffer_current_size': Array(4.112e+06, dtype=float32), 'training/critic_loss': Array(0.006, dtype=float32), 'eval/episode_reward': Array(856.798, dtype=float32), 'eval/episode_reward/angle_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/centered': Array(958.859, dtype=float32), 'eval/episode_reward/small_control': Array(981.687, dtype=float32), 'eval/episode_reward/small_velocity': Array(957.358, dtype=float32), 'eval/episode_reward/upright': Array(888.466, dtype=float32), 'eval/episode_reward_std': Array(0.712, dtype=float32), 'eval/episode_reward/angle_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/centered_std': Array(0.637, dtype=float32), 'eval/episode_reward/small_control_std': Array(0.454, dtype=float32), 'eval/episode_reward/small_velocity_std': Array(0.429, dtype=float32), 'eval/episode_reward/upright_std': Array(0.359, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 0.17996478080749512, 'eval/sps': 711250.275891032}
[2025-07-07 15:35:25,529][absl][INFO] - step 4446208
[2025-07-07 15:35:42,348][absl][INFO] - {'eval/walltime': 16.502201080322266, 'training/sps': 33344.355921903596, 'training/walltime': 134.24628233909607, 'training/actor_loss': Array(-90.04, dtype=float32), 'training/alpha': Array(0.011, dtype=float32), 'training/alpha_loss': Array(0., dtype=float32), 'training/buffer_current_size': Array(4.194e+06, dtype=float32), 'training/critic_loss': Array(0.001, dtype=float32), 'eval/episode_reward': Array(859.322, dtype=float32), 'eval/episode_reward/angle_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/centered': Array(960.868, dtype=float32), 'eval/episode_reward/small_control': Array(981.727, dtype=float32), 'eval/episode_reward/small_velocity': Array(957.748, dtype=float32), 'eval/episode_reward/upright': Array(888.397, dtype=float32), 'eval/episode_reward_std': Array(0.529, dtype=float32), 'eval/episode_reward/angle_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/centered_std': Array(0.422, dtype=float32), 'eval/episode_reward/small_control_std': Array(0.439, dtype=float32), 'eval/episode_reward/small_velocity_std': Array(0.38, dtype=float32), 'eval/episode_reward/upright_std': Array(0.355, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 0.17321515083312988, 'eval/sps': 738965.3814019493}
[2025-07-07 15:35:43,473][absl][INFO] - total steps: 5000960
