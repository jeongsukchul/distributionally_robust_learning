[2025-07-07 15:42:46,536][jax._src.xla_bridge][INFO] - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
[2025-07-07 15:42:46,693][root][INFO] - Using JAX default device: cuda:0.
[2025-07-07 15:42:46,693][root][INFO] - MJX Warp is disabled via MJX_WARP_ENABLED=false.
[2025-07-07 15:42:46,924][absl][INFO] - local_device_count: 1; total_device_count: 1
[2025-07-07 15:42:47,273][root][INFO] - Using JAX default device: cuda:0.
[2025-07-07 15:42:47,274][root][INFO] - MJX Warp is disabled via MJX_WARP_ENABLED=false.
[2025-07-07 15:42:52,747][root][INFO] - Using JAX default device: cuda:0.
[2025-07-07 15:42:52,747][root][INFO] - MJX Warp is disabled via MJX_WARP_ENABLED=false.
[2025-07-07 15:43:01,324][root][INFO] - Using JAX default device: cuda:0.
[2025-07-07 15:43:01,325][root][INFO] - MJX Warp is disabled via MJX_WARP_ENABLED=false.
[2025-07-07 15:43:16,446][absl][INFO] - {'eval/walltime': 14.98571491241455, 'eval/episode_reward': Array(150.641, dtype=float32), 'eval/episode_reward/angle_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/centered': Array(649.6, dtype=float32), 'eval/episode_reward/small_control': Array(849.234, dtype=float32), 'eval/episode_reward/small_velocity': Array(578.647, dtype=float32), 'eval/episode_reward/upright': Array(482.176, dtype=float32), 'eval/episode_reward_std': Array(15.348, dtype=float32), 'eval/episode_reward/angle_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/centered_std': Array(19.005, dtype=float32), 'eval/episode_reward/small_control_std': Array(9.627, dtype=float32), 'eval/episode_reward/small_velocity_std': Array(20.793, dtype=float32), 'eval/episode_reward/upright_std': Array(14.801, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 14.98571491241455, 'eval/sps': 8541.467707620777}
[2025-07-07 15:43:25,298][absl][INFO] - replay size after prefill 8192
[2025-07-07 15:43:25,346][absl][INFO] - step 0
[2025-07-07 15:43:51,861][absl][INFO] - {'eval/walltime': 15.152936935424805, 'training/sps': 21087.22506323951, 'training/walltime': 35.201595306396484, 'training/actor_loss': Array(-17.734, dtype=float32), 'training/alpha': Array(0.131, dtype=float32), 'training/alpha_loss': Array(0.132, dtype=float32), 'training/buffer_current_size': Array(285632., dtype=float32), 'training/critic_loss': Array(0.018, dtype=float32), 'eval/episode_reward': Array(662.884, dtype=float32), 'eval/episode_reward/angle_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/centered': Array(782.149, dtype=float32), 'eval/episode_reward/small_control': Array(963.634, dtype=float32), 'eval/episode_reward/small_velocity': Array(957.212, dtype=float32), 'eval/episode_reward/upright': Array(884.474, dtype=float32), 'eval/episode_reward_std': Array(4.527, dtype=float32), 'eval/episode_reward/angle_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/centered_std': Array(6.59, dtype=float32), 'eval/episode_reward/small_control_std': Array(2.227, dtype=float32), 'eval/episode_reward/small_velocity_std': Array(0.965, dtype=float32), 'eval/episode_reward/upright_std': Array(2.273, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 0.1672220230102539, 'eval/sps': 765449.4168638969}
[2025-07-07 15:43:51,878][absl][INFO] - step 562944
[2025-07-07 15:44:03,397][absl][INFO] - {'eval/walltime': 15.321135997772217, 'training/sps': 48899.787350688006, 'training/walltime': 46.546266317367554, 'training/actor_loss': Array(-50.284, dtype=float32), 'training/alpha': Array(0.035, dtype=float32), 'training/alpha_loss': Array(0., dtype=float32), 'training/buffer_current_size': Array(840383.94, dtype=float32), 'training/critic_loss': Array(0.04, dtype=float32), 'eval/episode_reward': Array(838.956, dtype=float32), 'eval/episode_reward/angle_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/centered': Array(950.909, dtype=float32), 'eval/episode_reward/small_control': Array(972.874, dtype=float32), 'eval/episode_reward/small_velocity': Array(957.447, dtype=float32), 'eval/episode_reward/upright': Array(886.659, dtype=float32), 'eval/episode_reward_std': Array(9.627, dtype=float32), 'eval/episode_reward/angle_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/centered_std': Array(7.677, dtype=float32), 'eval/episode_reward/small_control_std': Array(2.111, dtype=float32), 'eval/episode_reward/small_velocity_std': Array(0.762, dtype=float32), 'eval/episode_reward/upright_std': Array(0.649, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 0.1681990623474121, 'eval/sps': 761003.0532490028}
[2025-07-07 15:44:03,405][absl][INFO] - step 1117696
[2025-07-07 15:44:14,895][absl][INFO] - {'eval/walltime': 15.497848272323608, 'training/sps': 49061.44276130827, 'training/walltime': 57.853557109832764, 'training/actor_loss': Array(-69.575, dtype=float32), 'training/alpha': Array(0.026, dtype=float32), 'training/alpha_loss': Array(0., dtype=float32), 'training/buffer_current_size': Array(1.395e+06, dtype=float32), 'training/critic_loss': Array(0.022, dtype=float32), 'eval/episode_reward': Array(851.758, dtype=float32), 'eval/episode_reward/angle_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/centered': Array(958.792, dtype=float32), 'eval/episode_reward/small_control': Array(977.21, dtype=float32), 'eval/episode_reward/small_velocity': Array(956.304, dtype=float32), 'eval/episode_reward/upright': Array(887.372, dtype=float32), 'eval/episode_reward_std': Array(2.618, dtype=float32), 'eval/episode_reward/angle_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/centered_std': Array(1.939, dtype=float32), 'eval/episode_reward/small_control_std': Array(0.704, dtype=float32), 'eval/episode_reward/small_velocity_std': Array(0.481, dtype=float32), 'eval/episode_reward/upright_std': Array(0.534, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 0.1767122745513916, 'eval/sps': 724341.3075008264}
[2025-07-07 15:44:14,902][absl][INFO] - step 1672448
[2025-07-07 15:44:26,613][absl][INFO] - {'eval/walltime': 15.667690992355347, 'training/sps': 48101.22093842424, 'training/walltime': 69.38656997680664, 'training/actor_loss': Array(-77.134, dtype=float32), 'training/alpha': Array(0.021, dtype=float32), 'training/alpha_loss': Array(0., dtype=float32), 'training/buffer_current_size': Array(1.95e+06, dtype=float32), 'training/critic_loss': Array(0.016, dtype=float32), 'eval/episode_reward': Array(848.073, dtype=float32), 'eval/episode_reward/angle_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/centered': Array(954.172, dtype=float32), 'eval/episode_reward/small_control': Array(978.51, dtype=float32), 'eval/episode_reward/small_velocity': Array(956.184, dtype=float32), 'eval/episode_reward/upright': Array(887.344, dtype=float32), 'eval/episode_reward_std': Array(1.306, dtype=float32), 'eval/episode_reward/angle_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/centered_std': Array(0.74, dtype=float32), 'eval/episode_reward/small_control_std': Array(0.608, dtype=float32), 'eval/episode_reward/small_velocity_std': Array(0.518, dtype=float32), 'eval/episode_reward/upright_std': Array(0.492, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 0.16984272003173828, 'eval/sps': 753638.4248679061}
[2025-07-07 15:44:26,634][absl][INFO] - step 2227200
[2025-07-07 15:44:38,162][absl][INFO] - {'eval/walltime': 15.844250202178955, 'training/sps': 48897.569731838856, 'training/walltime': 80.73175549507141, 'training/actor_loss': Array(-80.956, dtype=float32), 'training/alpha': Array(0.018, dtype=float32), 'training/alpha_loss': Array(0., dtype=float32), 'training/buffer_current_size': Array(2.505e+06, dtype=float32), 'training/critic_loss': Array(0.011, dtype=float32), 'eval/episode_reward': Array(854.505, dtype=float32), 'eval/episode_reward/angle_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/centered': Array(958.657, dtype=float32), 'eval/episode_reward/small_control': Array(979.99, dtype=float32), 'eval/episode_reward/small_velocity': Array(957.075, dtype=float32), 'eval/episode_reward/upright': Array(887.967, dtype=float32), 'eval/episode_reward_std': Array(0.681, dtype=float32), 'eval/episode_reward/angle_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/centered_std': Array(0.459, dtype=float32), 'eval/episode_reward/small_control_std': Array(0.431, dtype=float32), 'eval/episode_reward/small_velocity_std': Array(0.46, dtype=float32), 'eval/episode_reward/upright_std': Array(0.392, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 0.1765592098236084, 'eval/sps': 724969.2617444227}
[2025-07-07 15:44:38,169][absl][INFO] - step 2781952
[2025-07-07 15:44:49,730][absl][INFO] - {'eval/walltime': 16.0209059715271, 'training/sps': 48756.171665165755, 'training/walltime': 92.10984325408936, 'training/actor_loss': Array(-83.439, dtype=float32), 'training/alpha': Array(0.017, dtype=float32), 'training/alpha_loss': Array(0., dtype=float32), 'training/buffer_current_size': Array(3.059e+06, dtype=float32), 'training/critic_loss': Array(0.01, dtype=float32), 'eval/episode_reward': Array(855.72, dtype=float32), 'eval/episode_reward/angle_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/centered': Array(959.681, dtype=float32), 'eval/episode_reward/small_control': Array(979.956, dtype=float32), 'eval/episode_reward/small_velocity': Array(957.106, dtype=float32), 'eval/episode_reward/upright': Array(888.191, dtype=float32), 'eval/episode_reward_std': Array(1.764, dtype=float32), 'eval/episode_reward/angle_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/centered_std': Array(1.857, dtype=float32), 'eval/episode_reward/small_control_std': Array(0.497, dtype=float32), 'eval/episode_reward/small_velocity_std': Array(0.533, dtype=float32), 'eval/episode_reward/upright_std': Array(0.444, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 0.17665576934814453, 'eval/sps': 724572.9956758099}
[2025-07-07 15:44:49,737][absl][INFO] - step 3336704
[2025-07-07 15:45:01,233][absl][INFO] - {'eval/walltime': 16.200867414474487, 'training/sps': 49068.01775897272, 'training/walltime': 103.41561889648438, 'training/actor_loss': Array(-84.944, dtype=float32), 'training/alpha': Array(0.016, dtype=float32), 'training/alpha_loss': Array(0., dtype=float32), 'training/buffer_current_size': Array(3.614e+06, dtype=float32), 'training/critic_loss': Array(0.009, dtype=float32), 'eval/episode_reward': Array(857.065, dtype=float32), 'eval/episode_reward/angle_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/centered': Array(959.532, dtype=float32), 'eval/episode_reward/small_control': Array(980.315, dtype=float32), 'eval/episode_reward/small_velocity': Array(957.395, dtype=float32), 'eval/episode_reward/upright': Array(889.086, dtype=float32), 'eval/episode_reward_std': Array(0.683, dtype=float32), 'eval/episode_reward/angle_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/centered_std': Array(0.836, dtype=float32), 'eval/episode_reward/small_control_std': Array(0.49, dtype=float32), 'eval/episode_reward/small_velocity_std': Array(0.422, dtype=float32), 'eval/episode_reward/upright_std': Array(0.405, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 0.1799614429473877, 'eval/sps': 711263.4679052958}
[2025-07-07 15:45:01,246][absl][INFO] - step 3891456
[2025-07-07 15:45:15,412][absl][INFO] - {'eval/walltime': 16.384121656417847, 'training/sps': 39700.842541339414, 'training/walltime': 117.38892436027527, 'training/actor_loss': Array(-86.527, dtype=float32), 'training/alpha': Array(0.014, dtype=float32), 'training/alpha_loss': Array(0., dtype=float32), 'training/buffer_current_size': Array(4.112e+06, dtype=float32), 'training/critic_loss': Array(0.007, dtype=float32), 'eval/episode_reward': Array(852.418, dtype=float32), 'eval/episode_reward/angle_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/centered': Array(953.092, dtype=float32), 'eval/episode_reward/small_control': Array(981.85, dtype=float32), 'eval/episode_reward/small_velocity': Array(958.13, dtype=float32), 'eval/episode_reward/upright': Array(889.339, dtype=float32), 'eval/episode_reward_std': Array(2.405, dtype=float32), 'eval/episode_reward/angle_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/centered_std': Array(2.692, dtype=float32), 'eval/episode_reward/small_control_std': Array(0.451, dtype=float32), 'eval/episode_reward/small_velocity_std': Array(0.474, dtype=float32), 'eval/episode_reward/upright_std': Array(0.381, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 0.18325424194335938, 'eval/sps': 698483.1491080164}
[2025-07-07 15:45:15,419][absl][INFO] - step 4446208
[2025-07-07 15:45:32,725][absl][INFO] - {'eval/walltime': 16.562690258026123, 'training/sps': 32400.0593389888, 'training/walltime': 134.51086831092834, 'training/actor_loss': Array(-91.078, dtype=float32), 'training/alpha': Array(0.011, dtype=float32), 'training/alpha_loss': Array(0., dtype=float32), 'training/buffer_current_size': Array(4.194e+06, dtype=float32), 'training/critic_loss': Array(0.001, dtype=float32), 'eval/episode_reward': Array(859.407, dtype=float32), 'eval/episode_reward/angle_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds': Array(0., dtype=float32), 'eval/episode_reward/centered': Array(959.203, dtype=float32), 'eval/episode_reward/small_control': Array(982.276, dtype=float32), 'eval/episode_reward/small_velocity': Array(958.822, dtype=float32), 'eval/episode_reward/upright': Array(889.394, dtype=float32), 'eval/episode_reward_std': Array(0.852, dtype=float32), 'eval/episode_reward/angle_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/cart_in_bounds_std': Array(0., dtype=float32), 'eval/episode_reward/centered_std': Array(1.091, dtype=float32), 'eval/episode_reward/small_control_std': Array(0.419, dtype=float32), 'eval/episode_reward/small_velocity_std': Array(0.49, dtype=float32), 'eval/episode_reward/upright_std': Array(0.381, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/std_episode_length': Array(0., dtype=float32), 'eval/epoch_eval_time': 0.17856860160827637, 'eval/sps': 716811.3478358975}
[2025-07-07 15:45:34,017][absl][INFO] - total steps: 5000960
