{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssCOanHc8JH_"
      },
      "source": [
        "# Training in Brax\n",
        "\n",
        "Once an environment is created in brax, we can quickly train it using brax's built-in training algorithms. Let's try it out!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "executionInfo": {
          "elapsed": 22308,
          "status": "ok",
          "timestamp": 1679686324614,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 240
        },
        "id": "kUrAlZTod7t_"
      },
      "outputs": [],
      "source": [
        "import functools\n",
        "import jax\n",
        "import os\n",
        "\n",
        "from datetime import datetime\n",
        "# from jax import numpy as jp\n",
        "import matplotlib.pyplot as plt\n",
        "import brax\n",
        "from IPython.display import HTML, clear_output\n",
        "# try:\n",
        "#   import brax\n",
        "# except ImportError:\n",
        "#   !pip install git+https://github.com/google/brax.git@main\n",
        "#   clear_output()\n",
        "#   import brax\n",
        "\n",
        "import flax\n",
        "from brax.io import model\n",
        "from brax.io import json\n",
        "from brax.io import html\n",
        "from learning.agents.apg import train as apg\n",
        "# from brax.training.agents.sac import train as sac\n",
        "from mujoco_playground import registry\n",
        "# if 'COLAB_TPU_ADDR' in os.environ:\n",
        "#   from jax.tools import colab_tpu\n",
        "#   colab_tpu.setup_tpu()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoyyw6pQ3xVJ"
      },
      "source": [
        "First let's pick an environment and a backend to train an agent in. \n",
        "\n",
        "Recall from the [Brax Basics](https://github.com/google/brax/blob/main/notebooks/basics.ipynb) colab, that the backend specifies which physics engine to use, each with different trade-offs between physical realism and training throughput/speed. The engines generally decrease in physical realism but increase in speed in the following order: `generalized`,  `positional`, then `spring`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "height": 480
        },
        "executionInfo": {
          "elapsed": 6143,
          "status": "ok",
          "timestamp": 1679686333304,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 240
        },
        "id": "4hHuDp53e4VJ",
        "outputId": "90d4c41b-9a25-4ca4-c6be-93172ea9ef57"
      },
      "outputs": [],
      "source": [
        "#@title Load Env { run: \"auto\" }\n",
        "\n",
        "env_name = 'HumanoidStand'  # @param ['ant', 'halfcheetah', 'hopper', 'humanoid', 'humanoidstandup', 'inverted_pendulum', 'inverted_double_pendulum', 'pusher', 'reacher', 'walker2d']\n",
        "env = registry.load(env_name)\n",
        "\n",
        "state = jax.jit(env.reset)(rng=jax.random.PRNGKey(seed=0))\n",
        "\n",
        "# HTML(html.render(env.mjx_model, [state.pipeline_state]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'Contact' object has no attribute 'elasticity'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_impl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontact\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43melasticity\u001b[49m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Contact' object has no attribute 'elasticity'"
          ]
        }
      ],
      "source": [
        "state.data._impl.contact.elasticity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMailSDb30t-"
      },
      "source": [
        "# Training\n",
        "\n",
        "Brax provides out of the box the following training algorithms:\n",
        "\n",
        "* [Proximal policy optimization](https://github.com/google/brax/blob/main/brax/training/agents/apg/train.py)\n",
        "* [Soft actor-critic](https://github.com/google/brax/blob/main/brax/training/agents/sac/train.py)\n",
        "* [Evolutionary strategy](https://github.com/google/brax/blob/main/brax/training/agents/es/train.py)\n",
        "* [Analytic policy gradients](https://github.com/google/brax/blob/main/brax/training/agents/apg/train.py)\n",
        "* [Augmented random search](https://github.com/google/brax/blob/main/brax/training/agents/ars/train.py)\n",
        "\n",
        "Trainers take as input an environment function and some hyperparameters, and return an inference function to operate the environment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3MA1UYlftuq"
      },
      "source": [
        "# Training\n",
        "\n",
        "Let's train the Ant policy using the `generalized` backend with apg."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "height": 321
        },
        "executionInfo": {
          "elapsed": 190263,
          "status": "ok",
          "timestamp": 1671658344336,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 300
        },
        "id": "FB6G2_Yt4A2m",
        "outputId": "402a0a43-3525-4eca-a425-ffcc71e8db0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env observation size 67\n",
            "data contact Contact(dist=Traced<float32[16]>with<BatchTrace> with\n",
            "  val = Traced<float32[128,16]>with<DynamicJaxprTrace>\n",
            "  batch_dim = 0, pos=Traced<float32[16,3]>with<BatchTrace> with\n",
            "  val = Traced<float32[128,16,3]>with<DynamicJaxprTrace>\n",
            "  batch_dim = 0, frame=Traced<float32[16,3,3]>with<BatchTrace> with\n",
            "  val = Traced<float32[128,16,3,3]>with<DynamicJaxprTrace>\n",
            "  batch_dim = 0, includemargin=Traced<float32[16]>with<BatchTrace> with\n",
            "  val = Traced<float32[128,16]>with<DynamicJaxprTrace>\n",
            "  batch_dim = 0, friction=Traced<float32[16,5]>with<BatchTrace> with\n",
            "  val = Traced<float32[128,16,5]>with<DynamicJaxprTrace>\n",
            "  batch_dim = 0, solref=Traced<float32[16,2]>with<BatchTrace> with\n",
            "  val = Traced<float32[128,16,2]>with<DynamicJaxprTrace>\n",
            "  batch_dim = 0, solreffriction=Traced<float32[16,2]>with<BatchTrace> with\n",
            "  val = Traced<float32[128,16,2]>with<DynamicJaxprTrace>\n",
            "  batch_dim = 0, solimp=Traced<float32[16,5]>with<BatchTrace> with\n",
            "  val = Traced<float32[128,16,5]>with<DynamicJaxprTrace>\n",
            "  batch_dim = 0, dim=array([1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3], dtype=int32), geom1=Traced<int32[16]>with<BatchTrace> with\n",
            "  val = Traced<int32[128,16]>with<DynamicJaxprTrace>\n",
            "  batch_dim = 0, geom2=Traced<int32[16]>with<BatchTrace> with\n",
            "  val = Traced<int32[128,16]>with<DynamicJaxprTrace>\n",
            "  batch_dim = 0, geom=Traced<int32[16,2]>with<BatchTrace> with\n",
            "  val = Traced<int32[128,16,2]>with<DynamicJaxprTrace>\n",
            "  batch_dim = 0, efc_address=array([21, 22, 23, 24, 25, 26, 27, 28, 29, 33, 37, 41, 45, 49, 53, 57]))\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "scan body function carry input and carry output must have the same pytree structure, but they differ:\n\nThe input carry component state.data._impl.contact is a <class 'mujoco.mjx._src.types.Contact'> but the corresponding component of the carry output is a <class 'brax.base.Contact'>, so their Python types differ.\n\nRevise the function so that the carry output has the same pytree structure as the carry input.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[3], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m   plt\u001b[38;5;241m.\u001b[39mplot(xdata, ydata)\n\u001b[1;32m     34\u001b[0m   plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m---> 36\u001b[0m make_inference_fn, params, _ \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43menvironment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime to jit: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimes[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mtimes[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime to train: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimes[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mtimes[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
            "File \u001b[0;32m~/distributionally_robust_learning/learning/agents/apg/train.py:341\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(environment, episode_length, policy_updates, wrap_env, wrap_env_fn, horizon_length, num_envs, num_evals, action_repeat, max_devices_per_host, num_eval_envs, learning_rate, adam_b, use_schedule, use_float64, schedule_decay, seed, max_gradient_norm, normalize_observations, deterministic_eval, network_factory, progress_fn, eval_env, randomization_fn)\u001b[0m\n\u001b[1;32m    338\u001b[0m metrics \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m process_id \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m num_evals \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 341\u001b[0m   metrics \u001b[38;5;241m=\u001b[39m \u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_evaluation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_unpmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m          \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalizer_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m      \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtraining_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m   logging\u001b[38;5;241m.\u001b[39minfo(metrics)\n\u001b[1;32m    348\u001b[0m   progress_fn(\u001b[38;5;241m0\u001b[39m, metrics)\n",
            "File \u001b[0;32m~/miniconda3/envs/sampling_bench/lib/python3.10/site-packages/brax/training/acting.py:133\u001b[0m, in \u001b[0;36mEvaluator.run_evaluation\u001b[0;34m(self, policy_params, training_metrics, aggregate_episodes)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_key, unroll_key \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_key)\n\u001b[1;32m    132\u001b[0m t \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 133\u001b[0m eval_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_eval_unroll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpolicy_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munroll_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m eval_metrics \u001b[38;5;241m=\u001b[39m eval_state\u001b[38;5;241m.\u001b[39minfo[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval_metrics\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    135\u001b[0m eval_metrics\u001b[38;5;241m.\u001b[39mactive_episodes\u001b[38;5;241m.\u001b[39mblock_until_ready()\n",
            "    \u001b[0;31m[... skipping hidden 14 frame]\u001b[0m\n",
            "File \u001b[0;32m~/miniconda3/envs/sampling_bench/lib/python3.10/site-packages/brax/training/acting.py:112\u001b[0m, in \u001b[0;36mEvaluator.__init__.<locals>.generate_eval_unroll\u001b[0;34m(policy_params, key)\u001b[0m\n\u001b[1;32m    110\u001b[0m reset_keys \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39msplit(key, num_eval_envs)\n\u001b[1;32m    111\u001b[0m eval_first_state \u001b[38;5;241m=\u001b[39m eval_env\u001b[38;5;241m.\u001b[39mreset(reset_keys)\n\u001b[0;32m--> 112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgenerate_unroll\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_first_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_policy_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpolicy_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43munroll_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepisode_length\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43maction_repeat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
            "File \u001b[0;32m~/miniconda3/envs/sampling_bench/lib/python3.10/site-packages/brax/training/acting.py:73\u001b[0m, in \u001b[0;36mgenerate_unroll\u001b[0;34m(env, env_state, policy, key, unroll_length, extra_fields)\u001b[0m\n\u001b[1;32m     68\u001b[0m   nstate, transition \u001b[38;5;241m=\u001b[39m actor_step(\n\u001b[1;32m     69\u001b[0m       env, state, policy, current_key, extra_fields\u001b[38;5;241m=\u001b[39mextra_fields\n\u001b[1;32m     70\u001b[0m   )\n\u001b[1;32m     71\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m (nstate, next_key), transition\n\u001b[0;32m---> 73\u001b[0m (final_state, _), data \u001b[38;5;241m=\u001b[39m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscan\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43menv_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlength\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munroll_length\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m final_state, data\n",
            "    \u001b[0;31m[... skipping hidden 24 frame]\u001b[0m\n",
            "File \u001b[0;32m~/miniconda3/envs/sampling_bench/lib/python3.10/site-packages/brax/training/acting.py:68\u001b[0m, in \u001b[0;36mgenerate_unroll.<locals>.f\u001b[0;34m(carry, unused_t)\u001b[0m\n\u001b[1;32m     66\u001b[0m state, current_key \u001b[38;5;241m=\u001b[39m carry\n\u001b[1;32m     67\u001b[0m current_key, next_key \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39msplit(current_key)\n\u001b[0;32m---> 68\u001b[0m nstate, transition \u001b[38;5;241m=\u001b[39m \u001b[43mactor_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_fields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_fields\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (nstate, next_key), transition\n",
            "File \u001b[0;32m~/miniconda3/envs/sampling_bench/lib/python3.10/site-packages/brax/training/acting.py:42\u001b[0m, in \u001b[0;36mactor_step\u001b[0;34m(env, env_state, policy, key, extra_fields)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Collect data.\"\"\"\u001b[39;00m\n\u001b[1;32m     41\u001b[0m actions, policy_extras \u001b[38;5;241m=\u001b[39m policy(env_state\u001b[38;5;241m.\u001b[39mobs, key)\n\u001b[0;32m---> 42\u001b[0m nstate \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m state_extras \u001b[38;5;241m=\u001b[39m {x: nstate\u001b[38;5;241m.\u001b[39minfo[x] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m extra_fields}\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m nstate, Transition(  \u001b[38;5;66;03m# pytype: disable=wrong-arg-types  # jax-ndarray\u001b[39;00m\n\u001b[1;32m     45\u001b[0m     observation\u001b[38;5;241m=\u001b[39menv_state\u001b[38;5;241m.\u001b[39mobs,\n\u001b[1;32m     46\u001b[0m     action\u001b[38;5;241m=\u001b[39mactions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     50\u001b[0m     extras\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpolicy_extras\u001b[39m\u001b[38;5;124m'\u001b[39m: policy_extras, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate_extras\u001b[39m\u001b[38;5;124m'\u001b[39m: state_extras},\n\u001b[1;32m     51\u001b[0m )\n",
            "File \u001b[0;32m~/miniconda3/envs/sampling_bench/lib/python3.10/site-packages/brax/envs/wrappers/training.py:200\u001b[0m, in \u001b[0;36mEvalWrapper.step\u001b[0;34m(self, state, action)\u001b[0m\n\u001b[1;32m    196\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    197\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIncorrect type for state_metrics: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(state_metrics)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    198\u001b[0m   )\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m state\u001b[38;5;241m.\u001b[39minfo[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval_metrics\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m--> 200\u001b[0m nstate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m nstate\u001b[38;5;241m.\u001b[39mmetrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreward\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m nstate\u001b[38;5;241m.\u001b[39mreward\n\u001b[1;32m    202\u001b[0m episode_steps \u001b[38;5;241m=\u001b[39m jp\u001b[38;5;241m.\u001b[39mwhere(\n\u001b[1;32m    203\u001b[0m     state_metrics\u001b[38;5;241m.\u001b[39mactive_episodes,\n\u001b[1;32m    204\u001b[0m     nstate\u001b[38;5;241m.\u001b[39minfo[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msteps\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    205\u001b[0m     state_metrics\u001b[38;5;241m.\u001b[39mepisode_steps,\n\u001b[1;32m    206\u001b[0m )\n",
            "File \u001b[0;32m~/distributionally_robust_learning/learning/module/wrapper/wrapper.py:140\u001b[0m, in \u001b[0;36mBraxAutoResetWrapper.step\u001b[0;34m(self, state, action)\u001b[0m\n\u001b[1;32m    138\u001b[0m   state\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mupdate(steps\u001b[38;5;241m=\u001b[39msteps)\n\u001b[1;32m    139\u001b[0m state \u001b[38;5;241m=\u001b[39m state\u001b[38;5;241m.\u001b[39mreplace(done\u001b[38;5;241m=\u001b[39mjp\u001b[38;5;241m.\u001b[39mzeros_like(state\u001b[38;5;241m.\u001b[39mdone))\n\u001b[0;32m--> 140\u001b[0m state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwhere_done\u001b[39m(x, y):\n\u001b[1;32m    143\u001b[0m   done \u001b[38;5;241m=\u001b[39m state\u001b[38;5;241m.\u001b[39mdone\n",
            "File \u001b[0;32m~/miniconda3/envs/sampling_bench/lib/python3.10/site-packages/brax/envs/wrappers/training.py:103\u001b[0m, in \u001b[0;36mEpisodeWrapper.step\u001b[0;34m(self, state, action)\u001b[0m\n\u001b[1;32m    100\u001b[0m   nstate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mstep(state, action)\n\u001b[1;32m    101\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m nstate, nstate\u001b[38;5;241m.\u001b[39mreward\n\u001b[0;32m--> 103\u001b[0m state, rewards \u001b[38;5;241m=\u001b[39m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction_repeat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m state \u001b[38;5;241m=\u001b[39m state\u001b[38;5;241m.\u001b[39mreplace(reward\u001b[38;5;241m=\u001b[39mjp\u001b[38;5;241m.\u001b[39msum(rewards, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m    105\u001b[0m steps \u001b[38;5;241m=\u001b[39m state\u001b[38;5;241m.\u001b[39minfo[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msteps\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_repeat\n",
            "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
            "File \u001b[0;32m~/miniconda3/envs/sampling_bench/lib/python3.10/site-packages/jax/_src/lax/control_flow/loops.py:494\u001b[0m, in \u001b[0;36m_check_carry_type\u001b[0;34m(name, body_fun, in_carry, out_carry_tree, out_avals)\u001b[0m\n\u001b[1;32m    491\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    492\u001b[0m       differences \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m  * \u001b[39m\u001b[38;5;132;01m{\u001b[39;00md\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m;\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m diffs[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    493\u001b[0m                      \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m  * \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdiffs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 494\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    495\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m function carry input and carry output must have the same \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    496\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpytree structure, but they differ:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    497\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdifferences\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    498\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRevise the function so that the carry output has the same pytree \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    499\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstructure as the carry input.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(_map(core\u001b[38;5;241m.\u001b[39mtypematch, in_avals, out_avals)):\n\u001b[1;32m    501\u001b[0m   diffs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcomponent(path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00min_aval\u001b[38;5;241m.\u001b[39mstr_short()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    502\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m but the corresponding output carry component has type \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    503\u001b[0m            \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout_aval\u001b[38;5;241m.\u001b[39mstr_short()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mcore\u001b[38;5;241m.\u001b[39maval_mismatch_extra(in_aval,\u001b[38;5;250m \u001b[39mout_aval)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    504\u001b[0m            \u001b[38;5;28;01mfor\u001b[39;00m path, in_aval, out_aval \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(paths, in_avals, out_avals)\n\u001b[1;32m    505\u001b[0m            \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m core\u001b[38;5;241m.\u001b[39mtypematch(in_aval, out_aval)]\n",
            "\u001b[0;31mTypeError\u001b[0m: scan body function carry input and carry output must have the same pytree structure, but they differ:\n\nThe input carry component state.data._impl.contact is a <class 'mujoco.mjx._src.types.Contact'> but the corresponding component of the carry output is a <class 'brax.base.Contact'>, so their Python types differ.\n\nRevise the function so that the carry output has the same pytree structure as the carry input."
          ]
        }
      ],
      "source": [
        "#@title Training\n",
        "\n",
        "# We determined some reasonable hyperparameters offline and share them here.\n",
        "train_fn = {\n",
        "  'inverted_pendulum': functools.partial(apg.train, num_evals=20, policy_updates=1e6, episode_length=1000, normalize_observations=True, action_repeat=1, learning_rate=3e-4,  num_envs=2048, seed=1),\n",
        "  # 'inverted_double_pendulum': functools.partial(apg.train, num_evals=20,  episod_length=1000, normalize_observations=True, action_repeat=1, unroll_length=5, num_minibatches=32, num_updates_per_batch=4, discounting=0.97, learning_rate=3e-4, entropy_cost=1e-2, num_envs=2048, seed=1),\n",
        "  # 'ant': functools.partial(apg.train,  num_evals=10,  episode_length=1000, normalize_observations=True, action_repeat=1, unroll_length=5, num_minibatches=32, num_updates_per_batch=4, discounting=0.97, learning_rate=3e-4, entropy_cost=1e-2, num_envs=4096, batch_size=2048, seed=1),\n",
        "  # 'humanoid': functools.partial(apg.train,  num_evals=10, episode_length=1000, normalize_observations=True, action_repeat=1, unroll_length=10, num_minibatches=32, num_updates_per_batch=8, discounting=0.97, learning_rate=3e-4, entropy_cost=1e-3, num_envs=2048, seed=1),\n",
        "  # 'reacher': functools.partial(apg.train, num_evals=20, episode_length=1000, normalize_observations=True, action_repeat=4, unroll_length=50, num_minibatches=32, num_updates_per_batch=8, discounting=0.95, learning_rate=3e-4, entropy_cost=1e-3, num_envs=2048, batch_size=256, max_devices_per_host=8, seed=1),\n",
        "   'HumanoidStand': functools.partial(apg.train, num_evals=20, policy_updates=1e6, episode_length=1000, normalize_observations=True, action_repeat=1, learning_rate=6e-4, num_envs=2048, seed=1),\n",
        "  # 'hopper': functools.partial(sac.train, num_evals=20, episode_length=1000, normalize_observations=True, action_repeat=1, discounting=0.997, learning_rate=6e-4, num_envs=128, grad_updates_per_step=64, max_devices_per_host=1, max_replay_size=1048576, min_replay_size=8192, seed=1),\n",
        "  # 'walker2d': functools.partial(sac.train, num_evals=20, episode_length=1000, normalize_observations=True, action_repeat=1, discounting=0.997, learning_rate=6e-4, num_envs=128, batch_size=128, grad_updates_per_step=32, max_devices_per_host=1, max_replay_size=1048576, min_replay_size=8192, seed=1),\n",
        "  # 'halfcheetah': functools.partial(apg.train, num_evals=20, episode_length=1000, normalize_observations=True, action_repeat=1, unroll_length=20, num_minibatches=32, num_updates_per_batch=8, discounting=0.95, learning_rate=3e-4, entropy_cost=0.001, num_envs=2048, seed=3),\n",
        "  # 'pusher': functools.partial(apg.train, num_evals=20, episode_length=1000, normalize_observations=True, action_repeat=1, unroll_length=30, num_minibatches=16, num_updates_per_batch=8, discounting=0.95, learning_rate=3e-4,entropy_cost=1e-2, num_envs=2048, seed=3),\n",
        "}[env_name]\n",
        "\n",
        "\n",
        "# max_y = {'ant': 8000, 'halfcheetah': 8000, 'hopper': 2500, 'humanoid': 13000, 'humanoidstandup': 75_000, 'reacher': 5, 'walker2d': 5000, 'pusher': 0}[env_name]\n",
        "# min_y = {'reacher': -100, 'pusher': -150}.get(env_name, 0)\n",
        "\n",
        "xdata, ydata = [], []\n",
        "times = [datetime.now()]\n",
        "\n",
        "def progress(num_steps, metrics):\n",
        "  times.append(datetime.now())\n",
        "  xdata.append(num_steps)\n",
        "  ydata.append(metrics['eval/episode_reward'])\n",
        "  clear_output(wait=True)\n",
        "  # plt.xlim([0, train_fn.keywords['num_timesteps']])\n",
        "  # plt.ylim([min_y, max_y])\n",
        "  plt.xlabel('# environment steps')\n",
        "  plt.ylabel('reward per episode')\n",
        "  plt.plot(xdata, ydata)\n",
        "  plt.show()\n",
        "\n",
        "make_inference_fn, params, _ = train_fn(environment=env, progress_fn=progress)\n",
        "\n",
        "print(f'time to jit: {times[1] - times[0]}')\n",
        "print(f'time to train: {times[-1] - times[1]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjlh7puy2ZM1"
      },
      "source": [
        "The trainers return an inference function, parameters, and the final set of metrics gathered during evaluation.\n",
        "\n",
        "# Saving and Loading Policies\n",
        "\n",
        "Brax can save and load trained policies:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gOWeDqlP35sI"
      },
      "outputs": [],
      "source": [
        "model.save_params('/tmp/params', params)\n",
        "params = model.load_params('/tmp/params')\n",
        "inference_fn = make_inference_fn(params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YlZvIG320sK"
      },
      "source": [
        "The trainers return an inference function, parameters, and the final set of metrics gathered during evaluation.\n",
        "\n",
        "# Saving and Loading Policies\n",
        "\n",
        "Brax can save and load trained policies:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "height": 480
        },
        "executionInfo": {
          "elapsed": 33520,
          "status": "ok",
          "timestamp": 1679346718844,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 240
        },
        "id": "kF5fS-yo35sI",
        "outputId": "94d1a7d5-8d6e-456c-8cfd-94a689b8808f"
      },
      "outputs": [],
      "source": [
        "#@title Visualizing a trajectory of the learned inference function\n",
        "\n",
        "# create an env with auto-reset\n",
        "# env = envs.create(env_name=env_name, backend=backend)\n",
        "import mediapy as media\n",
        "jit_env_reset = jax.jit(env.reset)\n",
        "jit_env_step = jax.jit(env.step)\n",
        "jit_inference_fn = jax.jit(inference_fn)\n",
        "\n",
        "rollout = []\n",
        "rng = jax.random.PRNGKey(seed=1)\n",
        "state = jit_env_reset(rng=rng)\n",
        "for _ in range(1000):\n",
        "  rollout.append(state)\n",
        "  act_rng, rng = jax.random.split(rng)\n",
        "  act, _ = jit_inference_fn(state.obs, act_rng)\n",
        "  state = jit_env_step(state, act)\n",
        "frames = env.render(rollout)\n",
        "media.show_video(frames, fps=1.0 / env.dt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBtrAqns35sI"
      },
      "source": [
        "ðŸ™Œ See you soon!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "sampling_bench",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
